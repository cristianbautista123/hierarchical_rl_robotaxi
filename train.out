Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-06_21-21-02

Map saved at: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-06_21-21-02/map_visualization.png

Using cpu device
Wrapping the env in a DummyVecEnv.
Logging to /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-06_21-21-02/tensorboard/PPO_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 196      |
|    ep_rew_mean     | 114      |
| time/              |          |
|    fps             | 2773     |
|    iterations      | 1        |
|    time_elapsed    | 0        |
|    total_timesteps | 2048     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 156         |
|    ep_rew_mean          | 78.3        |
| time/                   |             |
|    fps                  | 1954        |
|    iterations           | 2           |
|    time_elapsed         | 2           |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.011779067 |
|    clip_fraction        | 0.0344      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.685      |
|    explained_variance   | 0.00104     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.47        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00404    |
|    value_loss           | 51.3        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 163        |
|    ep_rew_mean          | 84.3       |
| time/                   |            |
|    fps                  | 1779       |
|    iterations           | 3          |
|    time_elapsed         | 3          |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.00921481 |
|    clip_fraction        | 0.0549     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.69      |
|    explained_variance   | -0.0151    |
|    learning_rate        | 0.0003     |
|    loss                 | 100        |
|    n_updates            | 20         |
|    policy_gradient_loss | -0.00349   |
|    value_loss           | 189        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 170         |
|    ep_rew_mean          | 95.1        |
| time/                   |             |
|    fps                  | 1701        |
|    iterations           | 4           |
|    time_elapsed         | 4           |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.011335144 |
|    clip_fraction        | 0.0251      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.686      |
|    explained_variance   | 0.00265     |
|    learning_rate        | 0.0003      |
|    loss                 | 49.5        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00291    |
|    value_loss           | 89.5        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=35.20 +/- 24.08
Episode length: 85.20 +/- 24.08
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 85.2         |
|    mean_reward          | 35.2         |
| time/                   |              |
|    total_timesteps      | 10000        |
| train/                  |              |
|    approx_kl            | 0.0036181975 |
|    clip_fraction        | 0.00742      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.677       |
|    explained_variance   | -0.00895     |
|    learning_rate        | 0.0003       |
|    loss                 | 59.9         |
|    n_updates            | 40           |
|    policy_gradient_loss | 0.000139     |
|    value_loss           | 78.1         |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 170      |
|    ep_rew_mean     | 95.9     |
| time/              |          |
|    fps             | 1621     |
|    iterations      | 5        |
|    time_elapsed    | 6        |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 172         |
|    ep_rew_mean          | 97.6        |
| time/                   |             |
|    fps                  | 1599        |
|    iterations           | 6           |
|    time_elapsed         | 7           |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.009141829 |
|    clip_fraction        | 0.0881      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.684      |
|    explained_variance   | -0.000718   |
|    learning_rate        | 0.0003      |
|    loss                 | 77.6        |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00298    |
|    value_loss           | 158         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 175         |
|    ep_rew_mean          | 99          |
| time/                   |             |
|    fps                  | 1584        |
|    iterations           | 7           |
|    time_elapsed         | 9           |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.006566106 |
|    clip_fraction        | 0.000488    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.69       |
|    explained_variance   | 0.0148      |
|    learning_rate        | 0.0003      |
|    loss                 | 94.7        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.000809   |
|    value_loss           | 141         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 175          |
|    ep_rew_mean          | 98.9         |
| time/                   |              |
|    fps                  | 1572         |
|    iterations           | 8            |
|    time_elapsed         | 10           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0078048445 |
|    clip_fraction        | 0.0236       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.689       |
|    explained_variance   | 0.114        |
|    learning_rate        | 0.0003       |
|    loss                 | 83.1         |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00287     |
|    value_loss           | 71.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 171          |
|    ep_rew_mean          | 95.5         |
| time/                   |              |
|    fps                  | 1563         |
|    iterations           | 9            |
|    time_elapsed         | 11           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0018696599 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.685       |
|    explained_variance   | 0.207        |
|    learning_rate        | 0.0003       |
|    loss                 | 115          |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.000485    |
|    value_loss           | 136          |
------------------------------------------
Eval num_timesteps=20000, episode_reward=33.04 +/- 9.95
Episode length: 98.40 +/- 28.46
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 98.4         |
|    mean_reward          | 33           |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0047922134 |
|    clip_fraction        | 0.00146      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.678       |
|    explained_variance   | 0.255        |
|    learning_rate        | 0.0003       |
|    loss                 | 46.8         |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00162     |
|    value_loss           | 158          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 175      |
|    ep_rew_mean     | 99.7     |
| time/              |          |
|    fps             | 1540     |
|    iterations      | 10       |
|    time_elapsed    | 13       |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 167          |
|    ep_rew_mean          | 93.6         |
| time/                   |              |
|    fps                  | 1537         |
|    iterations           | 11           |
|    time_elapsed         | 14           |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0066649355 |
|    clip_fraction        | 0.0415       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.682       |
|    explained_variance   | 0.209        |
|    learning_rate        | 0.0003       |
|    loss                 | 86.8         |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00134     |
|    value_loss           | 196          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 164           |
|    ep_rew_mean          | 90.1          |
| time/                   |               |
|    fps                  | 1534          |
|    iterations           | 12            |
|    time_elapsed         | 16            |
|    total_timesteps      | 24576         |
| train/                  |               |
|    approx_kl            | 0.00034231468 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.665        |
|    explained_variance   | 0.0359        |
|    learning_rate        | 0.0003        |
|    loss                 | 139           |
|    n_updates            | 110           |
|    policy_gradient_loss | -0.000311     |
|    value_loss           | 293           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 162          |
|    ep_rew_mean          | 87.9         |
| time/                   |              |
|    fps                  | 1530         |
|    iterations           | 13           |
|    time_elapsed         | 17           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0045562694 |
|    clip_fraction        | 0.0281       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.66        |
|    explained_variance   | 0.163        |
|    learning_rate        | 0.0003       |
|    loss                 | 150          |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00383     |
|    value_loss           | 146          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 157          |
|    ep_rew_mean          | 83.8         |
| time/                   |              |
|    fps                  | 1528         |
|    iterations           | 14           |
|    time_elapsed         | 18           |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 0.0030619055 |
|    clip_fraction        | 0.00249      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.664       |
|    explained_variance   | 0.165        |
|    learning_rate        | 0.0003       |
|    loss                 | 57.4         |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.000172    |
|    value_loss           | 187          |
------------------------------------------
Eval num_timesteps=30000, episode_reward=87.05 +/- 51.53
Episode length: 162.60 +/- 72.38
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 163         |
|    mean_reward          | 87          |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.010082519 |
|    clip_fraction        | 0.0407      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.632      |
|    explained_variance   | 0.151       |
|    learning_rate        | 0.0003      |
|    loss                 | 86.6        |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.00333    |
|    value_loss           | 193         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | 78.8     |
| time/              |          |
|    fps             | 1509     |
|    iterations      | 15       |
|    time_elapsed    | 20       |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 151         |
|    ep_rew_mean          | 80.4        |
| time/                   |             |
|    fps                  | 1509        |
|    iterations           | 16          |
|    time_elapsed         | 21          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.005509002 |
|    clip_fraction        | 0.0782      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.675      |
|    explained_variance   | 0.159       |
|    learning_rate        | 0.0003      |
|    loss                 | 103         |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00234    |
|    value_loss           | 183         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 154         |
|    ep_rew_mean          | 83.5        |
| time/                   |             |
|    fps                  | 1508        |
|    iterations           | 17          |
|    time_elapsed         | 23          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.010531475 |
|    clip_fraction        | 0.0575      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.655      |
|    explained_variance   | 0.304       |
|    learning_rate        | 0.0003      |
|    loss                 | 55.6        |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.00434    |
|    value_loss           | 118         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 158         |
|    ep_rew_mean          | 87.6        |
| time/                   |             |
|    fps                  | 1508        |
|    iterations           | 18          |
|    time_elapsed         | 24          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.004298752 |
|    clip_fraction        | 0.0191      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.667      |
|    explained_variance   | 0.292       |
|    learning_rate        | 0.0003      |
|    loss                 | 91.3        |
|    n_updates            | 170         |
|    policy_gradient_loss | 7.76e-05    |
|    value_loss           | 141         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 160         |
|    ep_rew_mean          | 90.4        |
| time/                   |             |
|    fps                  | 1507        |
|    iterations           | 19          |
|    time_elapsed         | 25          |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.008189056 |
|    clip_fraction        | 0.0565      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.684      |
|    explained_variance   | 0.299       |
|    learning_rate        | 0.0003      |
|    loss                 | 99.9        |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00118    |
|    value_loss           | 144         |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=115.27 +/- 74.61
Episode length: 162.20 +/- 72.14
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 162       |
|    mean_reward          | 115       |
| time/                   |           |
|    total_timesteps      | 40000     |
| train/                  |           |
|    approx_kl            | 0.0095603 |
|    clip_fraction        | 0.0678    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.689    |
|    explained_variance   | 0.371     |
|    learning_rate        | 0.0003    |
|    loss                 | 38.6      |
|    n_updates            | 190       |
|    policy_gradient_loss | -0.00304  |
|    value_loss           | 117       |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 161      |
|    ep_rew_mean     | 90.7     |
| time/              |          |
|    fps             | 1494     |
|    iterations      | 20       |
|    time_elapsed    | 27       |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 165          |
|    ep_rew_mean          | 93.7         |
| time/                   |              |
|    fps                  | 1494         |
|    iterations           | 21           |
|    time_elapsed         | 28           |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0013904616 |
|    clip_fraction        | 0.018        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.689       |
|    explained_variance   | 0.325        |
|    learning_rate        | 0.0003       |
|    loss                 | 120          |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.0012      |
|    value_loss           | 146          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 169          |
|    ep_rew_mean          | 95.7         |
| time/                   |              |
|    fps                  | 1495         |
|    iterations           | 22           |
|    time_elapsed         | 30           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0034690832 |
|    clip_fraction        | 0.0192       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.685       |
|    explained_variance   | 0.498        |
|    learning_rate        | 0.0003       |
|    loss                 | 72.5         |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.00215     |
|    value_loss           | 89           |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 170         |
|    ep_rew_mean          | 97.1        |
| time/                   |             |
|    fps                  | 1495        |
|    iterations           | 23          |
|    time_elapsed         | 31          |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.015719306 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.672      |
|    explained_variance   | 0.413       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.4         |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.00729    |
|    value_loss           | 117         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 170         |
|    ep_rew_mean          | 97.1        |
| time/                   |             |
|    fps                  | 1495        |
|    iterations           | 24          |
|    time_elapsed         | 32          |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.005105312 |
|    clip_fraction        | 0.0559      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.659      |
|    explained_variance   | 0.379       |
|    learning_rate        | 0.0003      |
|    loss                 | 61.4        |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.00407    |
|    value_loss           | 157         |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=126.50 +/- 50.47
Episode length: 170.40 +/- 43.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 170         |
|    mean_reward          | 127         |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.009653839 |
|    clip_fraction        | 0.0498      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.625      |
|    explained_variance   | 0.558       |
|    learning_rate        | 0.0003      |
|    loss                 | 47.1        |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.00506    |
|    value_loss           | 102         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 167      |
|    ep_rew_mean     | 93.2     |
| time/              |          |
|    fps             | 1485     |
|    iterations      | 25       |
|    time_elapsed    | 34       |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 163         |
|    ep_rew_mean          | 89.5        |
| time/                   |             |
|    fps                  | 1485        |
|    iterations           | 26          |
|    time_elapsed         | 35          |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.009489882 |
|    clip_fraction        | 0.0751      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.65       |
|    explained_variance   | 0.575       |
|    learning_rate        | 0.0003      |
|    loss                 | 26.3        |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00403    |
|    value_loss           | 166         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 161          |
|    ep_rew_mean          | 86.3         |
| time/                   |              |
|    fps                  | 1485         |
|    iterations           | 27           |
|    time_elapsed         | 37           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 0.0052245623 |
|    clip_fraction        | 0.0256       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.672       |
|    explained_variance   | 0.534        |
|    learning_rate        | 0.0003       |
|    loss                 | 82.8         |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.0014      |
|    value_loss           | 173          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 160         |
|    ep_rew_mean          | 87.2        |
| time/                   |             |
|    fps                  | 1486        |
|    iterations           | 28          |
|    time_elapsed         | 38          |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.010308152 |
|    clip_fraction        | 0.0395      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.662      |
|    explained_variance   | 0.676       |
|    learning_rate        | 0.0003      |
|    loss                 | 66.9        |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0018     |
|    value_loss           | 131         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 153          |
|    ep_rew_mean          | 81.3         |
| time/                   |              |
|    fps                  | 1486         |
|    iterations           | 29           |
|    time_elapsed         | 39           |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 0.0075389976 |
|    clip_fraction        | 0.0125       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.659       |
|    explained_variance   | 0.503        |
|    learning_rate        | 0.0003       |
|    loss                 | 162          |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.000419    |
|    value_loss           | 166          |
------------------------------------------
Eval num_timesteps=60000, episode_reward=139.34 +/- 40.70
Episode length: 186.40 +/- 38.31
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 186         |
|    mean_reward          | 139         |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.008399423 |
|    clip_fraction        | 0.0295      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.627      |
|    explained_variance   | 0.716       |
|    learning_rate        | 0.0003      |
|    loss                 | 95.4        |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0015     |
|    value_loss           | 162         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | 75.7     |
| time/              |          |
|    fps             | 1477     |
|    iterations      | 30       |
|    time_elapsed    | 41       |
|    total_timesteps | 61440    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 145        |
|    ep_rew_mean          | 73.4       |
| time/                   |            |
|    fps                  | 1478       |
|    iterations           | 31         |
|    time_elapsed         | 42         |
|    total_timesteps      | 63488      |
| train/                  |            |
|    approx_kl            | 0.00438471 |
|    clip_fraction        | 0.0304     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.585     |
|    explained_variance   | 0.899      |
|    learning_rate        | 0.0003     |
|    loss                 | 50.8       |
|    n_updates            | 300        |
|    policy_gradient_loss | -0.00126   |
|    value_loss           | 52.7       |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 141          |
|    ep_rew_mean          | 70.1         |
| time/                   |              |
|    fps                  | 1479         |
|    iterations           | 32           |
|    time_elapsed         | 44           |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0069180783 |
|    clip_fraction        | 0.0528       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.552       |
|    explained_variance   | 0.913        |
|    learning_rate        | 0.0003       |
|    loss                 | 36.9         |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.00441     |
|    value_loss           | 41.8         |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 145        |
|    ep_rew_mean          | 74.8       |
| time/                   |            |
|    fps                  | 1479       |
|    iterations           | 33         |
|    time_elapsed         | 45         |
|    total_timesteps      | 67584      |
| train/                  |            |
|    approx_kl            | 0.00793398 |
|    clip_fraction        | 0.0562     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.589     |
|    explained_variance   | 0.608      |
|    learning_rate        | 0.0003     |
|    loss                 | 62         |
|    n_updates            | 320        |
|    policy_gradient_loss | -0.00224   |
|    value_loss           | 235        |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 144          |
|    ep_rew_mean          | 75.4         |
| time/                   |              |
|    fps                  | 1479         |
|    iterations           | 34           |
|    time_elapsed         | 47           |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 0.0028853114 |
|    clip_fraction        | 0.0256       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.548       |
|    explained_variance   | 0.908        |
|    learning_rate        | 0.0003       |
|    loss                 | 7.26         |
|    n_updates            | 330          |
|    policy_gradient_loss | 7.7e-05      |
|    value_loss           | 38.8         |
------------------------------------------
Eval num_timesteps=70000, episode_reward=127.39 +/- 51.52
Episode length: 171.00 +/- 43.69
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 171          |
|    mean_reward          | 127          |
| time/                   |              |
|    total_timesteps      | 70000        |
| train/                  |              |
|    approx_kl            | 0.0015651509 |
|    clip_fraction        | 0.0337       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.533       |
|    explained_variance   | 0.829        |
|    learning_rate        | 0.0003       |
|    loss                 | 25.8         |
|    n_updates            | 340          |
|    policy_gradient_loss | -0.00114     |
|    value_loss           | 101          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 75.8     |
| time/              |          |
|    fps             | 1473     |
|    iterations      | 35       |
|    time_elapsed    | 48       |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 147         |
|    ep_rew_mean          | 79.9        |
| time/                   |             |
|    fps                  | 1474        |
|    iterations           | 36          |
|    time_elapsed         | 50          |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.005965657 |
|    clip_fraction        | 0.0413      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.529      |
|    explained_variance   | 0.87        |
|    learning_rate        | 0.0003      |
|    loss                 | 47.1        |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00149    |
|    value_loss           | 70          |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 147          |
|    ep_rew_mean          | 82.3         |
| time/                   |              |
|    fps                  | 1474         |
|    iterations           | 37           |
|    time_elapsed         | 51           |
|    total_timesteps      | 75776        |
| train/                  |              |
|    approx_kl            | 0.0025337976 |
|    clip_fraction        | 0.0336       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.436       |
|    explained_variance   | 0.897        |
|    learning_rate        | 0.0003       |
|    loss                 | 34.3         |
|    n_updates            | 360          |
|    policy_gradient_loss | 0.000276     |
|    value_loss           | 71.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 147          |
|    ep_rew_mean          | 83.1         |
| time/                   |              |
|    fps                  | 1475         |
|    iterations           | 38           |
|    time_elapsed         | 52           |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 0.0022443172 |
|    clip_fraction        | 0.0421       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.35        |
|    explained_variance   | 0.993        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.3          |
|    n_updates            | 370          |
|    policy_gradient_loss | -0.00241     |
|    value_loss           | 3.1          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 151          |
|    ep_rew_mean          | 87.2         |
| time/                   |              |
|    fps                  | 1475         |
|    iterations           | 39           |
|    time_elapsed         | 54           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 0.0029702224 |
|    clip_fraction        | 0.06         |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.345       |
|    explained_variance   | 0.996        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.4          |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.0049      |
|    value_loss           | 1.6          |
------------------------------------------
Eval num_timesteps=80000, episode_reward=68.04 +/- 70.69
Episode length: 125.80 +/- 54.23
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 126          |
|    mean_reward          | 68           |
| time/                   |              |
|    total_timesteps      | 80000        |
| train/                  |              |
|    approx_kl            | 0.0065327836 |
|    clip_fraction        | 0.0901       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.44        |
|    explained_variance   | 0.933        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.16         |
|    n_updates            | 390          |
|    policy_gradient_loss | -0.00393     |
|    value_loss           | 40.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 151      |
|    ep_rew_mean     | 88.5     |
| time/              |          |
|    fps             | 1471     |
|    iterations      | 40       |
|    time_elapsed    | 55       |
|    total_timesteps | 81920    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 153          |
|    ep_rew_mean          | 90.6         |
| time/                   |              |
|    fps                  | 1472         |
|    iterations           | 41           |
|    time_elapsed         | 57           |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 0.0049742903 |
|    clip_fraction        | 0.024        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.487       |
|    explained_variance   | 0.695        |
|    learning_rate        | 0.0003       |
|    loss                 | 53.3         |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00156     |
|    value_loss           | 182          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 154          |
|    ep_rew_mean          | 92.1         |
| time/                   |              |
|    fps                  | 1472         |
|    iterations           | 42           |
|    time_elapsed         | 58           |
|    total_timesteps      | 86016        |
| train/                  |              |
|    approx_kl            | 0.0038970076 |
|    clip_fraction        | 0.0161       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.429       |
|    explained_variance   | 0.88         |
|    learning_rate        | 0.0003       |
|    loss                 | 9.81         |
|    n_updates            | 410          |
|    policy_gradient_loss | -2.65e-05    |
|    value_loss           | 75           |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 155         |
|    ep_rew_mean          | 94.4        |
| time/                   |             |
|    fps                  | 1473        |
|    iterations           | 43          |
|    time_elapsed         | 59          |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.009261116 |
|    clip_fraction        | 0.0847      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.388      |
|    explained_variance   | 0.993       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.327       |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.0048     |
|    value_loss           | 2.08        |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=122.56 +/- 48.93
Episode length: 169.80 +/- 45.56
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 170          |
|    mean_reward          | 123          |
| time/                   |              |
|    total_timesteps      | 90000        |
| train/                  |              |
|    approx_kl            | 0.0007174564 |
|    clip_fraction        | 0.037        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.303       |
|    explained_variance   | 0.945        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.01         |
|    n_updates            | 430          |
|    policy_gradient_loss | -0.000659    |
|    value_loss           | 41.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 157      |
|    ep_rew_mean     | 97.8     |
| time/              |          |
|    fps             | 1468     |
|    iterations      | 44       |
|    time_elapsed    | 61       |
|    total_timesteps | 90112    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 158          |
|    ep_rew_mean          | 99.3         |
| time/                   |              |
|    fps                  | 1469         |
|    iterations           | 45           |
|    time_elapsed         | 62           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0072056837 |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.371       |
|    explained_variance   | 0.996        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.434        |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00797     |
|    value_loss           | 1.53         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 158          |
|    ep_rew_mean          | 100          |
| time/                   |              |
|    fps                  | 1469         |
|    iterations           | 46           |
|    time_elapsed         | 64           |
|    total_timesteps      | 94208        |
| train/                  |              |
|    approx_kl            | 0.0036597494 |
|    clip_fraction        | 0.0299       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.288       |
|    explained_variance   | 0.903        |
|    learning_rate        | 0.0003       |
|    loss                 | 43.2         |
|    n_updates            | 450          |
|    policy_gradient_loss | -0.000265    |
|    value_loss           | 82.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 160          |
|    ep_rew_mean          | 103          |
| time/                   |              |
|    fps                  | 1470         |
|    iterations           | 47           |
|    time_elapsed         | 65           |
|    total_timesteps      | 96256        |
| train/                  |              |
|    approx_kl            | 0.0056597576 |
|    clip_fraction        | 0.0194       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.41        |
|    explained_variance   | 0.871        |
|    learning_rate        | 0.0003       |
|    loss                 | 17.1         |
|    n_updates            | 460          |
|    policy_gradient_loss | 0.00014      |
|    value_loss           | 81.7         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 158          |
|    ep_rew_mean          | 101          |
| time/                   |              |
|    fps                  | 1470         |
|    iterations           | 48           |
|    time_elapsed         | 66           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 0.0007586886 |
|    clip_fraction        | 0.049        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.306       |
|    explained_variance   | 0.996        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.215        |
|    n_updates            | 470          |
|    policy_gradient_loss | -0.00483     |
|    value_loss           | 2.05         |
------------------------------------------
Eval num_timesteps=100000, episode_reward=157.18 +/- 35.10
Episode length: 201.60 +/- 32.38
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 202          |
|    mean_reward          | 157          |
| time/                   |              |
|    total_timesteps      | 100000       |
| train/                  |              |
|    approx_kl            | 0.0011610913 |
|    clip_fraction        | 0.0249       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.34        |
|    explained_variance   | 0.843        |
|    learning_rate        | 0.0003       |
|    loss                 | 58.5         |
|    n_updates            | 480          |
|    policy_gradient_loss | 0.000549     |
|    value_loss           | 119          |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 157      |
|    ep_rew_mean     | 100      |
| time/              |          |
|    fps             | 1465     |
|    iterations      | 49       |
|    time_elapsed    | 68       |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 155         |
|    ep_rew_mean          | 98.9        |
| time/                   |             |
|    fps                  | 1465        |
|    iterations           | 50          |
|    time_elapsed         | 69          |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.006787707 |
|    clip_fraction        | 0.0253      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.262      |
|    explained_variance   | 0.904       |
|    learning_rate        | 0.0003      |
|    loss                 | 41.9        |
|    n_updates            | 490         |
|    policy_gradient_loss | 0.000251    |
|    value_loss           | 78.1        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 154          |
|    ep_rew_mean          | 96.8         |
| time/                   |              |
|    fps                  | 1465         |
|    iterations           | 51           |
|    time_elapsed         | 71           |
|    total_timesteps      | 104448       |
| train/                  |              |
|    approx_kl            | 0.0031318152 |
|    clip_fraction        | 0.0378       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.351       |
|    explained_variance   | 0.881        |
|    learning_rate        | 0.0003       |
|    loss                 | 23.6         |
|    n_updates            | 500          |
|    policy_gradient_loss | -0.000859    |
|    value_loss           | 78           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 153          |
|    ep_rew_mean          | 96.1         |
| time/                   |              |
|    fps                  | 1466         |
|    iterations           | 52           |
|    time_elapsed         | 72           |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 0.0005519688 |
|    clip_fraction        | 0.0265       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.226       |
|    explained_variance   | 0.951        |
|    learning_rate        | 0.0003       |
|    loss                 | 40.2         |
|    n_updates            | 510          |
|    policy_gradient_loss | 0.000256     |
|    value_loss           | 40.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 154           |
|    ep_rew_mean          | 97            |
| time/                   |               |
|    fps                  | 1467          |
|    iterations           | 53            |
|    time_elapsed         | 73            |
|    total_timesteps      | 108544        |
| train/                  |               |
|    approx_kl            | 0.00081016286 |
|    clip_fraction        | 0.00967       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.267        |
|    explained_variance   | 0.995         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.624         |
|    n_updates            | 520           |
|    policy_gradient_loss | 0.000691      |
|    value_loss           | 1.82          |
-------------------------------------------
Eval num_timesteps=110000, episode_reward=86.73 +/- 61.40
Episode length: 141.00 +/- 49.80
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 141          |
|    mean_reward          | 86.7         |
| time/                   |              |
|    total_timesteps      | 110000       |
| train/                  |              |
|    approx_kl            | 0.0015940863 |
|    clip_fraction        | 0.0182       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.369       |
|    explained_variance   | 0.817        |
|    learning_rate        | 0.0003       |
|    loss                 | 66.5         |
|    n_updates            | 530          |
|    policy_gradient_loss | 0.00129      |
|    value_loss           | 122          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 151      |
|    ep_rew_mean     | 94.8     |
| time/              |          |
|    fps             | 1463     |
|    iterations      | 54       |
|    time_elapsed    | 75       |
|    total_timesteps | 110592   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 152          |
|    ep_rew_mean          | 96.2         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 55           |
|    time_elapsed         | 76           |
|    total_timesteps      | 112640       |
| train/                  |              |
|    approx_kl            | 0.0036147048 |
|    clip_fraction        | 0.0291       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.248       |
|    explained_variance   | 0.897        |
|    learning_rate        | 0.0003       |
|    loss                 | 55.2         |
|    n_updates            | 540          |
|    policy_gradient_loss | 0.00082      |
|    value_loss           | 80           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 150          |
|    ep_rew_mean          | 93.7         |
| time/                   |              |
|    fps                  | 1465         |
|    iterations           | 56           |
|    time_elapsed         | 78           |
|    total_timesteps      | 114688       |
| train/                  |              |
|    approx_kl            | 0.0032208716 |
|    clip_fraction        | 0.0268       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.212       |
|    explained_variance   | 0.951        |
|    learning_rate        | 0.0003       |
|    loss                 | 3.17         |
|    n_updates            | 550          |
|    policy_gradient_loss | -0.00113     |
|    value_loss           | 41.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 152          |
|    ep_rew_mean          | 95.9         |
| time/                   |              |
|    fps                  | 1465         |
|    iterations           | 57           |
|    time_elapsed         | 79           |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 0.0044097556 |
|    clip_fraction        | 0.0515       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.291       |
|    explained_variance   | 0.855        |
|    learning_rate        | 0.0003       |
|    loss                 | 28.3         |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.000924    |
|    value_loss           | 117          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 147         |
|    ep_rew_mean          | 91.5        |
| time/                   |             |
|    fps                  | 1466        |
|    iterations           | 58          |
|    time_elapsed         | 81          |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.007457516 |
|    clip_fraction        | 0.0372      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.27       |
|    explained_variance   | 0.887       |
|    learning_rate        | 0.0003      |
|    loss                 | 9.26        |
|    n_updates            | 570         |
|    policy_gradient_loss | 0.00032     |
|    value_loss           | 80          |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=100.95 +/- 38.57
Episode length: 151.40 +/- 32.40
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 151          |
|    mean_reward          | 101          |
| time/                   |              |
|    total_timesteps      | 120000       |
| train/                  |              |
|    approx_kl            | 0.0017900587 |
|    clip_fraction        | 0.0225       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0856      |
|    explained_variance   | 0.96         |
|    learning_rate        | 0.0003       |
|    loss                 | 15.2         |
|    n_updates            | 580          |
|    policy_gradient_loss | -0.00471     |
|    value_loss           | 36.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | 88.9     |
| time/              |          |
|    fps             | 1463     |
|    iterations      | 59       |
|    time_elapsed    | 82       |
|    total_timesteps | 120832   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 141          |
|    ep_rew_mean          | 85.1         |
| time/                   |              |
|    fps                  | 1463         |
|    iterations           | 60           |
|    time_elapsed         | 83           |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 0.0018241645 |
|    clip_fraction        | 0.0215       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0696      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0631       |
|    n_updates            | 590          |
|    policy_gradient_loss | -0.00418     |
|    value_loss           | 0.55         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 140          |
|    ep_rew_mean          | 85           |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 61           |
|    time_elapsed         | 85           |
|    total_timesteps      | 124928       |
| train/                  |              |
|    approx_kl            | 0.0021587117 |
|    clip_fraction        | 0.0178       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0952      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.164        |
|    n_updates            | 600          |
|    policy_gradient_loss | -0.0012      |
|    value_loss           | 0.616        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 138         |
|    ep_rew_mean          | 82          |
| time/                   |             |
|    fps                  | 1465        |
|    iterations           | 62          |
|    time_elapsed         | 86          |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.004110112 |
|    clip_fraction        | 0.00825     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0321     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0596      |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.00565    |
|    value_loss           | 0.191       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 135          |
|    ep_rew_mean          | 79.3         |
| time/                   |              |
|    fps                  | 1465         |
|    iterations           | 63           |
|    time_elapsed         | 88           |
|    total_timesteps      | 129024       |
| train/                  |              |
|    approx_kl            | 0.0010995653 |
|    clip_fraction        | 0.00283      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0145      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.05         |
|    n_updates            | 620          |
|    policy_gradient_loss | -0.000885    |
|    value_loss           | 0.0699       |
------------------------------------------
Eval num_timesteps=130000, episode_reward=79.95 +/- 2.80
Episode length: 135.40 +/- 2.06
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 135           |
|    mean_reward          | 80            |
| time/                   |               |
|    total_timesteps      | 130000        |
| train/                  |               |
|    approx_kl            | 0.00020415158 |
|    clip_fraction        | 0.00122       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00756      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0268        |
|    n_updates            | 630           |
|    policy_gradient_loss | -0.00123      |
|    value_loss           | 0.076         |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 135      |
|    ep_rew_mean     | 79.8     |
| time/              |          |
|    fps             | 1463     |
|    iterations      | 64       |
|    time_elapsed    | 89       |
|    total_timesteps | 131072   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 136           |
|    ep_rew_mean          | 81            |
| time/                   |               |
|    fps                  | 1463          |
|    iterations           | 65            |
|    time_elapsed         | 90            |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 0.00026814782 |
|    clip_fraction        | 0.00166       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00377      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.00786       |
|    n_updates            | 640           |
|    policy_gradient_loss | -0.00102      |
|    value_loss           | 0.0427        |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 136          |
|    ep_rew_mean          | 81.5         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 66           |
|    time_elapsed         | 92           |
|    total_timesteps      | 135168       |
| train/                  |              |
|    approx_kl            | 8.898991e-05 |
|    clip_fraction        | 0.000439     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00302     |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0361       |
|    n_updates            | 650          |
|    policy_gradient_loss | -0.000389    |
|    value_loss           | 0.0595       |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 133          |
|    ep_rew_mean          | 78.7         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 67           |
|    time_elapsed         | 93           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 0.0013409212 |
|    clip_fraction        | 0.00845      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00867     |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00724      |
|    n_updates            | 660          |
|    policy_gradient_loss | -0.00297     |
|    value_loss           | 0.0367       |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 131         |
|    ep_rew_mean          | 76.5        |
| time/                   |             |
|    fps                  | 1465        |
|    iterations           | 68          |
|    time_elapsed         | 95          |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.004492624 |
|    clip_fraction        | 0.0228      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0645     |
|    explained_variance   | 0.883       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.81        |
|    n_updates            | 670         |
|    policy_gradient_loss | 0.0013      |
|    value_loss           | 102         |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=82.44 +/- 5.55
Episode length: 133.80 +/- 3.97
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 134         |
|    mean_reward          | 82.4        |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.003676134 |
|    clip_fraction        | 0.0299      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0727     |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.5         |
|    n_updates            | 680         |
|    policy_gradient_loss | 0.000255    |
|    value_loss           | 92.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 130      |
|    ep_rew_mean     | 75.4     |
| time/              |          |
|    fps             | 1463     |
|    iterations      | 69       |
|    time_elapsed    | 96       |
|    total_timesteps | 141312   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 130          |
|    ep_rew_mean          | 74.7         |
| time/                   |              |
|    fps                  | 1463         |
|    iterations           | 70           |
|    time_elapsed         | 97           |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 0.0007532075 |
|    clip_fraction        | 0.0241       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0492      |
|    explained_variance   | 0.963        |
|    learning_rate        | 0.0003       |
|    loss                 | 15.2         |
|    n_updates            | 690          |
|    policy_gradient_loss | -0.00438     |
|    value_loss           | 33.3         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 130         |
|    ep_rew_mean          | 74.9        |
| time/                   |             |
|    fps                  | 1464        |
|    iterations           | 71          |
|    time_elapsed         | 99          |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.004658257 |
|    clip_fraction        | 0.0145      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0176     |
|    explained_variance   | 0.997       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.179       |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.00502    |
|    value_loss           | 0.952       |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 129           |
|    ep_rew_mean          | 74.6          |
| time/                   |               |
|    fps                  | 1464          |
|    iterations           | 72            |
|    time_elapsed         | 100           |
|    total_timesteps      | 147456        |
| train/                  |               |
|    approx_kl            | 0.00011891639 |
|    clip_fraction        | 0.000488      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00878      |
|    explained_variance   | 0.999         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0197        |
|    n_updates            | 710           |
|    policy_gradient_loss | -0.000121     |
|    value_loss           | 0.406         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 130          |
|    ep_rew_mean          | 74.7         |
| time/                   |              |
|    fps                  | 1465         |
|    iterations           | 73           |
|    time_elapsed         | 102          |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 0.0006548448 |
|    clip_fraction        | 0.00313      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00761     |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0688       |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.000778    |
|    value_loss           | 0.151        |
------------------------------------------
Eval num_timesteps=150000, episode_reward=80.08 +/- 5.39
Episode length: 132.80 +/- 2.32
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 133        |
|    mean_reward          | 80.1       |
| time/                   |            |
|    total_timesteps      | 150000     |
| train/                  |            |
|    approx_kl            | 0.00149665 |
|    clip_fraction        | 0.00142    |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00423   |
|    explained_variance   | 1          |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00945    |
|    n_updates            | 730        |
|    policy_gradient_loss | -0.00135   |
|    value_loss           | 0.053      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 132      |
|    ep_rew_mean     | 78       |
| time/              |          |
|    fps             | 1462     |
|    iterations      | 74       |
|    time_elapsed    | 103      |
|    total_timesteps | 151552   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 133           |
|    ep_rew_mean          | 78.9          |
| time/                   |               |
|    fps                  | 1463          |
|    iterations           | 75            |
|    time_elapsed         | 104           |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 1.2805685e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00276      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0163        |
|    n_updates            | 740           |
|    policy_gradient_loss | -3.44e-05     |
|    value_loss           | 0.0453        |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 134       |
|    ep_rew_mean          | 80.2      |
| time/                   |           |
|    fps                  | 1464      |
|    iterations           | 76        |
|    time_elapsed         | 106       |
|    total_timesteps      | 155648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00233  |
|    explained_variance   | 1         |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0222    |
|    n_updates            | 750       |
|    policy_gradient_loss | -2.11e-06 |
|    value_loss           | 0.0319    |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 134          |
|    ep_rew_mean          | 80.1         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 77           |
|    time_elapsed         | 107          |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 6.209125e-05 |
|    clip_fraction        | 0.000439     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00162     |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00889      |
|    n_updates            | 760          |
|    policy_gradient_loss | -0.000309    |
|    value_loss           | 0.0362       |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 131         |
|    ep_rew_mean          | 77.4        |
| time/                   |             |
|    fps                  | 1465        |
|    iterations           | 78          |
|    time_elapsed         | 109         |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.001567113 |
|    clip_fraction        | 0.00244     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00459    |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00545     |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.00103    |
|    value_loss           | 0.0312      |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=78.15 +/- 2.58
Episode length: 133.60 +/- 3.01
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 134          |
|    mean_reward          | 78.2         |
| time/                   |              |
|    total_timesteps      | 160000       |
| train/                  |              |
|    approx_kl            | 0.0016202382 |
|    clip_fraction        | 0.0279       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0929      |
|    explained_variance   | 0.847        |
|    learning_rate        | 0.0003       |
|    loss                 | 48.9         |
|    n_updates            | 780          |
|    policy_gradient_loss | 0.000283     |
|    value_loss           | 132          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 129      |
|    ep_rew_mean     | 74.8     |
| time/              |          |
|    fps             | 1463     |
|    iterations      | 79       |
|    time_elapsed    | 110      |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 128         |
|    ep_rew_mean          | 73.8        |
| time/                   |             |
|    fps                  | 1463        |
|    iterations           | 80          |
|    time_elapsed         | 111         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.024414359 |
|    clip_fraction        | 0.0941      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0986     |
|    explained_variance   | 0.842       |
|    learning_rate        | 0.0003      |
|    loss                 | 7.69        |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.00542    |
|    value_loss           | 141         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 128          |
|    ep_rew_mean          | 73.9         |
| time/                   |              |
|    fps                  | 1463         |
|    iterations           | 81           |
|    time_elapsed         | 113          |
|    total_timesteps      | 165888       |
| train/                  |              |
|    approx_kl            | 0.0036217729 |
|    clip_fraction        | 0.0226       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0533      |
|    explained_variance   | 0.964        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.52         |
|    n_updates            | 800          |
|    policy_gradient_loss | 0.00134      |
|    value_loss           | 31.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 128          |
|    ep_rew_mean          | 74.2         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 82           |
|    time_elapsed         | 114          |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 0.0014912278 |
|    clip_fraction        | 0.013        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.021       |
|    explained_variance   | 0.997        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0726       |
|    n_updates            | 810          |
|    policy_gradient_loss | -0.000926    |
|    value_loss           | 1.09         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 128           |
|    ep_rew_mean          | 73.5          |
| time/                   |               |
|    fps                  | 1464          |
|    iterations           | 83            |
|    time_elapsed         | 116           |
|    total_timesteps      | 169984        |
| train/                  |               |
|    approx_kl            | 0.00064939924 |
|    clip_fraction        | 0.00313       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0175       |
|    explained_variance   | 0.999         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0293        |
|    n_updates            | 820           |
|    policy_gradient_loss | -0.00173      |
|    value_loss           | 0.453         |
-------------------------------------------
Eval num_timesteps=170000, episode_reward=82.68 +/- 4.97
Episode length: 135.40 +/- 3.38
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 135         |
|    mean_reward          | 82.7        |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.001177104 |
|    clip_fraction        | 0.00649     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0172     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0102      |
|    n_updates            | 830         |
|    policy_gradient_loss | 0.000658    |
|    value_loss           | 0.106       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 130      |
|    ep_rew_mean     | 75.3     |
| time/              |          |
|    fps             | 1462     |
|    iterations      | 84       |
|    time_elapsed    | 117      |
|    total_timesteps | 172032   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 133          |
|    ep_rew_mean          | 78.4         |
| time/                   |              |
|    fps                  | 1463         |
|    iterations           | 85           |
|    time_elapsed         | 118          |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 0.0032947687 |
|    clip_fraction        | 0.0111       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00734     |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0145       |
|    n_updates            | 840          |
|    policy_gradient_loss | -0.00494     |
|    value_loss           | 0.0463       |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 135           |
|    ep_rew_mean          | 80.5          |
| time/                   |               |
|    fps                  | 1463          |
|    iterations           | 86            |
|    time_elapsed         | 120           |
|    total_timesteps      | 176128        |
| train/                  |               |
|    approx_kl            | 3.0840747e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00268      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0263        |
|    n_updates            | 850           |
|    policy_gradient_loss | -0.000146     |
|    value_loss           | 0.0508        |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 135           |
|    ep_rew_mean          | 80.9          |
| time/                   |               |
|    fps                  | 1464          |
|    iterations           | 87            |
|    time_elapsed         | 121           |
|    total_timesteps      | 178176        |
| train/                  |               |
|    approx_kl            | 0.00012013977 |
|    clip_fraction        | 0.000879      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00161      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0136        |
|    n_updates            | 860           |
|    policy_gradient_loss | -0.000554     |
|    value_loss           | 0.0413        |
-------------------------------------------
Eval num_timesteps=180000, episode_reward=79.52 +/- 3.81
Episode length: 133.60 +/- 2.58
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 134           |
|    mean_reward          | 79.5          |
| time/                   |               |
|    total_timesteps      | 180000        |
| train/                  |               |
|    approx_kl            | 5.0640665e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00132      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0184        |
|    n_updates            | 870           |
|    policy_gradient_loss | -1.81e-05     |
|    value_loss           | 0.0284        |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 135      |
|    ep_rew_mean     | 80.9     |
| time/              |          |
|    fps             | 1462     |
|    iterations      | 88       |
|    time_elapsed    | 123      |
|    total_timesteps | 180224   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 135          |
|    ep_rew_mean          | 81.1         |
| time/                   |              |
|    fps                  | 1463         |
|    iterations           | 89           |
|    time_elapsed         | 124          |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 0.0003595369 |
|    clip_fraction        | 0.000391     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00116     |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0117       |
|    n_updates            | 880          |
|    policy_gradient_loss | -0.000124    |
|    value_loss           | 0.0287       |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 134           |
|    ep_rew_mean          | 80.9          |
| time/                   |               |
|    fps                  | 1463          |
|    iterations           | 90            |
|    time_elapsed         | 125           |
|    total_timesteps      | 184320        |
| train/                  |               |
|    approx_kl            | 0.00023316313 |
|    clip_fraction        | 0.000879      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.000479     |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.00812       |
|    n_updates            | 890           |
|    policy_gradient_loss | -0.000625     |
|    value_loss           | 0.0307        |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 134           |
|    ep_rew_mean          | 80.8          |
| time/                   |               |
|    fps                  | 1463          |
|    iterations           | 91            |
|    time_elapsed         | 127           |
|    total_timesteps      | 186368        |
| train/                  |               |
|    approx_kl            | 4.8603397e-09 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.000538     |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0078        |
|    n_updates            | 900           |
|    policy_gradient_loss | -1.66e-05     |
|    value_loss           | 0.0255        |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 134       |
|    ep_rew_mean          | 80.3      |
| time/                   |           |
|    fps                  | 1464      |
|    iterations           | 92        |
|    time_elapsed         | 128       |
|    total_timesteps      | 188416    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000593 |
|    explained_variance   | 1         |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0136    |
|    n_updates            | 910       |
|    policy_gradient_loss | -1.61e-07 |
|    value_loss           | 0.0259    |
---------------------------------------
Eval num_timesteps=190000, episode_reward=79.92 +/- 4.06
Episode length: 134.00 +/- 3.29
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 134          |
|    mean_reward          | 79.9         |
| time/                   |              |
|    total_timesteps      | 190000       |
| train/                  |              |
|    approx_kl            | 3.000605e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.000715    |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0222       |
|    n_updates            | 920          |
|    policy_gradient_loss | -7.79e-06    |
|    value_loss           | 0.0244       |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 134      |
|    ep_rew_mean     | 80.2     |
| time/              |          |
|    fps             | 1462     |
|    iterations      | 93       |
|    time_elapsed    | 130      |
|    total_timesteps | 190464   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 134           |
|    ep_rew_mean          | 80.2          |
| time/                   |               |
|    fps                  | 1463          |
|    iterations           | 94            |
|    time_elapsed         | 131           |
|    total_timesteps      | 192512        |
| train/                  |               |
|    approx_kl            | 2.3283064e-10 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.000772     |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0058        |
|    n_updates            | 930           |
|    policy_gradient_loss | -2.38e-07     |
|    value_loss           | 0.0228        |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 134         |
|    ep_rew_mean          | 80.4        |
| time/                   |             |
|    fps                  | 1463        |
|    iterations           | 95          |
|    time_elapsed         | 132         |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 5.84354e-05 |
|    clip_fraction        | 0.000439    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.000697   |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0085      |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.000254   |
|    value_loss           | 0.0284      |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 134           |
|    ep_rew_mean          | 80.4          |
| time/                   |               |
|    fps                  | 1463          |
|    iterations           | 96            |
|    time_elapsed         | 134           |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 1.0855729e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.000482     |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.00329       |
|    n_updates            | 950           |
|    policy_gradient_loss | -3.96e-06     |
|    value_loss           | 0.0175        |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 135          |
|    ep_rew_mean          | 81           |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 97           |
|    time_elapsed         | 135          |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 0.0001777147 |
|    clip_fraction        | 0.00303      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00511     |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00651      |
|    n_updates            | 960          |
|    policy_gradient_loss | -0.00062     |
|    value_loss           | 0.0215       |
------------------------------------------
Eval num_timesteps=200000, episode_reward=49.00 +/- 30.65
Episode length: 99.00 +/- 30.65
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 99           |
|    mean_reward          | 49           |
| time/                   |              |
|    total_timesteps      | 200000       |
| train/                  |              |
|    approx_kl            | 0.0006066958 |
|    clip_fraction        | 0.00776      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0134      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00688      |
|    n_updates            | 970          |
|    policy_gradient_loss | 0.00234      |
|    value_loss           | 0.0244       |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 129      |
|    ep_rew_mean     | 74.8     |
| time/              |          |
|    fps             | 1462     |
|    iterations      | 98       |
|    time_elapsed    | 137      |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 123         |
|    ep_rew_mean          | 68.9        |
| time/                   |             |
|    fps                  | 1463        |
|    iterations           | 99          |
|    time_elapsed         | 138         |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.002671794 |
|    clip_fraction        | 0.0609      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.143      |
|    explained_variance   | 0.643       |
|    learning_rate        | 0.0003      |
|    loss                 | 101         |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.000821   |
|    value_loss           | 299         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 118          |
|    ep_rew_mean          | 64.9         |
| time/                   |              |
|    fps                  | 1463         |
|    iterations           | 100          |
|    time_elapsed         | 139          |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 0.0013350528 |
|    clip_fraction        | 0.0107       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.113       |
|    explained_variance   | 0.713        |
|    learning_rate        | 0.0003       |
|    loss                 | 83.8         |
|    n_updates            | 990          |
|    policy_gradient_loss | -0.00134     |
|    value_loss           | 249          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 116           |
|    ep_rew_mean          | 63.2          |
| time/                   |               |
|    fps                  | 1464          |
|    iterations           | 101           |
|    time_elapsed         | 141           |
|    total_timesteps      | 206848        |
| train/                  |               |
|    approx_kl            | 0.00018788979 |
|    clip_fraction        | 0.00747       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0758       |
|    explained_variance   | 0.796         |
|    learning_rate        | 0.0003        |
|    loss                 | 153           |
|    n_updates            | 1000          |
|    policy_gradient_loss | -1.21e-05     |
|    value_loss           | 162           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 106          |
|    ep_rew_mean          | 53.3         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 102          |
|    time_elapsed         | 142          |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 8.990579e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0409      |
|    explained_variance   | 0.907        |
|    learning_rate        | 0.0003       |
|    loss                 | 4.54         |
|    n_updates            | 1010         |
|    policy_gradient_loss | -5.83e-06    |
|    value_loss           | 33.1         |
------------------------------------------
Eval num_timesteps=210000, episode_reward=36.20 +/- 24.46
Episode length: 86.20 +/- 24.46
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 86.2         |
|    mean_reward          | 36.2         |
| time/                   |              |
|    total_timesteps      | 210000       |
| train/                  |              |
|    approx_kl            | 0.0006186424 |
|    clip_fraction        | 0.0162       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.185       |
|    explained_variance   | 0.898        |
|    learning_rate        | 0.0003       |
|    loss                 | 9.02         |
|    n_updates            | 1020         |
|    policy_gradient_loss | -0.000304    |
|    value_loss           | 17.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 108      |
|    ep_rew_mean     | 55.8     |
| time/              |          |
|    fps             | 1463     |
|    iterations      | 103      |
|    time_elapsed    | 144      |
|    total_timesteps | 210944   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 109          |
|    ep_rew_mean          | 57.7         |
| time/                   |              |
|    fps                  | 1463         |
|    iterations           | 104          |
|    time_elapsed         | 145          |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 0.0005948398 |
|    clip_fraction        | 0.00386      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0711      |
|    explained_variance   | 0.968        |
|    learning_rate        | 0.0003       |
|    loss                 | 4.46         |
|    n_updates            | 1030         |
|    policy_gradient_loss | 0.000101     |
|    value_loss           | 10.1         |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 108        |
|    ep_rew_mean          | 56.2       |
| time/                   |            |
|    fps                  | 1464       |
|    iterations           | 105        |
|    time_elapsed         | 146        |
|    total_timesteps      | 215040     |
| train/                  |            |
|    approx_kl            | 0.00109201 |
|    clip_fraction        | 0.00273    |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0565    |
|    explained_variance   | 0.981      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.89       |
|    n_updates            | 1040       |
|    policy_gradient_loss | 0.000384   |
|    value_loss           | 7.25       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 109         |
|    ep_rew_mean          | 56          |
| time/                   |             |
|    fps                  | 1464        |
|    iterations           | 106         |
|    time_elapsed         | 148         |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.003965077 |
|    clip_fraction        | 0.0443      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.156      |
|    explained_variance   | 0.984       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.22        |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.00237    |
|    value_loss           | 9.49        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 112          |
|    ep_rew_mean          | 59           |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 107          |
|    time_elapsed         | 149          |
|    total_timesteps      | 219136       |
| train/                  |              |
|    approx_kl            | 0.0010591096 |
|    clip_fraction        | 0.0323       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.109       |
|    explained_variance   | 0.989        |
|    learning_rate        | 0.0003       |
|    loss                 | 2.61         |
|    n_updates            | 1060         |
|    policy_gradient_loss | -0.00521     |
|    value_loss           | 9.01         |
------------------------------------------
Eval num_timesteps=220000, episode_reward=58.60 +/- 29.59
Episode length: 108.60 +/- 29.59
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 109          |
|    mean_reward          | 58.6         |
| time/                   |              |
|    total_timesteps      | 220000       |
| train/                  |              |
|    approx_kl            | 0.0013830699 |
|    clip_fraction        | 0.0232       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0873      |
|    explained_variance   | 0.987        |
|    learning_rate        | 0.0003       |
|    loss                 | 5.26         |
|    n_updates            | 1070         |
|    policy_gradient_loss | -0.00642     |
|    value_loss           | 11.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 115      |
|    ep_rew_mean     | 62.3     |
| time/              |          |
|    fps             | 1463     |
|    iterations      | 108      |
|    time_elapsed    | 151      |
|    total_timesteps | 221184   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 118          |
|    ep_rew_mean          | 64.3         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 109          |
|    time_elapsed         | 152          |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 0.0022770914 |
|    clip_fraction        | 0.0417       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.122       |
|    explained_variance   | 0.983        |
|    learning_rate        | 0.0003       |
|    loss                 | 7.01         |
|    n_updates            | 1080         |
|    policy_gradient_loss | -0.0102      |
|    value_loss           | 15.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 119          |
|    ep_rew_mean          | 65.4         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 110          |
|    time_elapsed         | 153          |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 0.0016525434 |
|    clip_fraction        | 0.0269       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0755      |
|    explained_variance   | 0.988        |
|    learning_rate        | 0.0003       |
|    loss                 | 10.4         |
|    n_updates            | 1090         |
|    policy_gradient_loss | -0.00569     |
|    value_loss           | 9.62         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 124          |
|    ep_rew_mean          | 70.1         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 111          |
|    time_elapsed         | 155          |
|    total_timesteps      | 227328       |
| train/                  |              |
|    approx_kl            | 0.0007256572 |
|    clip_fraction        | 0.00684      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.014       |
|    explained_variance   | 0.997        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0469       |
|    n_updates            | 1100         |
|    policy_gradient_loss | 0.00267      |
|    value_loss           | 0.449        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 127          |
|    ep_rew_mean          | 73           |
| time/                   |              |
|    fps                  | 1465         |
|    iterations           | 112          |
|    time_elapsed         | 156          |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 0.0005854473 |
|    clip_fraction        | 0.0084       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0157      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0365       |
|    n_updates            | 1110         |
|    policy_gradient_loss | -3.19e-05    |
|    value_loss           | 0.465        |
------------------------------------------
Eval num_timesteps=230000, episode_reward=82.08 +/- 4.60
Episode length: 134.80 +/- 1.72
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 135          |
|    mean_reward          | 82.1         |
| time/                   |              |
|    total_timesteps      | 230000       |
| train/                  |              |
|    approx_kl            | 9.418206e-05 |
|    clip_fraction        | 0.00161      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00409     |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0124       |
|    n_updates            | 1120         |
|    policy_gradient_loss | -0.000689    |
|    value_loss           | 0.061        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 129      |
|    ep_rew_mean     | 74.7     |
| time/              |          |
|    fps             | 1463     |
|    iterations      | 113      |
|    time_elapsed    | 158      |
|    total_timesteps | 231424   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 132          |
|    ep_rew_mean          | 78           |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 114          |
|    time_elapsed         | 159          |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 0.0009522535 |
|    clip_fraction        | 0.00278      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00649     |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0167       |
|    n_updates            | 1130         |
|    policy_gradient_loss | -0.000582    |
|    value_loss           | 0.0589       |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 134           |
|    ep_rew_mean          | 79.8          |
| time/                   |               |
|    fps                  | 1464          |
|    iterations           | 115           |
|    time_elapsed         | 160           |
|    total_timesteps      | 235520        |
| train/                  |               |
|    approx_kl            | 1.5372992e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00195      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0178        |
|    n_updates            | 1140          |
|    policy_gradient_loss | -0.000458     |
|    value_loss           | 0.039         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 134          |
|    ep_rew_mean          | 80.8         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 116          |
|    time_elapsed         | 162          |
|    total_timesteps      | 237568       |
| train/                  |              |
|    approx_kl            | 1.458393e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00162     |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0151       |
|    n_updates            | 1150         |
|    policy_gradient_loss | -7.36e-06    |
|    value_loss           | 0.0322       |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 134           |
|    ep_rew_mean          | 80.8          |
| time/                   |               |
|    fps                  | 1465          |
|    iterations           | 117           |
|    time_elapsed         | 163           |
|    total_timesteps      | 239616        |
| train/                  |               |
|    approx_kl            | 0.00063409365 |
|    clip_fraction        | 0.00083       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00138      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0096        |
|    n_updates            | 1160          |
|    policy_gradient_loss | -0.000148     |
|    value_loss           | 0.0215        |
-------------------------------------------
Eval num_timesteps=240000, episode_reward=80.52 +/- 2.93
Episode length: 134.60 +/- 1.85
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 135           |
|    mean_reward          | 80.5          |
| time/                   |               |
|    total_timesteps      | 240000        |
| train/                  |               |
|    approx_kl            | 0.00011242431 |
|    clip_fraction        | 0.000439      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00121      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0106        |
|    n_updates            | 1170          |
|    policy_gradient_loss | -0.000321     |
|    value_loss           | 0.0286        |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 134      |
|    ep_rew_mean     | 80.7     |
| time/              |          |
|    fps             | 1463     |
|    iterations      | 118      |
|    time_elapsed    | 165      |
|    total_timesteps | 241664   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 134           |
|    ep_rew_mean          | 80.9          |
| time/                   |               |
|    fps                  | 1464          |
|    iterations           | 119           |
|    time_elapsed         | 166           |
|    total_timesteps      | 243712        |
| train/                  |               |
|    approx_kl            | 1.6152626e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00145      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.00945       |
|    n_updates            | 1180          |
|    policy_gradient_loss | 7.96e-07      |
|    value_loss           | 0.0254        |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 134         |
|    ep_rew_mean          | 80.2        |
| time/                   |             |
|    fps                  | 1464        |
|    iterations           | 120         |
|    time_elapsed         | 167         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.000679428 |
|    clip_fraction        | 0.00396     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00576    |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00745     |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.00107    |
|    value_loss           | 0.0209      |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 134          |
|    ep_rew_mean          | 80.2         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 121          |
|    time_elapsed         | 169          |
|    total_timesteps      | 247808       |
| train/                  |              |
|    approx_kl            | 0.0015370175 |
|    clip_fraction        | 0.00894      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00828     |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0324       |
|    n_updates            | 1200         |
|    policy_gradient_loss | -0.0013      |
|    value_loss           | 0.0195       |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 134           |
|    ep_rew_mean          | 79.9          |
| time/                   |               |
|    fps                  | 1464          |
|    iterations           | 122           |
|    time_elapsed         | 170           |
|    total_timesteps      | 249856        |
| train/                  |               |
|    approx_kl            | 1.3030891e-05 |
|    clip_fraction        | 0.00127       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00486      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0108        |
|    n_updates            | 1210          |
|    policy_gradient_loss | 0.00049       |
|    value_loss           | 0.0245        |
-------------------------------------------
Eval num_timesteps=250000, episode_reward=83.44 +/- 3.90
Episode length: 134.80 +/- 3.71
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 135           |
|    mean_reward          | 83.4          |
| time/                   |               |
|    total_timesteps      | 250000        |
| train/                  |               |
|    approx_kl            | 0.00026474358 |
|    clip_fraction        | 0.00269       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00826      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0105        |
|    n_updates            | 1220          |
|    policy_gradient_loss | -0.000321     |
|    value_loss           | 0.0204        |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 134      |
|    ep_rew_mean     | 79.6     |
| time/              |          |
|    fps             | 1463     |
|    iterations      | 123      |
|    time_elapsed    | 172      |
|    total_timesteps | 251904   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 133          |
|    ep_rew_mean          | 79.4         |
| time/                   |              |
|    fps                  | 1463         |
|    iterations           | 124          |
|    time_elapsed         | 173          |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 7.275873e-05 |
|    clip_fraction        | 0.00181      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00584     |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0134       |
|    n_updates            | 1230         |
|    policy_gradient_loss | 0.000192     |
|    value_loss           | 0.0152       |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 134           |
|    ep_rew_mean          | 79.5          |
| time/                   |               |
|    fps                  | 1464          |
|    iterations           | 125           |
|    time_elapsed         | 174           |
|    total_timesteps      | 256000        |
| train/                  |               |
|    approx_kl            | 0.00017659567 |
|    clip_fraction        | 0.002         |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00579      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0107        |
|    n_updates            | 1240          |
|    policy_gradient_loss | -2.28e-05     |
|    value_loss           | 0.0215        |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 134           |
|    ep_rew_mean          | 79.8          |
| time/                   |               |
|    fps                  | 1464          |
|    iterations           | 126           |
|    time_elapsed         | 176           |
|    total_timesteps      | 258048        |
| train/                  |               |
|    approx_kl            | 2.0983949e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00217      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.006         |
|    n_updates            | 1250          |
|    policy_gradient_loss | -0.000276     |
|    value_loss           | 0.0216        |
-------------------------------------------
Eval num_timesteps=260000, episode_reward=78.75 +/- 4.34
Episode length: 134.20 +/- 2.56
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 134           |
|    mean_reward          | 78.8          |
| time/                   |               |
|    total_timesteps      | 260000        |
| train/                  |               |
|    approx_kl            | 5.2735413e-05 |
|    clip_fraction        | 0.000439      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00226      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0148        |
|    n_updates            | 1260          |
|    policy_gradient_loss | -0.000159     |
|    value_loss           | 0.0177        |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 134      |
|    ep_rew_mean     | 80       |
| time/              |          |
|    fps             | 1463     |
|    iterations      | 127      |
|    time_elapsed    | 177      |
|    total_timesteps | 260096   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 134          |
|    ep_rew_mean          | 80.4         |
| time/                   |              |
|    fps                  | 1463         |
|    iterations           | 128          |
|    time_elapsed         | 179          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0013338777 |
|    clip_fraction        | 0.00537      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00656     |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00641      |
|    n_updates            | 1270         |
|    policy_gradient_loss | -0.00191     |
|    value_loss           | 0.0189       |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 135          |
|    ep_rew_mean          | 80.7         |
| time/                   |              |
|    fps                  | 1463         |
|    iterations           | 129          |
|    time_elapsed         | 180          |
|    total_timesteps      | 264192       |
| train/                  |              |
|    approx_kl            | 0.0003268295 |
|    clip_fraction        | 0.00615      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0117      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0107       |
|    n_updates            | 1280         |
|    policy_gradient_loss | 7.34e-05     |
|    value_loss           | 0.018        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 135          |
|    ep_rew_mean          | 80.7         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 130          |
|    time_elapsed         | 181          |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 0.0011710994 |
|    clip_fraction        | 0.00981      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0178      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0108      |
|    n_updates            | 1290         |
|    policy_gradient_loss | 0.000941     |
|    value_loss           | 0.0159       |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 135          |
|    ep_rew_mean          | 80.7         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 131          |
|    time_elapsed         | 183          |
|    total_timesteps      | 268288       |
| train/                  |              |
|    approx_kl            | 0.0017550224 |
|    clip_fraction        | 0.0151       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0358      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0666       |
|    n_updates            | 1300         |
|    policy_gradient_loss | -0.00116     |
|    value_loss           | 0.45         |
------------------------------------------
Eval num_timesteps=270000, episode_reward=46.80 +/- 26.32
Episode length: 96.80 +/- 26.32
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 96.8        |
|    mean_reward          | 46.8        |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.007909437 |
|    clip_fraction        | 0.0191      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.04       |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.116       |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.00329    |
|    value_loss           | 0.158       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 131      |
|    ep_rew_mean     | 77.5     |
| time/              |          |
|    fps             | 1463     |
|    iterations      | 132      |
|    time_elapsed    | 184      |
|    total_timesteps | 270336   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 126           |
|    ep_rew_mean          | 72.5          |
| time/                   |               |
|    fps                  | 1463          |
|    iterations           | 133           |
|    time_elapsed         | 186           |
|    total_timesteps      | 272384        |
| train/                  |               |
|    approx_kl            | 0.00047088732 |
|    clip_fraction        | 0.0113        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0856       |
|    explained_variance   | 0.911         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.863         |
|    n_updates            | 1320          |
|    policy_gradient_loss | 0.000269      |
|    value_loss           | 13.1          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 126         |
|    ep_rew_mean          | 72.3        |
| time/                   |             |
|    fps                  | 1464        |
|    iterations           | 134         |
|    time_elapsed         | 187         |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.022632191 |
|    clip_fraction        | 0.0166      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.112      |
|    explained_variance   | 0.962       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.584       |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.00488    |
|    value_loss           | 3.34        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 126          |
|    ep_rew_mean          | 72.2         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 135          |
|    time_elapsed         | 188          |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 0.0013674436 |
|    clip_fraction        | 0.0141       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0319      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00887      |
|    n_updates            | 1340         |
|    policy_gradient_loss | -0.00128     |
|    value_loss           | 0.0916       |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 126           |
|    ep_rew_mean          | 72.7          |
| time/                   |               |
|    fps                  | 1464          |
|    iterations           | 136           |
|    time_elapsed         | 190           |
|    total_timesteps      | 278528        |
| train/                  |               |
|    approx_kl            | 0.00016254038 |
|    clip_fraction        | 0.00708       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0186       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0182        |
|    n_updates            | 1350          |
|    policy_gradient_loss | 0.00118       |
|    value_loss           | 0.0297        |
-------------------------------------------
Eval num_timesteps=280000, episode_reward=46.60 +/- 27.09
Episode length: 96.60 +/- 27.09
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 96.6          |
|    mean_reward          | 46.6          |
| time/                   |               |
|    total_timesteps      | 280000        |
| train/                  |               |
|    approx_kl            | 0.00023180788 |
|    clip_fraction        | 0.00278       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00852      |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0137        |
|    n_updates            | 1360          |
|    policy_gradient_loss | -7.3e-05      |
|    value_loss           | 0.0209        |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 126      |
|    ep_rew_mean     | 73.1     |
| time/              |          |
|    fps             | 1463     |
|    iterations      | 137      |
|    time_elapsed    | 191      |
|    total_timesteps | 280576   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 128           |
|    ep_rew_mean          | 74.5          |
| time/                   |               |
|    fps                  | 1464          |
|    iterations           | 138           |
|    time_elapsed         | 193           |
|    total_timesteps      | 282624        |
| train/                  |               |
|    approx_kl            | 0.00024139948 |
|    clip_fraction        | 0.00347       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0149       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.00986       |
|    n_updates            | 1370          |
|    policy_gradient_loss | 0.000436      |
|    value_loss           | 0.02          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 133          |
|    ep_rew_mean          | 79.1         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 139          |
|    time_elapsed         | 194          |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 0.0014399455 |
|    clip_fraction        | 0.00928      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0127      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0112       |
|    n_updates            | 1380         |
|    policy_gradient_loss | -0.00172     |
|    value_loss           | 0.0177       |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 135         |
|    ep_rew_mean          | 81.1        |
| time/                   |             |
|    fps                  | 1464        |
|    iterations           | 140         |
|    time_elapsed         | 195         |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.003673338 |
|    clip_fraction        | 0.0165      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0128     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0244      |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.00378    |
|    value_loss           | 0.0394      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 131         |
|    ep_rew_mean          | 77.7        |
| time/                   |             |
|    fps                  | 1464        |
|    iterations           | 141         |
|    time_elapsed         | 197         |
|    total_timesteps      | 288768      |
| train/                  |             |
|    approx_kl            | 0.005591761 |
|    clip_fraction        | 0.017       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0244     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.037       |
|    n_updates            | 1400        |
|    policy_gradient_loss | 3.15e-06    |
|    value_loss           | 0.0683      |
-----------------------------------------
Eval num_timesteps=290000, episode_reward=63.60 +/- 30.31
Episode length: 113.60 +/- 30.31
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 114         |
|    mean_reward          | 63.6        |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.008666358 |
|    clip_fraction        | 0.00728     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0789     |
|    explained_variance   | 0.945       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.597       |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.00345    |
|    value_loss           | 5.09        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 130      |
|    ep_rew_mean     | 77       |
| time/              |          |
|    fps             | 1464     |
|    iterations      | 142      |
|    time_elapsed    | 198      |
|    total_timesteps | 290816   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 130          |
|    ep_rew_mean          | 76.8         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 143          |
|    time_elapsed         | 199          |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 0.0064559784 |
|    clip_fraction        | 0.0124       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.054       |
|    explained_variance   | 0.988        |
|    learning_rate        | 0.0003       |
|    loss                 | 2.04         |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.00121     |
|    value_loss           | 5.7          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 130          |
|    ep_rew_mean          | 76.6         |
| time/                   |              |
|    fps                  | 1464         |
|    iterations           | 144          |
|    time_elapsed         | 201          |
|    total_timesteps      | 294912       |
| train/                  |              |
|    approx_kl            | 9.572189e-05 |
|    clip_fraction        | 0.00317      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00851     |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.00926      |
|    n_updates            | 1430         |
|    policy_gradient_loss | 0.00108      |
|    value_loss           | 0.0138       |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 130          |
|    ep_rew_mean          | 77           |
| time/                   |              |
|    fps                  | 1465         |
|    iterations           | 145          |
|    time_elapsed         | 202          |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 0.0006576383 |
|    clip_fraction        | 0.00776      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0157      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0088       |
|    n_updates            | 1440         |
|    policy_gradient_loss | 0.00115      |
|    value_loss           | 0.0205       |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 130         |
|    ep_rew_mean          | 76.6        |
| time/                   |             |
|    fps                  | 1465        |
|    iterations           | 146         |
|    time_elapsed         | 204         |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.002743808 |
|    clip_fraction        | 0.014       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0116     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00504    |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.000348   |
|    value_loss           | 0.0172      |
-----------------------------------------
Eval num_timesteps=300000, episode_reward=82.60 +/- 3.14
Episode length: 132.60 +/- 3.14
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 133         |
|    mean_reward          | 82.6        |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.000313496 |
|    clip_fraction        | 0.00796     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0356     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0271      |
|    n_updates            | 1460        |
|    policy_gradient_loss | 0.000785    |
|    value_loss           | 0.0684      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 132      |
|    ep_rew_mean     | 78.5     |
| time/              |          |
|    fps             | 1464     |
|    iterations      | 147      |
|    time_elapsed    | 205      |
|    total_timesteps | 301056   |
---------------------------------

Training complete!
Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-06_21-21-02

