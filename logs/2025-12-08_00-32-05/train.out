Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-08_00-32-05

Map saved at: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-08_00-32-05/map_visualization.png

Using cpu device
Wrapping the env in a DummyVecEnv.
Logging to /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-08_00-32-05/tensorboard/PPO_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 203      |
|    ep_rew_mean     | 130      |
| time/              |          |
|    fps             | 2581     |
|    iterations      | 1        |
|    time_elapsed    | 0        |
|    total_timesteps | 2048     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 195         |
|    ep_rew_mean          | 123         |
| time/                   |             |
|    fps                  | 1860        |
|    iterations           | 2           |
|    time_elapsed         | 2           |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.013159389 |
|    clip_fraction        | 0.0524      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.683      |
|    explained_variance   | -0.0136     |
|    learning_rate        | 0.0003      |
|    loss                 | 24          |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00409    |
|    value_loss           | 48.8        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 188          |
|    ep_rew_mean          | 117          |
| time/                   |              |
|    fps                  | 1729         |
|    iterations           | 3            |
|    time_elapsed         | 3            |
|    total_timesteps      | 6144         |
| train/                  |              |
|    approx_kl            | 0.0067233336 |
|    clip_fraction        | 0.00347      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.665       |
|    explained_variance   | 0.0446       |
|    learning_rate        | 0.0003       |
|    loss                 | 26           |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.00277     |
|    value_loss           | 80           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 180          |
|    ep_rew_mean          | 108          |
| time/                   |              |
|    fps                  | 1670         |
|    iterations           | 4            |
|    time_elapsed         | 4            |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0015248444 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.655       |
|    explained_variance   | 0.101        |
|    learning_rate        | 0.0003       |
|    loss                 | 52.8         |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.000437    |
|    value_loss           | 99.2         |
------------------------------------------
Eval num_timesteps=10000, episode_reward=217.40 +/- 3.45
Episode length: 221.80 +/- 4.07
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 222         |
|    mean_reward          | 217         |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.010322048 |
|    clip_fraction        | 0.039       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.652      |
|    explained_variance   | 0.131       |
|    learning_rate        | 0.0003      |
|    loss                 | 51.4        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00441    |
|    value_loss           | 152         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 185      |
|    ep_rew_mean     | 113      |
| time/              |          |
|    fps             | 1558     |
|    iterations      | 5        |
|    time_elapsed    | 6        |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 188         |
|    ep_rew_mean          | 117         |
| time/                   |             |
|    fps                  | 1551        |
|    iterations           | 6           |
|    time_elapsed         | 7           |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.007436374 |
|    clip_fraction        | 0.0399      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.646      |
|    explained_variance   | -0.0215     |
|    learning_rate        | 0.0003      |
|    loss                 | 27.3        |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0013     |
|    value_loss           | 79.4        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 189         |
|    ep_rew_mean          | 119         |
| time/                   |             |
|    fps                  | 1546        |
|    iterations           | 7           |
|    time_elapsed         | 9           |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.012394318 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.648      |
|    explained_variance   | 0.00442     |
|    learning_rate        | 0.0003      |
|    loss                 | 7.03        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00603    |
|    value_loss           | 65.4        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 190         |
|    ep_rew_mean          | 120         |
| time/                   |             |
|    fps                  | 1541        |
|    iterations           | 8           |
|    time_elapsed         | 10          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.009476882 |
|    clip_fraction        | 0.0287      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.637      |
|    explained_variance   | 0.00635     |
|    learning_rate        | 0.0003      |
|    loss                 | 35.5        |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00269    |
|    value_loss           | 94.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 190         |
|    ep_rew_mean          | 120         |
| time/                   |             |
|    fps                  | 1538        |
|    iterations           | 9           |
|    time_elapsed         | 11          |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.010092407 |
|    clip_fraction        | 0.0951      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.612      |
|    explained_variance   | 0.0161      |
|    learning_rate        | 0.0003      |
|    loss                 | 46.1        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00531    |
|    value_loss           | 115         |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=214.59 +/- 2.85
Episode length: 219.00 +/- 1.79
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 219         |
|    mean_reward          | 215         |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.001280685 |
|    clip_fraction        | 0.000732    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.592      |
|    explained_variance   | 0.0328      |
|    learning_rate        | 0.0003      |
|    loss                 | 48          |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00134    |
|    value_loss           | 129         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 191      |
|    ep_rew_mean     | 121      |
| time/              |          |
|    fps             | 1502     |
|    iterations      | 10       |
|    time_elapsed    | 13       |
|    total_timesteps | 20480    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 195         |
|    ep_rew_mean          | 126         |
| time/                   |             |
|    fps                  | 1503        |
|    iterations           | 11          |
|    time_elapsed         | 14          |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.009352971 |
|    clip_fraction        | 0.0736      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.597      |
|    explained_variance   | -0.0232     |
|    learning_rate        | 0.0003      |
|    loss                 | 104         |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00719    |
|    value_loss           | 89.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 193         |
|    ep_rew_mean          | 125         |
| time/                   |             |
|    fps                  | 1504        |
|    iterations           | 12          |
|    time_elapsed         | 16          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.007380572 |
|    clip_fraction        | 0.0206      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.584      |
|    explained_variance   | 0.0412      |
|    learning_rate        | 0.0003      |
|    loss                 | 22.3        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00359    |
|    value_loss           | 89          |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 197          |
|    ep_rew_mean          | 129          |
| time/                   |              |
|    fps                  | 1504         |
|    iterations           | 13           |
|    time_elapsed         | 17           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0029113372 |
|    clip_fraction        | 0.00137      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.57        |
|    explained_variance   | 0.0637       |
|    learning_rate        | 0.0003       |
|    loss                 | 144          |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00146     |
|    value_loss           | 117          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 196         |
|    ep_rew_mean          | 129         |
| time/                   |             |
|    fps                  | 1504        |
|    iterations           | 14          |
|    time_elapsed         | 19          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.000507943 |
|    clip_fraction        | 0.000781    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.554      |
|    explained_variance   | 0.111       |
|    learning_rate        | 0.0003      |
|    loss                 | 45.8        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00058    |
|    value_loss           | 145         |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=214.95 +/- 3.62
Episode length: 220.00 +/- 2.37
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 220         |
|    mean_reward          | 215         |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.001029838 |
|    clip_fraction        | 0.000684    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.55       |
|    explained_variance   | 0.155       |
|    learning_rate        | 0.0003      |
|    loss                 | 64          |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.000647   |
|    value_loss           | 189         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 198      |
|    ep_rew_mean     | 131      |
| time/              |          |
|    fps             | 1483     |
|    iterations      | 15       |
|    time_elapsed    | 20       |
|    total_timesteps | 30720    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 196           |
|    ep_rew_mean          | 130           |
| time/                   |               |
|    fps                  | 1485          |
|    iterations           | 16            |
|    time_elapsed         | 22            |
|    total_timesteps      | 32768         |
| train/                  |               |
|    approx_kl            | 0.00016489737 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.544        |
|    explained_variance   | 0.168         |
|    learning_rate        | 0.0003        |
|    loss                 | 43.9          |
|    n_updates            | 150           |
|    policy_gradient_loss | -0.00017      |
|    value_loss           | 110           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 198          |
|    ep_rew_mean          | 133          |
| time/                   |              |
|    fps                  | 1487         |
|    iterations           | 17           |
|    time_elapsed         | 23           |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0017331119 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.531       |
|    explained_variance   | 0.195        |
|    learning_rate        | 0.0003       |
|    loss                 | 43.2         |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.000573    |
|    value_loss           | 108          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 197          |
|    ep_rew_mean          | 133          |
| time/                   |              |
|    fps                  | 1488         |
|    iterations           | 18           |
|    time_elapsed         | 24           |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 0.0008130818 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.501       |
|    explained_variance   | 0.244        |
|    learning_rate        | 0.0003       |
|    loss                 | 83.1         |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.000524    |
|    value_loss           | 125          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 198          |
|    ep_rew_mean          | 134          |
| time/                   |              |
|    fps                  | 1489         |
|    iterations           | 19           |
|    time_elapsed         | 26           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 0.0016872298 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.47        |
|    explained_variance   | 0.313        |
|    learning_rate        | 0.0003       |
|    loss                 | 33           |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.000947    |
|    value_loss           | 122          |
------------------------------------------
Eval num_timesteps=40000, episode_reward=220.05 +/- 3.20
Episode length: 224.60 +/- 2.24
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 225          |
|    mean_reward          | 220          |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0007390241 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.44        |
|    explained_variance   | 0.32         |
|    learning_rate        | 0.0003       |
|    loss                 | 86           |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.000877    |
|    value_loss           | 74.4         |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 196      |
|    ep_rew_mean     | 134      |
| time/              |          |
|    fps             | 1473     |
|    iterations      | 20       |
|    time_elapsed    | 27       |
|    total_timesteps | 40960    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 196        |
|    ep_rew_mean          | 136        |
| time/                   |            |
|    fps                  | 1475       |
|    iterations           | 21         |
|    time_elapsed         | 29         |
|    total_timesteps      | 43008      |
| train/                  |            |
|    approx_kl            | 0.00212092 |
|    clip_fraction        | 0.0104     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.444     |
|    explained_variance   | 0.293      |
|    learning_rate        | 0.0003     |
|    loss                 | 107        |
|    n_updates            | 200        |
|    policy_gradient_loss | -0.000735  |
|    value_loss           | 112        |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 197          |
|    ep_rew_mean          | 137          |
| time/                   |              |
|    fps                  | 1476         |
|    iterations           | 22           |
|    time_elapsed         | 30           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0029616547 |
|    clip_fraction        | 0.0105       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.421       |
|    explained_variance   | 0.52         |
|    learning_rate        | 0.0003       |
|    loss                 | 18.7         |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.00237     |
|    value_loss           | 70.6         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 198         |
|    ep_rew_mean          | 140         |
| time/                   |             |
|    fps                  | 1478        |
|    iterations           | 23          |
|    time_elapsed         | 31          |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.002558773 |
|    clip_fraction        | 0.0111      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.382      |
|    explained_variance   | 0.39        |
|    learning_rate        | 0.0003      |
|    loss                 | 32.9        |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.00174    |
|    value_loss           | 105         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 199          |
|    ep_rew_mean          | 143          |
| time/                   |              |
|    fps                  | 1479         |
|    iterations           | 24           |
|    time_elapsed         | 33           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0014723748 |
|    clip_fraction        | 0.00396      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.35        |
|    explained_variance   | 0.435        |
|    learning_rate        | 0.0003       |
|    loss                 | 51.4         |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.0012      |
|    value_loss           | 114          |
------------------------------------------
Eval num_timesteps=50000, episode_reward=218.04 +/- 3.53
Episode length: 224.00 +/- 2.37
--------------------------------------------
| eval/                   |                |
|    mean_ep_length       | 224            |
|    mean_reward          | 218            |
| time/                   |                |
|    total_timesteps      | 50000          |
| train/                  |                |
|    approx_kl            | 0.000115883624 |
|    clip_fraction        | 0              |
|    clip_range           | 0.2            |
|    entropy_loss         | -0.333         |
|    explained_variance   | 0.479          |
|    learning_rate        | 0.0003         |
|    loss                 | 47             |
|    n_updates            | 240            |
|    policy_gradient_loss | -0.000148      |
|    value_loss           | 123            |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 147      |
| time/              |          |
|    fps             | 1468     |
|    iterations      | 25       |
|    time_elapsed    | 34       |
|    total_timesteps | 51200    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 201          |
|    ep_rew_mean          | 148          |
| time/                   |              |
|    fps                  | 1469         |
|    iterations           | 26           |
|    time_elapsed         | 36           |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0020403315 |
|    clip_fraction        | 0.00747      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.311       |
|    explained_variance   | 0.721        |
|    learning_rate        | 0.0003       |
|    loss                 | 9.59         |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.0014      |
|    value_loss           | 26           |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 202         |
|    ep_rew_mean          | 152         |
| time/                   |             |
|    fps                  | 1471        |
|    iterations           | 27          |
|    time_elapsed         | 37          |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.001961588 |
|    clip_fraction        | 0.0231      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.293      |
|    explained_variance   | 0.794       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.23        |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.00273    |
|    value_loss           | 32.8        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 201         |
|    ep_rew_mean          | 154         |
| time/                   |             |
|    fps                  | 1472        |
|    iterations           | 28          |
|    time_elapsed         | 38          |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.001479947 |
|    clip_fraction        | 0.0155      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.231      |
|    explained_variance   | 0.73        |
|    learning_rate        | 0.0003      |
|    loss                 | 8.95        |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.00189    |
|    value_loss           | 55.4        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 201           |
|    ep_rew_mean          | 157           |
| time/                   |               |
|    fps                  | 1474          |
|    iterations           | 29            |
|    time_elapsed         | 40            |
|    total_timesteps      | 59392         |
| train/                  |               |
|    approx_kl            | 0.00094123534 |
|    clip_fraction        | 0.00371       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.229        |
|    explained_variance   | 0.55          |
|    learning_rate        | 0.0003        |
|    loss                 | 76.2          |
|    n_updates            | 280           |
|    policy_gradient_loss | -0.000889     |
|    value_loss           | 138           |
-------------------------------------------
Eval num_timesteps=60000, episode_reward=218.21 +/- 1.91
Episode length: 224.00 +/- 1.41
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 224          |
|    mean_reward          | 218          |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0025974745 |
|    clip_fraction        | 0.0292       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.178       |
|    explained_variance   | 0.782        |
|    learning_rate        | 0.0003       |
|    loss                 | 5.76         |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.00325     |
|    value_loss           | 53.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 162      |
| time/              |          |
|    fps             | 1464     |
|    iterations      | 30       |
|    time_elapsed    | 41       |
|    total_timesteps | 61440    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 205          |
|    ep_rew_mean          | 167          |
| time/                   |              |
|    fps                  | 1466         |
|    iterations           | 31           |
|    time_elapsed         | 43           |
|    total_timesteps      | 63488        |
| train/                  |              |
|    approx_kl            | 0.0015082948 |
|    clip_fraction        | 0.0156       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.171       |
|    explained_variance   | 0.929        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.37         |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.00248     |
|    value_loss           | 12           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 208          |
|    ep_rew_mean          | 173          |
| time/                   |              |
|    fps                  | 1467         |
|    iterations           | 32           |
|    time_elapsed         | 44           |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0024277845 |
|    clip_fraction        | 0.0179       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.127       |
|    explained_variance   | 0.955        |
|    learning_rate        | 0.0003       |
|    loss                 | 5.12         |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.00164     |
|    value_loss           | 10.6         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 211         |
|    ep_rew_mean          | 180         |
| time/                   |             |
|    fps                  | 1468        |
|    iterations           | 33          |
|    time_elapsed         | 46          |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.001137065 |
|    clip_fraction        | 0.0063      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.108      |
|    explained_variance   | 0.97        |
|    learning_rate        | 0.0003      |
|    loss                 | 4.62        |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.00191    |
|    value_loss           | 9.02        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 212          |
|    ep_rew_mean          | 184          |
| time/                   |              |
|    fps                  | 1469         |
|    iterations           | 34           |
|    time_elapsed         | 47           |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 0.0015543695 |
|    clip_fraction        | 0.0169       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0995      |
|    explained_variance   | 0.972        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.24         |
|    n_updates            | 330          |
|    policy_gradient_loss | -0.00241     |
|    value_loss           | 8.1          |
------------------------------------------
Eval num_timesteps=70000, episode_reward=215.85 +/- 2.76
Episode length: 221.00 +/- 2.61
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 221          |
|    mean_reward          | 216          |
| time/                   |              |
|    total_timesteps      | 70000        |
| train/                  |              |
|    approx_kl            | 0.0015612062 |
|    clip_fraction        | 0.019        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0915      |
|    explained_variance   | 0.981        |
|    learning_rate        | 0.0003       |
|    loss                 | 4.23         |
|    n_updates            | 340          |
|    policy_gradient_loss | -0.00205     |
|    value_loss           | 5.77         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 215      |
|    ep_rew_mean     | 190      |
| time/              |          |
|    fps             | 1461     |
|    iterations      | 35       |
|    time_elapsed    | 49       |
|    total_timesteps | 71680    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 216          |
|    ep_rew_mean          | 195          |
| time/                   |              |
|    fps                  | 1462         |
|    iterations           | 36           |
|    time_elapsed         | 50           |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 0.0009735221 |
|    clip_fraction        | 0.013        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0763      |
|    explained_variance   | 0.987        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.98         |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.00155     |
|    value_loss           | 5.17         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 217         |
|    ep_rew_mean          | 199         |
| time/                   |             |
|    fps                  | 1464        |
|    iterations           | 37          |
|    time_elapsed         | 51          |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.003902749 |
|    clip_fraction        | 0.0105      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0676     |
|    explained_variance   | 0.99        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.84        |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.000193   |
|    value_loss           | 4.47        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 204          |
| time/                   |              |
|    fps                  | 1465         |
|    iterations           | 38           |
|    time_elapsed         | 53           |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 0.0012848333 |
|    clip_fraction        | 0.00859      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0618      |
|    explained_variance   | 0.993        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.469        |
|    n_updates            | 370          |
|    policy_gradient_loss | -0.000131    |
|    value_loss           | 2.89         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 208         |
| time/                   |             |
|    fps                  | 1466        |
|    iterations           | 39          |
|    time_elapsed         | 54          |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.003921527 |
|    clip_fraction        | 0.0114      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0747     |
|    explained_variance   | 0.994       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.01        |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.000663   |
|    value_loss           | 2.69        |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=215.07 +/- 3.78
Episode length: 220.80 +/- 2.86
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 221          |
|    mean_reward          | 215          |
| time/                   |              |
|    total_timesteps      | 80000        |
| train/                  |              |
|    approx_kl            | 0.0008109418 |
|    clip_fraction        | 0.00845      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0533      |
|    explained_variance   | 0.995        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.34         |
|    n_updates            | 390          |
|    policy_gradient_loss | -0.00136     |
|    value_loss           | 2.06         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 211      |
| time/              |          |
|    fps             | 1459     |
|    iterations      | 40       |
|    time_elapsed    | 56       |
|    total_timesteps | 81920    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 212           |
| time/                   |               |
|    fps                  | 1460          |
|    iterations           | 41            |
|    time_elapsed         | 57            |
|    total_timesteps      | 83968         |
| train/                  |               |
|    approx_kl            | 0.00039947557 |
|    clip_fraction        | 0.00498       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0461       |
|    explained_variance   | 0.997         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.17          |
|    n_updates            | 400           |
|    policy_gradient_loss | -0.00048      |
|    value_loss           | 1.59          |
-------------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 222            |
|    ep_rew_mean          | 213            |
| time/                   |                |
|    fps                  | 1461           |
|    iterations           | 42             |
|    time_elapsed         | 58             |
|    total_timesteps      | 86016          |
| train/                  |                |
|    approx_kl            | 0.000100886755 |
|    clip_fraction        | 0.00737        |
|    clip_range           | 0.2            |
|    entropy_loss         | -0.0438        |
|    explained_variance   | 0.997          |
|    learning_rate        | 0.0003         |
|    loss                 | 1.02           |
|    n_updates            | 410            |
|    policy_gradient_loss | -0.000473      |
|    value_loss           | 1.3            |
--------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 213           |
| time/                   |               |
|    fps                  | 1462          |
|    iterations           | 43            |
|    time_elapsed         | 60            |
|    total_timesteps      | 88064         |
| train/                  |               |
|    approx_kl            | 0.00024019956 |
|    clip_fraction        | 0.00513       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.046        |
|    explained_variance   | 0.998         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.558         |
|    n_updates            | 420           |
|    policy_gradient_loss | -0.000714     |
|    value_loss           | 1.19          |
-------------------------------------------
Eval num_timesteps=90000, episode_reward=216.79 +/- 3.94
Episode length: 221.40 +/- 2.87
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 221          |
|    mean_reward          | 217          |
| time/                   |              |
|    total_timesteps      | 90000        |
| train/                  |              |
|    approx_kl            | 0.0001403935 |
|    clip_fraction        | 0.00332      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0419      |
|    explained_variance   | 0.998        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.302        |
|    n_updates            | 430          |
|    policy_gradient_loss | -0.000504    |
|    value_loss           | 1.02         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 214      |
| time/              |          |
|    fps             | 1456     |
|    iterations      | 44       |
|    time_elapsed    | 61       |
|    total_timesteps | 90112    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 214          |
| time/                   |              |
|    fps                  | 1458         |
|    iterations           | 45           |
|    time_elapsed         | 63           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0007079133 |
|    clip_fraction        | 0.00903      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0481      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.272        |
|    n_updates            | 440          |
|    policy_gradient_loss | 0.000119     |
|    value_loss           | 0.803        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 215          |
| time/                   |              |
|    fps                  | 1459         |
|    iterations           | 46           |
|    time_elapsed         | 64           |
|    total_timesteps      | 94208        |
| train/                  |              |
|    approx_kl            | 0.0015030463 |
|    clip_fraction        | 0.0203       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0458      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0384       |
|    n_updates            | 450          |
|    policy_gradient_loss | -0.000887    |
|    value_loss           | 0.554        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 215         |
| time/                   |             |
|    fps                  | 1460        |
|    iterations           | 47          |
|    time_elapsed         | 65          |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.002734416 |
|    clip_fraction        | 0.0248      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0488     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.193       |
|    n_updates            | 460         |
|    policy_gradient_loss | 0.00176     |
|    value_loss           | 0.397       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 215          |
| time/                   |              |
|    fps                  | 1461         |
|    iterations           | 48           |
|    time_elapsed         | 67           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 0.0007836526 |
|    clip_fraction        | 0.00908      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0487      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.15         |
|    n_updates            | 470          |
|    policy_gradient_loss | -0.00357     |
|    value_loss           | 0.567        |
------------------------------------------
Eval num_timesteps=100000, episode_reward=215.13 +/- 3.42
Episode length: 221.00 +/- 2.28
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 221          |
|    mean_reward          | 215          |
| time/                   |              |
|    total_timesteps      | 100000       |
| train/                  |              |
|    approx_kl            | 0.0020982022 |
|    clip_fraction        | 0.0226       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0421      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.109        |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.000425    |
|    value_loss           | 0.322        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 215      |
| time/              |          |
|    fps             | 1456     |
|    iterations      | 49       |
|    time_elapsed    | 68       |
|    total_timesteps | 100352   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 215           |
| time/                   |               |
|    fps                  | 1457          |
|    iterations           | 50            |
|    time_elapsed         | 70            |
|    total_timesteps      | 102400        |
| train/                  |               |
|    approx_kl            | 0.00047005102 |
|    clip_fraction        | 0.00977       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0386       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0934        |
|    n_updates            | 490           |
|    policy_gradient_loss | 0.00032       |
|    value_loss           | 0.255         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 215          |
| time/                   |              |
|    fps                  | 1458         |
|    iterations           | 51           |
|    time_elapsed         | 71           |
|    total_timesteps      | 104448       |
| train/                  |              |
|    approx_kl            | 0.0017018728 |
|    clip_fraction        | 0.0189       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0694      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.212        |
|    n_updates            | 500          |
|    policy_gradient_loss | -0.00206     |
|    value_loss           | 0.384        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 220          |
|    ep_rew_mean          | 213          |
| time/                   |              |
|    fps                  | 1459         |
|    iterations           | 52           |
|    time_elapsed         | 72           |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 0.0010190399 |
|    clip_fraction        | 0.00933      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0538      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.171        |
|    n_updates            | 510          |
|    policy_gradient_loss | -7.52e-05    |
|    value_loss           | 0.249        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 220          |
|    ep_rew_mean          | 213          |
| time/                   |              |
|    fps                  | 1460         |
|    iterations           | 53           |
|    time_elapsed         | 74           |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 0.0009174218 |
|    clip_fraction        | 0.0062       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0487      |
|    explained_variance   | 0.884        |
|    learning_rate        | 0.0003       |
|    loss                 | 107          |
|    n_updates            | 520          |
|    policy_gradient_loss | -0.000882    |
|    value_loss           | 62.5         |
------------------------------------------
Eval num_timesteps=110000, episode_reward=215.33 +/- 5.03
Episode length: 220.40 +/- 3.56
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 220          |
|    mean_reward          | 215          |
| time/                   |              |
|    total_timesteps      | 110000       |
| train/                  |              |
|    approx_kl            | 0.0008805898 |
|    clip_fraction        | 0.0128       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0546      |
|    explained_variance   | 0.998        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.065        |
|    n_updates            | 530          |
|    policy_gradient_loss | -4.83e-05    |
|    value_loss           | 0.227        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 219      |
|    ep_rew_mean     | 212      |
| time/              |          |
|    fps             | 1455     |
|    iterations      | 54       |
|    time_elapsed    | 75       |
|    total_timesteps | 110592   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 219           |
|    ep_rew_mean          | 212           |
| time/                   |               |
|    fps                  | 1456          |
|    iterations           | 55            |
|    time_elapsed         | 77            |
|    total_timesteps      | 112640        |
| train/                  |               |
|    approx_kl            | 0.00072127645 |
|    clip_fraction        | 0.00454       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0518       |
|    explained_variance   | 0.909         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.906         |
|    n_updates            | 540           |
|    policy_gradient_loss | -0.000237     |
|    value_loss           | 42.1          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 212          |
| time/                   |              |
|    fps                  | 1457         |
|    iterations           | 56           |
|    time_elapsed         | 78           |
|    total_timesteps      | 114688       |
| train/                  |              |
|    approx_kl            | 0.0005241125 |
|    clip_fraction        | 0.00518      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.049       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.107        |
|    n_updates            | 550          |
|    policy_gradient_loss | -0.000145    |
|    value_loss           | 0.191        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 212          |
| time/                   |              |
|    fps                  | 1458         |
|    iterations           | 57           |
|    time_elapsed         | 80           |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 0.0007104947 |
|    clip_fraction        | 0.00752      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0502      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.105        |
|    n_updates            | 560          |
|    policy_gradient_loss | 4.47e-05     |
|    value_loss           | 0.241        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 219         |
|    ep_rew_mean          | 212         |
| time/                   |             |
|    fps                  | 1459        |
|    iterations           | 58          |
|    time_elapsed         | 81          |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.001806339 |
|    clip_fraction        | 0.0175      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.058      |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0758      |
|    n_updates            | 570         |
|    policy_gradient_loss | 0.000979    |
|    value_loss           | 0.192       |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=216.21 +/- 3.77
Episode length: 220.80 +/- 3.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 221         |
|    mean_reward          | 216         |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.002314453 |
|    clip_fraction        | 0.0183      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0422     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0334      |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.00195    |
|    value_loss           | 0.319       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 219      |
|    ep_rew_mean     | 212      |
| time/              |          |
|    fps             | 1455     |
|    iterations      | 59       |
|    time_elapsed    | 83       |
|    total_timesteps | 120832   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 212          |
| time/                   |              |
|    fps                  | 1456         |
|    iterations           | 60           |
|    time_elapsed         | 84           |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 0.0037169582 |
|    clip_fraction        | 0.0114       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0458      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.127        |
|    n_updates            | 590          |
|    policy_gradient_loss | -0.000292    |
|    value_loss           | 0.232        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 212          |
| time/                   |              |
|    fps                  | 1457         |
|    iterations           | 61           |
|    time_elapsed         | 85           |
|    total_timesteps      | 124928       |
| train/                  |              |
|    approx_kl            | 0.0013773905 |
|    clip_fraction        | 0.0062       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0568      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.049        |
|    n_updates            | 600          |
|    policy_gradient_loss | 0.00011      |
|    value_loss           | 0.228        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 212          |
| time/                   |              |
|    fps                  | 1458         |
|    iterations           | 62           |
|    time_elapsed         | 87           |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 0.0025895787 |
|    clip_fraction        | 0.0153       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.038       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.103        |
|    n_updates            | 610          |
|    policy_gradient_loss | -0.000708    |
|    value_loss           | 0.248        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 220           |
|    ep_rew_mean          | 214           |
| time/                   |               |
|    fps                  | 1458          |
|    iterations           | 63            |
|    time_elapsed         | 88            |
|    total_timesteps      | 129024        |
| train/                  |               |
|    approx_kl            | 0.00021766058 |
|    clip_fraction        | 0.00811       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0353       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0438        |
|    n_updates            | 620           |
|    policy_gradient_loss | 0.000627      |
|    value_loss           | 0.216         |
-------------------------------------------
Eval num_timesteps=130000, episode_reward=216.08 +/- 4.68
Episode length: 221.80 +/- 4.31
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 222           |
|    mean_reward          | 216           |
| time/                   |               |
|    total_timesteps      | 130000        |
| train/                  |               |
|    approx_kl            | 0.00012086856 |
|    clip_fraction        | 0.00425       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0384       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.23          |
|    n_updates            | 630           |
|    policy_gradient_loss | -7.13e-05     |
|    value_loss           | 0.429         |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 220      |
|    ep_rew_mean     | 214      |
| time/              |          |
|    fps             | 1454     |
|    iterations      | 64       |
|    time_elapsed    | 90       |
|    total_timesteps | 131072   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1455          |
|    iterations           | 65            |
|    time_elapsed         | 91            |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 0.00015790512 |
|    clip_fraction        | 0.00605       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.037        |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0469        |
|    n_updates            | 640           |
|    policy_gradient_loss | 0.000677      |
|    value_loss           | 0.106         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1456         |
|    iterations           | 66           |
|    time_elapsed         | 92           |
|    total_timesteps      | 135168       |
| train/                  |              |
|    approx_kl            | 0.0006858922 |
|    clip_fraction        | 0.0119       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0313      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0173       |
|    n_updates            | 650          |
|    policy_gradient_loss | -0.00103     |
|    value_loss           | 0.132        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1457         |
|    iterations           | 67           |
|    time_elapsed         | 94           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 0.0003524166 |
|    clip_fraction        | 0.0135       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0281      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.117        |
|    n_updates            | 660          |
|    policy_gradient_loss | 0.00412      |
|    value_loss           | 0.189        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1458          |
|    iterations           | 68            |
|    time_elapsed         | 95            |
|    total_timesteps      | 139264        |
| train/                  |               |
|    approx_kl            | 0.00015687545 |
|    clip_fraction        | 0.00459       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0279       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.187         |
|    n_updates            | 670           |
|    policy_gradient_loss | -0.000477     |
|    value_loss           | 0.211         |
-------------------------------------------
Eval num_timesteps=140000, episode_reward=214.24 +/- 2.06
Episode length: 219.80 +/- 1.47
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 220          |
|    mean_reward          | 214          |
| time/                   |              |
|    total_timesteps      | 140000       |
| train/                  |              |
|    approx_kl            | 0.0002721231 |
|    clip_fraction        | 0.00332      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0296      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0946       |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.000175    |
|    value_loss           | 0.202        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 215      |
| time/              |          |
|    fps             | 1454     |
|    iterations      | 69       |
|    time_elapsed    | 97       |
|    total_timesteps | 141312   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 215           |
| time/                   |               |
|    fps                  | 1455          |
|    iterations           | 70            |
|    time_elapsed         | 98            |
|    total_timesteps      | 143360        |
| train/                  |               |
|    approx_kl            | 0.00062750647 |
|    clip_fraction        | 0.0061        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0298       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0836        |
|    n_updates            | 690           |
|    policy_gradient_loss | -0.00202      |
|    value_loss           | 0.25          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1456         |
|    iterations           | 71           |
|    time_elapsed         | 99           |
|    total_timesteps      | 145408       |
| train/                  |              |
|    approx_kl            | 0.0003080843 |
|    clip_fraction        | 0.00513      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0253      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.123        |
|    n_updates            | 700          |
|    policy_gradient_loss | 2.82e-05     |
|    value_loss           | 0.16         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1457         |
|    iterations           | 72           |
|    time_elapsed         | 101          |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 0.0004206522 |
|    clip_fraction        | 0.00415      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0297      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0434       |
|    n_updates            | 710          |
|    policy_gradient_loss | -0.000788    |
|    value_loss           | 0.331        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1457          |
|    iterations           | 73            |
|    time_elapsed         | 102           |
|    total_timesteps      | 149504        |
| train/                  |               |
|    approx_kl            | 0.00032085285 |
|    clip_fraction        | 0.004         |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.022        |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.341         |
|    n_updates            | 720           |
|    policy_gradient_loss | -0.000825     |
|    value_loss           | 0.489         |
-------------------------------------------
Eval num_timesteps=150000, episode_reward=216.89 +/- 3.76
Episode length: 222.00 +/- 3.16
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 222         |
|    mean_reward          | 217         |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.000234241 |
|    clip_fraction        | 0.00356     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0246     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.128       |
|    n_updates            | 730         |
|    policy_gradient_loss | 0.000102    |
|    value_loss           | 0.18        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 216      |
| time/              |          |
|    fps             | 1454     |
|    iterations      | 74       |
|    time_elapsed    | 104      |
|    total_timesteps | 151552   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1455          |
|    iterations           | 75            |
|    time_elapsed         | 105           |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 0.00042392587 |
|    clip_fraction        | 0.00513       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0208       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.138         |
|    n_updates            | 740           |
|    policy_gradient_loss | 0.00034       |
|    value_loss           | 0.212         |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 216         |
| time/                   |             |
|    fps                  | 1455        |
|    iterations           | 76          |
|    time_elapsed         | 106         |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.006498687 |
|    clip_fraction        | 0.0225      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0368     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0325      |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.00163    |
|    value_loss           | 0.178       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1456         |
|    iterations           | 77           |
|    time_elapsed         | 108          |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 0.0033118348 |
|    clip_fraction        | 0.00703      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0377      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0973       |
|    n_updates            | 760          |
|    policy_gradient_loss | -0.000177    |
|    value_loss           | 0.102        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1457         |
|    iterations           | 78           |
|    time_elapsed         | 109          |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 0.0011893893 |
|    clip_fraction        | 0.00947      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0264      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0396       |
|    n_updates            | 770          |
|    policy_gradient_loss | 9.15e-05     |
|    value_loss           | 0.144        |
------------------------------------------
Eval num_timesteps=160000, episode_reward=216.45 +/- 2.15
Episode length: 221.60 +/- 1.96
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 222          |
|    mean_reward          | 216          |
| time/                   |              |
|    total_timesteps      | 160000       |
| train/                  |              |
|    approx_kl            | 0.0005457324 |
|    clip_fraction        | 0.00688      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0213      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0362       |
|    n_updates            | 780          |
|    policy_gradient_loss | -0.000169    |
|    value_loss           | 0.128        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 216      |
| time/              |          |
|    fps             | 1453     |
|    iterations      | 79       |
|    time_elapsed    | 111      |
|    total_timesteps | 161792   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1454         |
|    iterations           | 80           |
|    time_elapsed         | 112          |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 0.0005472371 |
|    clip_fraction        | 0.0063       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0219      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0158       |
|    n_updates            | 790          |
|    policy_gradient_loss | -0.00124     |
|    value_loss           | 0.0853       |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1455          |
|    iterations           | 81            |
|    time_elapsed         | 113           |
|    total_timesteps      | 165888        |
| train/                  |               |
|    approx_kl            | 0.00034073513 |
|    clip_fraction        | 0.00913       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0175       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0837        |
|    n_updates            | 800           |
|    policy_gradient_loss | 0.000381      |
|    value_loss           | 0.119         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1456          |
|    iterations           | 82            |
|    time_elapsed         | 115           |
|    total_timesteps      | 167936        |
| train/                  |               |
|    approx_kl            | 0.00027852634 |
|    clip_fraction        | 0.00591       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0199       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0495        |
|    n_updates            | 810           |
|    policy_gradient_loss | -0.00129      |
|    value_loss           | 0.0877        |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 215          |
| time/                   |              |
|    fps                  | 1456         |
|    iterations           | 83           |
|    time_elapsed         | 116          |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 0.0007984716 |
|    clip_fraction        | 0.00596      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0261      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.138        |
|    n_updates            | 820          |
|    policy_gradient_loss | 0.000271     |
|    value_loss           | 0.187        |
------------------------------------------
Eval num_timesteps=170000, episode_reward=217.31 +/- 2.21
Episode length: 221.80 +/- 2.64
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 222          |
|    mean_reward          | 217          |
| time/                   |              |
|    total_timesteps      | 170000       |
| train/                  |              |
|    approx_kl            | 0.0007737115 |
|    clip_fraction        | 0.00796      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0292      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.015        |
|    n_updates            | 830          |
|    policy_gradient_loss | 3.78e-06     |
|    value_loss           | 0.0593       |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 216      |
| time/              |          |
|    fps             | 1453     |
|    iterations      | 84       |
|    time_elapsed    | 118      |
|    total_timesteps | 172032   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1454         |
|    iterations           | 85           |
|    time_elapsed         | 119          |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 0.0027384004 |
|    clip_fraction        | 0.012        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0331      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0884       |
|    n_updates            | 840          |
|    policy_gradient_loss | 0.000255     |
|    value_loss           | 0.148        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1454         |
|    iterations           | 86           |
|    time_elapsed         | 121          |
|    total_timesteps      | 176128       |
| train/                  |              |
|    approx_kl            | 0.0012592046 |
|    clip_fraction        | 0.00796      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0257      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0584       |
|    n_updates            | 850          |
|    policy_gradient_loss | 0.00134      |
|    value_loss           | 0.123        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1455          |
|    iterations           | 87            |
|    time_elapsed         | 122           |
|    total_timesteps      | 178176        |
| train/                  |               |
|    approx_kl            | 0.00012893889 |
|    clip_fraction        | 0.0019        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0239       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0322        |
|    n_updates            | 860           |
|    policy_gradient_loss | 6.27e-05      |
|    value_loss           | 0.08          |
-------------------------------------------
Eval num_timesteps=180000, episode_reward=216.63 +/- 4.55
Episode length: 223.20 +/- 3.87
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 223           |
|    mean_reward          | 217           |
| time/                   |               |
|    total_timesteps      | 180000        |
| train/                  |               |
|    approx_kl            | 0.00074747053 |
|    clip_fraction        | 0.00796       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0256       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0609        |
|    n_updates            | 870           |
|    policy_gradient_loss | -0.000988     |
|    value_loss           | 0.0832        |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 216      |
| time/              |          |
|    fps             | 1452     |
|    iterations      | 88       |
|    time_elapsed    | 124      |
|    total_timesteps | 180224   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1453          |
|    iterations           | 89            |
|    time_elapsed         | 125           |
|    total_timesteps      | 182272        |
| train/                  |               |
|    approx_kl            | 0.00013501091 |
|    clip_fraction        | 0.00239       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0284       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.037         |
|    n_updates            | 880           |
|    policy_gradient_loss | 0.000133      |
|    value_loss           | 0.0751        |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 217           |
| time/                   |               |
|    fps                  | 1453          |
|    iterations           | 90            |
|    time_elapsed         | 126           |
|    total_timesteps      | 184320        |
| train/                  |               |
|    approx_kl            | 0.00023523984 |
|    clip_fraction        | 0.00469       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0293       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0127        |
|    n_updates            | 890           |
|    policy_gradient_loss | 5.25e-05      |
|    value_loss           | 0.0473        |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1454         |
|    iterations           | 91           |
|    time_elapsed         | 128          |
|    total_timesteps      | 186368       |
| train/                  |              |
|    approx_kl            | 0.0007235543 |
|    clip_fraction        | 0.00884      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0321      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.127        |
|    n_updates            | 900          |
|    policy_gradient_loss | -0.00131     |
|    value_loss           | 0.181        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 217           |
| time/                   |               |
|    fps                  | 1455          |
|    iterations           | 92            |
|    time_elapsed         | 129           |
|    total_timesteps      | 188416        |
| train/                  |               |
|    approx_kl            | 0.00054249784 |
|    clip_fraction        | 0.00591       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.03         |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.118         |
|    n_updates            | 910           |
|    policy_gradient_loss | -0.0015       |
|    value_loss           | 0.188         |
-------------------------------------------
Eval num_timesteps=190000, episode_reward=217.53 +/- 4.28
Episode length: 222.60 +/- 2.73
--------------------------------------------
| eval/                   |                |
|    mean_ep_length       | 223            |
|    mean_reward          | 218            |
| time/                   |                |
|    total_timesteps      | 190000         |
| train/                  |                |
|    approx_kl            | 0.000121453704 |
|    clip_fraction        | 0.00156        |
|    clip_range           | 0.2            |
|    entropy_loss         | -0.0241        |
|    explained_variance   | 1              |
|    learning_rate        | 0.0003         |
|    loss                 | 0.146          |
|    n_updates            | 920            |
|    policy_gradient_loss | 0.00035        |
|    value_loss           | 0.172          |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 217      |
| time/              |          |
|    fps             | 1452     |
|    iterations      | 93       |
|    time_elapsed    | 131      |
|    total_timesteps | 190464   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 217           |
| time/                   |               |
|    fps                  | 1452          |
|    iterations           | 94            |
|    time_elapsed         | 132           |
|    total_timesteps      | 192512        |
| train/                  |               |
|    approx_kl            | 0.00037655677 |
|    clip_fraction        | 0.004         |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0314       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0862        |
|    n_updates            | 930           |
|    policy_gradient_loss | -0.000226     |
|    value_loss           | 0.176         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 217           |
| time/                   |               |
|    fps                  | 1453          |
|    iterations           | 95            |
|    time_elapsed         | 133           |
|    total_timesteps      | 194560        |
| train/                  |               |
|    approx_kl            | 0.00020730354 |
|    clip_fraction        | 0.00254       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0266       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.171         |
|    n_updates            | 940           |
|    policy_gradient_loss | 0.000179      |
|    value_loss           | 0.178         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1454          |
|    iterations           | 96            |
|    time_elapsed         | 135           |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 0.00034953287 |
|    clip_fraction        | 0.00669       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.026        |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.135         |
|    n_updates            | 950           |
|    policy_gradient_loss | -0.000588     |
|    value_loss           | 0.173         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1454          |
|    iterations           | 97            |
|    time_elapsed         | 136           |
|    total_timesteps      | 198656        |
| train/                  |               |
|    approx_kl            | 0.00087968085 |
|    clip_fraction        | 0.00503       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0338       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.123         |
|    n_updates            | 960           |
|    policy_gradient_loss | -0.000738     |
|    value_loss           | 0.171         |
-------------------------------------------
Eval num_timesteps=200000, episode_reward=214.95 +/- 0.80
Episode length: 220.60 +/- 1.96
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 221          |
|    mean_reward          | 215          |
| time/                   |              |
|    total_timesteps      | 200000       |
| train/                  |              |
|    approx_kl            | 0.0014913161 |
|    clip_fraction        | 0.0103       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.038       |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.173        |
|    n_updates            | 970          |
|    policy_gradient_loss | -0.000144    |
|    value_loss           | 0.17         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 216      |
| time/              |          |
|    fps             | 1451     |
|    iterations      | 98       |
|    time_elapsed    | 138      |
|    total_timesteps | 200704   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1452          |
|    iterations           | 99            |
|    time_elapsed         | 139           |
|    total_timesteps      | 202752        |
| train/                  |               |
|    approx_kl            | 0.00023371253 |
|    clip_fraction        | 0.00498       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0419       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.13          |
|    n_updates            | 980           |
|    policy_gradient_loss | 0.000129      |
|    value_loss           | 0.177         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1453         |
|    iterations           | 100          |
|    time_elapsed         | 140          |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 0.0020825022 |
|    clip_fraction        | 0.0127       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.043       |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.103        |
|    n_updates            | 990          |
|    policy_gradient_loss | -0.00335     |
|    value_loss           | 0.184        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1453          |
|    iterations           | 101           |
|    time_elapsed         | 142           |
|    total_timesteps      | 206848        |
| train/                  |               |
|    approx_kl            | 0.00016924825 |
|    clip_fraction        | 0.00293       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0353       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.108         |
|    n_updates            | 1000          |
|    policy_gradient_loss | 0.000309      |
|    value_loss           | 0.172         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1454          |
|    iterations           | 102           |
|    time_elapsed         | 143           |
|    total_timesteps      | 208896        |
| train/                  |               |
|    approx_kl            | 0.00051800674 |
|    clip_fraction        | 0.00391       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0293       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.109         |
|    n_updates            | 1010          |
|    policy_gradient_loss | -0.00081      |
|    value_loss           | 0.17          |
-------------------------------------------
Eval num_timesteps=210000, episode_reward=218.54 +/- 3.29
Episode length: 224.40 +/- 2.42
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 224          |
|    mean_reward          | 219          |
| time/                   |              |
|    total_timesteps      | 210000       |
| train/                  |              |
|    approx_kl            | 9.215395e-05 |
|    clip_fraction        | 0.00342      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0271      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0825       |
|    n_updates            | 1020         |
|    policy_gradient_loss | 0.00066      |
|    value_loss           | 0.176        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 216      |
| time/              |          |
|    fps             | 1451     |
|    iterations      | 103      |
|    time_elapsed    | 145      |
|    total_timesteps | 210944   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1452          |
|    iterations           | 104           |
|    time_elapsed         | 146           |
|    total_timesteps      | 212992        |
| train/                  |               |
|    approx_kl            | 0.00019163472 |
|    clip_fraction        | 0.00435       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0315       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.124         |
|    n_updates            | 1030          |
|    policy_gradient_loss | -0.00093      |
|    value_loss           | 0.178         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1452         |
|    iterations           | 105          |
|    time_elapsed         | 148          |
|    total_timesteps      | 215040       |
| train/                  |              |
|    approx_kl            | 0.0003976631 |
|    clip_fraction        | 0.00435      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0348      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.118        |
|    n_updates            | 1040         |
|    policy_gradient_loss | -0.000156    |
|    value_loss           | 0.174        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1453          |
|    iterations           | 106           |
|    time_elapsed         | 149           |
|    total_timesteps      | 217088        |
| train/                  |               |
|    approx_kl            | 0.00060629647 |
|    clip_fraction        | 0.00996       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0358       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0985        |
|    n_updates            | 1050          |
|    policy_gradient_loss | -0.00171      |
|    value_loss           | 0.169         |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 217         |
| time/                   |             |
|    fps                  | 1453        |
|    iterations           | 107         |
|    time_elapsed         | 150         |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.003923681 |
|    clip_fraction        | 0.0145      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0437     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.138       |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.0046     |
|    value_loss           | 0.172       |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=213.13 +/- 1.68
Episode length: 220.20 +/- 1.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 220          |
|    mean_reward          | 213          |
| time/                   |              |
|    total_timesteps      | 220000       |
| train/                  |              |
|    approx_kl            | 0.0004179073 |
|    clip_fraction        | 0.00303      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0475      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0974       |
|    n_updates            | 1070         |
|    policy_gradient_loss | -3.44e-06    |
|    value_loss           | 0.176        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 216      |
| time/              |          |
|    fps             | 1451     |
|    iterations      | 108      |
|    time_elapsed    | 152      |
|    total_timesteps | 221184   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1451         |
|    iterations           | 109          |
|    time_elapsed         | 153          |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 0.0002444515 |
|    clip_fraction        | 0.00898      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0535      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.113        |
|    n_updates            | 1080         |
|    policy_gradient_loss | -0.00185     |
|    value_loss           | 0.183        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1452         |
|    iterations           | 110          |
|    time_elapsed         | 155          |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 0.0009736162 |
|    clip_fraction        | 0.00923      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0451      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.15         |
|    n_updates            | 1090         |
|    policy_gradient_loss | -0.000864    |
|    value_loss           | 0.168        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1452         |
|    iterations           | 111          |
|    time_elapsed         | 156          |
|    total_timesteps      | 227328       |
| train/                  |              |
|    approx_kl            | 0.0009231446 |
|    clip_fraction        | 0.0106       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0445      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.101        |
|    n_updates            | 1100         |
|    policy_gradient_loss | -0.00056     |
|    value_loss           | 0.169        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1453          |
|    iterations           | 112           |
|    time_elapsed         | 157           |
|    total_timesteps      | 229376        |
| train/                  |               |
|    approx_kl            | 0.00084160396 |
|    clip_fraction        | 0.00723       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0524       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.124         |
|    n_updates            | 1110          |
|    policy_gradient_loss | -7.97e-05     |
|    value_loss           | 0.227         |
-------------------------------------------
Eval num_timesteps=230000, episode_reward=216.77 +/- 3.62
Episode length: 222.60 +/- 2.58
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 223           |
|    mean_reward          | 217           |
| time/                   |               |
|    total_timesteps      | 230000        |
| train/                  |               |
|    approx_kl            | 0.00044604333 |
|    clip_fraction        | 0.00781       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0569       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0627        |
|    n_updates            | 1120          |
|    policy_gradient_loss | -0.000726     |
|    value_loss           | 0.0853        |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 216      |
| time/              |          |
|    fps             | 1451     |
|    iterations      | 113      |
|    time_elapsed    | 159      |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 216         |
| time/                   |             |
|    fps                  | 1451        |
|    iterations           | 114         |
|    time_elapsed         | 160         |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.000780582 |
|    clip_fraction        | 0.011       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.042      |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00558     |
|    n_updates            | 1130        |
|    policy_gradient_loss | 0.000557    |
|    value_loss           | 0.135       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1452         |
|    iterations           | 115          |
|    time_elapsed         | 162          |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 0.0010943032 |
|    clip_fraction        | 0.0194       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0524      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0422       |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.00269     |
|    value_loss           | 0.0799       |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1452         |
|    iterations           | 116          |
|    time_elapsed         | 163          |
|    total_timesteps      | 237568       |
| train/                  |              |
|    approx_kl            | 0.0015499663 |
|    clip_fraction        | 0.0175       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0673      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.376        |
|    n_updates            | 1150         |
|    policy_gradient_loss | -0.000668    |
|    value_loss           | 0.287        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 216         |
| time/                   |             |
|    fps                  | 1453        |
|    iterations           | 117         |
|    time_elapsed         | 164         |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.003440991 |
|    clip_fraction        | 0.0177      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0706     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0655      |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.000146   |
|    value_loss           | 0.134       |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=215.15 +/- 3.02
Episode length: 220.20 +/- 2.99
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 220          |
|    mean_reward          | 215          |
| time/                   |              |
|    total_timesteps      | 240000       |
| train/                  |              |
|    approx_kl            | 0.0008540965 |
|    clip_fraction        | 0.013        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0612      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.256        |
|    n_updates            | 1170         |
|    policy_gradient_loss | -0.00268     |
|    value_loss           | 0.37         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 216      |
| time/              |          |
|    fps             | 1450     |
|    iterations      | 118      |
|    time_elapsed    | 166      |
|    total_timesteps | 241664   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1451         |
|    iterations           | 119          |
|    time_elapsed         | 167          |
|    total_timesteps      | 243712       |
| train/                  |              |
|    approx_kl            | 0.0004876349 |
|    clip_fraction        | 0.0143       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0562      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.021        |
|    n_updates            | 1180         |
|    policy_gradient_loss | 0.000479     |
|    value_loss           | 0.108        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1451          |
|    iterations           | 120           |
|    time_elapsed         | 169           |
|    total_timesteps      | 245760        |
| train/                  |               |
|    approx_kl            | 0.00045811658 |
|    clip_fraction        | 0.00747       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.057        |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0963        |
|    n_updates            | 1190          |
|    policy_gradient_loss | -8.95e-05     |
|    value_loss           | 0.111         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1452         |
|    iterations           | 121          |
|    time_elapsed         | 170          |
|    total_timesteps      | 247808       |
| train/                  |              |
|    approx_kl            | 0.0004117097 |
|    clip_fraction        | 0.00962      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0522      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0191       |
|    n_updates            | 1200         |
|    policy_gradient_loss | -0.00166     |
|    value_loss           | 0.0838       |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1452          |
|    iterations           | 122           |
|    time_elapsed         | 171           |
|    total_timesteps      | 249856        |
| train/                  |               |
|    approx_kl            | 0.00088065944 |
|    clip_fraction        | 0.0187        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0462       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0346        |
|    n_updates            | 1210          |
|    policy_gradient_loss | 0.00488       |
|    value_loss           | 0.103         |
-------------------------------------------
Eval num_timesteps=250000, episode_reward=218.49 +/- 2.10
Episode length: 223.40 +/- 1.36
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 223          |
|    mean_reward          | 218          |
| time/                   |              |
|    total_timesteps      | 250000       |
| train/                  |              |
|    approx_kl            | 0.0020354534 |
|    clip_fraction        | 0.0154       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0488      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.04         |
|    n_updates            | 1220         |
|    policy_gradient_loss | -0.00316     |
|    value_loss           | 0.129        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 216      |
| time/              |          |
|    fps             | 1450     |
|    iterations      | 123      |
|    time_elapsed    | 173      |
|    total_timesteps | 251904   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 216          |
| time/                   |              |
|    fps                  | 1451         |
|    iterations           | 124          |
|    time_elapsed         | 175          |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 0.0010375405 |
|    clip_fraction        | 0.016        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.079       |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0688       |
|    n_updates            | 1230         |
|    policy_gradient_loss | -0.00104     |
|    value_loss           | 0.156        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 216         |
| time/                   |             |
|    fps                  | 1451        |
|    iterations           | 125         |
|    time_elapsed         | 176         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.008768518 |
|    clip_fraction        | 0.0236      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0388     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0159      |
|    n_updates            | 1240        |
|    policy_gradient_loss | 0.00301     |
|    value_loss           | 0.114       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 215          |
| time/                   |              |
|    fps                  | 1451         |
|    iterations           | 126          |
|    time_elapsed         | 177          |
|    total_timesteps      | 258048       |
| train/                  |              |
|    approx_kl            | 0.0006353933 |
|    clip_fraction        | 0.00659      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0639      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0716       |
|    n_updates            | 1250         |
|    policy_gradient_loss | -0.000229    |
|    value_loss           | 0.178        |
------------------------------------------
Eval num_timesteps=260000, episode_reward=217.03 +/- 2.75
Episode length: 224.00 +/- 2.76
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 224          |
|    mean_reward          | 217          |
| time/                   |              |
|    total_timesteps      | 260000       |
| train/                  |              |
|    approx_kl            | 0.0033119167 |
|    clip_fraction        | 0.0419       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0502      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.131        |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.00406     |
|    value_loss           | 0.162        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 215      |
| time/              |          |
|    fps             | 1449     |
|    iterations      | 127      |
|    time_elapsed    | 179      |
|    total_timesteps | 260096   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 215           |
| time/                   |               |
|    fps                  | 1450          |
|    iterations           | 128           |
|    time_elapsed         | 180           |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 0.00063371257 |
|    clip_fraction        | 0.00659       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0448       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.127         |
|    n_updates            | 1270          |
|    policy_gradient_loss | -0.00223      |
|    value_loss           | 0.182         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 215          |
| time/                   |              |
|    fps                  | 1450         |
|    iterations           | 129          |
|    time_elapsed         | 182          |
|    total_timesteps      | 264192       |
| train/                  |              |
|    approx_kl            | 0.0008649058 |
|    clip_fraction        | 0.0105       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0513      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0895       |
|    n_updates            | 1280         |
|    policy_gradient_loss | -0.00177     |
|    value_loss           | 0.179        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 215          |
| time/                   |              |
|    fps                  | 1451         |
|    iterations           | 130          |
|    time_elapsed         | 183          |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 0.0003998346 |
|    clip_fraction        | 0.00249      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0417      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.125        |
|    n_updates            | 1290         |
|    policy_gradient_loss | -0.000918    |
|    value_loss           | 0.164        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 216         |
| time/                   |             |
|    fps                  | 1451        |
|    iterations           | 131         |
|    time_elapsed         | 184         |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.001105367 |
|    clip_fraction        | 0.0166      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0513     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.117       |
|    n_updates            | 1300        |
|    policy_gradient_loss | -0.00259    |
|    value_loss           | 0.182       |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=217.72 +/- 2.33
Episode length: 222.80 +/- 1.72
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 223           |
|    mean_reward          | 218           |
| time/                   |               |
|    total_timesteps      | 270000        |
| train/                  |               |
|    approx_kl            | 0.00034829893 |
|    clip_fraction        | 0.00474       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0422       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.118         |
|    n_updates            | 1310          |
|    policy_gradient_loss | -0.00152      |
|    value_loss           | 0.178         |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 216      |
| time/              |          |
|    fps             | 1449     |
|    iterations      | 132      |
|    time_elapsed    | 186      |
|    total_timesteps | 270336   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 215          |
| time/                   |              |
|    fps                  | 1450         |
|    iterations           | 133          |
|    time_elapsed         | 187          |
|    total_timesteps      | 272384       |
| train/                  |              |
|    approx_kl            | 0.0011399256 |
|    clip_fraction        | 0.00845      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0396      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.126        |
|    n_updates            | 1320         |
|    policy_gradient_loss | -0.000583    |
|    value_loss           | 0.19         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 215           |
| time/                   |               |
|    fps                  | 1450          |
|    iterations           | 134           |
|    time_elapsed         | 189           |
|    total_timesteps      | 274432        |
| train/                  |               |
|    approx_kl            | 0.00042313588 |
|    clip_fraction        | 0.00444       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0516       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.106         |
|    n_updates            | 1330          |
|    policy_gradient_loss | 9.2e-05       |
|    value_loss           | 0.182         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1450          |
|    iterations           | 135           |
|    time_elapsed         | 190           |
|    total_timesteps      | 276480        |
| train/                  |               |
|    approx_kl            | 0.00048023125 |
|    clip_fraction        | 0.0152        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0388       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.101         |
|    n_updates            | 1340          |
|    policy_gradient_loss | -0.0021       |
|    value_loss           | 0.175         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 216           |
| time/                   |               |
|    fps                  | 1451          |
|    iterations           | 136           |
|    time_elapsed         | 191           |
|    total_timesteps      | 278528        |
| train/                  |               |
|    approx_kl            | 0.00070823554 |
|    clip_fraction        | 0.00376       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0422       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.142         |
|    n_updates            | 1350          |
|    policy_gradient_loss | -0.000527     |
|    value_loss           | 0.176         |
-------------------------------------------
Eval num_timesteps=280000, episode_reward=214.81 +/- 3.77
Episode length: 220.60 +/- 3.61
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 221          |
|    mean_reward          | 215          |
| time/                   |              |
|    total_timesteps      | 280000       |
| train/                  |              |
|    approx_kl            | 0.0009588549 |
|    clip_fraction        | 0.0144       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0511      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.123        |
|    n_updates            | 1360         |
|    policy_gradient_loss | -0.00257     |
|    value_loss           | 0.209        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 216      |
| time/              |          |
|    fps             | 1449     |
|    iterations      | 137      |
|    time_elapsed    | 193      |
|    total_timesteps | 280576   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 217          |
| time/                   |              |
|    fps                  | 1449         |
|    iterations           | 138          |
|    time_elapsed         | 194          |
|    total_timesteps      | 282624       |
| train/                  |              |
|    approx_kl            | 0.0012382562 |
|    clip_fraction        | 0.0133       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0529      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.000653     |
|    n_updates            | 1370         |
|    policy_gradient_loss | 0.00111      |
|    value_loss           | 0.14         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 217          |
| time/                   |              |
|    fps                  | 1450         |
|    iterations           | 139          |
|    time_elapsed         | 196          |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 0.0016029325 |
|    clip_fraction        | 0.0102       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0347      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0387       |
|    n_updates            | 1380         |
|    policy_gradient_loss | -0.00201     |
|    value_loss           | 0.123        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 217          |
| time/                   |              |
|    fps                  | 1450         |
|    iterations           | 140          |
|    time_elapsed         | 197          |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 0.0014503727 |
|    clip_fraction        | 0.00835      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0553      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0702       |
|    n_updates            | 1390         |
|    policy_gradient_loss | -0.00221     |
|    value_loss           | 0.0935       |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 217           |
| time/                   |               |
|    fps                  | 1450          |
|    iterations           | 141           |
|    time_elapsed         | 199           |
|    total_timesteps      | 288768        |
| train/                  |               |
|    approx_kl            | 0.00043961586 |
|    clip_fraction        | 0.00967       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0418       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0397        |
|    n_updates            | 1400          |
|    policy_gradient_loss | -0.00119      |
|    value_loss           | 0.0963        |
-------------------------------------------
Eval num_timesteps=290000, episode_reward=215.48 +/- 4.06
Episode length: 222.00 +/- 3.16
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 222          |
|    mean_reward          | 215          |
| time/                   |              |
|    total_timesteps      | 290000       |
| train/                  |              |
|    approx_kl            | 0.0012942185 |
|    clip_fraction        | 0.03         |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.032       |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0891       |
|    n_updates            | 1410         |
|    policy_gradient_loss | -0.000969    |
|    value_loss           | 0.113        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 217      |
| time/              |          |
|    fps             | 1449     |
|    iterations      | 142      |
|    time_elapsed    | 200      |
|    total_timesteps | 290816   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 217          |
| time/                   |              |
|    fps                  | 1449         |
|    iterations           | 143          |
|    time_elapsed         | 202          |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 0.0012561006 |
|    clip_fraction        | 0.00874      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0514      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0756       |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.00182     |
|    value_loss           | 0.0935       |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 217           |
| time/                   |               |
|    fps                  | 1450          |
|    iterations           | 144           |
|    time_elapsed         | 203           |
|    total_timesteps      | 294912        |
| train/                  |               |
|    approx_kl            | 0.00047858275 |
|    clip_fraction        | 0.00869       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0606       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.028         |
|    n_updates            | 1430          |
|    policy_gradient_loss | -0.00133      |
|    value_loss           | 0.084         |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 217         |
| time/                   |             |
|    fps                  | 1450        |
|    iterations           | 145         |
|    time_elapsed         | 204         |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.002502399 |
|    clip_fraction        | 0.0535      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0432     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.118       |
|    n_updates            | 1440        |
|    policy_gradient_loss | 0.013       |
|    value_loss           | 0.168       |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 217           |
| time/                   |               |
|    fps                  | 1450          |
|    iterations           | 146           |
|    time_elapsed         | 206           |
|    total_timesteps      | 299008        |
| train/                  |               |
|    approx_kl            | 0.00023353989 |
|    clip_fraction        | 0.00977       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.038        |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0707        |
|    n_updates            | 1450          |
|    policy_gradient_loss | 0.00154       |
|    value_loss           | 0.0809        |
-------------------------------------------
Eval num_timesteps=300000, episode_reward=216.20 +/- 3.43
Episode length: 221.20 +/- 2.23
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 221           |
|    mean_reward          | 216           |
| time/                   |               |
|    total_timesteps      | 300000        |
| train/                  |               |
|    approx_kl            | 0.00073500705 |
|    clip_fraction        | 0.0117        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0512       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.0302        |
|    n_updates            | 1460          |
|    policy_gradient_loss | -0.00066      |
|    value_loss           | 0.0754        |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 216      |
| time/              |          |
|    fps             | 1449     |
|    iterations      | 147      |
|    time_elapsed    | 207      |
|    total_timesteps | 301056   |
---------------------------------

Training complete!
Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-08_00-32-05

