Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-09_01-14-35

Map saved at: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-09_01-14-35/map_visualization.png

Using cpu device
Wrapping the env in a DummyVecEnv.
Logging to /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-09_01-14-35/tensorboard/PPO_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 155      |
|    ep_rew_mean     | -66.3    |
| time/              |          |
|    fps             | 2114     |
|    iterations      | 1        |
|    time_elapsed    | 0        |
|    total_timesteps | 2048     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 171         |
|    ep_rew_mean          | -45.5       |
| time/                   |             |
|    fps                  | 1690        |
|    iterations           | 2           |
|    time_elapsed         | 2           |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.034335263 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | -0.00819    |
|    learning_rate        | 0.0003      |
|    loss                 | 25.2        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0295     |
|    value_loss           | 70.8        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 173         |
|    ep_rew_mean          | -22.2       |
| time/                   |             |
|    fps                  | 1614        |
|    iterations           | 3           |
|    time_elapsed         | 3           |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.049579144 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.989      |
|    explained_variance   | 0.432       |
|    learning_rate        | 0.0003      |
|    loss                 | 26.4        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.026      |
|    value_loss           | 36.4        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 181         |
|    ep_rew_mean          | 2.63        |
| time/                   |             |
|    fps                  | 1575        |
|    iterations           | 4           |
|    time_elapsed         | 5           |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.011589015 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.912      |
|    explained_variance   | 0.576       |
|    learning_rate        | 0.0003      |
|    loss                 | 15.4        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0115     |
|    value_loss           | 40.9        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=128.09 +/- 113.99
Episode length: 148.40 +/- 89.77
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 148        |
|    mean_reward          | 128        |
| time/                   |            |
|    total_timesteps      | 10000      |
| train/                  |            |
|    approx_kl            | 0.00955745 |
|    clip_fraction        | 0.0608     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.859     |
|    explained_variance   | 0.677      |
|    learning_rate        | 0.0003     |
|    loss                 | 11.1       |
|    n_updates            | 40         |
|    policy_gradient_loss | -0.00712   |
|    value_loss           | 36.4       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 164      |
|    ep_rew_mean     | 9.59     |
| time/              |          |
|    fps             | 1486     |
|    iterations      | 5        |
|    time_elapsed    | 6        |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 165          |
|    ep_rew_mean          | 20.5         |
| time/                   |              |
|    fps                  | 1484         |
|    iterations           | 6            |
|    time_elapsed         | 8            |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0045924317 |
|    clip_fraction        | 0.0186       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.846       |
|    explained_variance   | 0.609        |
|    learning_rate        | 0.0003       |
|    loss                 | 28.4         |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00352     |
|    value_loss           | 88.8         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 162         |
|    ep_rew_mean          | 27.7        |
| time/                   |             |
|    fps                  | 1482        |
|    iterations           | 7           |
|    time_elapsed         | 9           |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.004938283 |
|    clip_fraction        | 0.0214      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.784      |
|    explained_variance   | 0.613       |
|    learning_rate        | 0.0003      |
|    loss                 | 21.7        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00455    |
|    value_loss           | 70.9        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 167          |
|    ep_rew_mean          | 36.6         |
| time/                   |              |
|    fps                  | 1480         |
|    iterations           | 8            |
|    time_elapsed         | 11           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0019133969 |
|    clip_fraction        | 0.0165       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.764       |
|    explained_variance   | 0.648        |
|    learning_rate        | 0.0003       |
|    loss                 | 20.7         |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.0031      |
|    value_loss           | 70.7         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 164         |
|    ep_rew_mean          | 56.3        |
| time/                   |             |
|    fps                  | 1478        |
|    iterations           | 9           |
|    time_elapsed         | 12          |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.009928308 |
|    clip_fraction        | 0.0191      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.7        |
|    explained_variance   | 0.557       |
|    learning_rate        | 0.0003      |
|    loss                 | 17.2        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00196    |
|    value_loss           | 38.1        |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=78.53 +/- 114.62
Episode length: 108.60 +/- 90.23
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 109           |
|    mean_reward          | 78.5          |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 0.00047598945 |
|    clip_fraction        | 0.000977      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.68         |
|    explained_variance   | 0.765         |
|    learning_rate        | 0.0003        |
|    loss                 | 23.3          |
|    n_updates            | 90            |
|    policy_gradient_loss | -0.000821     |
|    value_loss           | 67.2          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 155      |
|    ep_rew_mean     | 66.2     |
| time/              |          |
|    fps             | 1414     |
|    iterations      | 10       |
|    time_elapsed    | 14       |
|    total_timesteps | 20480    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 147         |
|    ep_rew_mean          | 67.7        |
| time/                   |             |
|    fps                  | 1419        |
|    iterations           | 11          |
|    time_elapsed         | 15          |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.006400361 |
|    clip_fraction        | 0.00303     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.647      |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.0003      |
|    loss                 | 64.5        |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00165    |
|    value_loss           | 77.3        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 146          |
|    ep_rew_mean          | 71.8         |
| time/                   |              |
|    fps                  | 1423         |
|    iterations           | 12           |
|    time_elapsed         | 17           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0047892854 |
|    clip_fraction        | 0.0223       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.65        |
|    explained_variance   | 0.857        |
|    learning_rate        | 0.0003       |
|    loss                 | 28           |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00219     |
|    value_loss           | 62.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 143          |
|    ep_rew_mean          | 73.2         |
| time/                   |              |
|    fps                  | 1426         |
|    iterations           | 13           |
|    time_elapsed         | 18           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0067783603 |
|    clip_fraction        | 0.0186       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.619       |
|    explained_variance   | 0.855        |
|    learning_rate        | 0.0003       |
|    loss                 | 39.5         |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00275     |
|    value_loss           | 81           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 143          |
|    ep_rew_mean          | 76           |
| time/                   |              |
|    fps                  | 1430         |
|    iterations           | 14           |
|    time_elapsed         | 20           |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 0.0033166516 |
|    clip_fraction        | 0.00273      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.552       |
|    explained_variance   | 0.769        |
|    learning_rate        | 0.0003       |
|    loss                 | 33           |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00134     |
|    value_loss           | 71.1         |
------------------------------------------
Eval num_timesteps=30000, episode_reward=126.10 +/- 115.26
Episode length: 146.40 +/- 91.03
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 146          |
|    mean_reward          | 126          |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0053553926 |
|    clip_fraction        | 0.0399       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.483       |
|    explained_variance   | 0.863        |
|    learning_rate        | 0.0003       |
|    loss                 | 38.9         |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00463     |
|    value_loss           | 78.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 80.3     |
| time/              |          |
|    fps             | 1403     |
|    iterations      | 15       |
|    time_elapsed    | 21       |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 140         |
|    ep_rew_mean          | 78.7        |
| time/                   |             |
|    fps                  | 1408        |
|    iterations           | 16          |
|    time_elapsed         | 23          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.003473993 |
|    clip_fraction        | 0.0163      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.419      |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.0003      |
|    loss                 | 16.6        |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00111    |
|    value_loss           | 49.5        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 143          |
|    ep_rew_mean          | 84.4         |
| time/                   |              |
|    fps                  | 1412         |
|    iterations           | 17           |
|    time_elapsed         | 24           |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0025398228 |
|    clip_fraction        | 0.00635      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.384       |
|    explained_variance   | 0.848        |
|    learning_rate        | 0.0003       |
|    loss                 | 33.3         |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00157     |
|    value_loss           | 73.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 149          |
|    ep_rew_mean          | 92.1         |
| time/                   |              |
|    fps                  | 1415         |
|    iterations           | 18           |
|    time_elapsed         | 26           |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 0.0024973205 |
|    clip_fraction        | 0.0258       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.314       |
|    explained_variance   | 0.76         |
|    learning_rate        | 0.0003       |
|    loss                 | 42.1         |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00264     |
|    value_loss           | 97.4         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | 97          |
| time/                   |             |
|    fps                  | 1418        |
|    iterations           | 19          |
|    time_elapsed         | 27          |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.002742546 |
|    clip_fraction        | 0.0215      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.27       |
|    explained_variance   | 0.722       |
|    learning_rate        | 0.0003      |
|    loss                 | 36.5        |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00241    |
|    value_loss           | 69.8        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=172.74 +/- 95.92
Episode length: 183.20 +/- 76.16
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 183          |
|    mean_reward          | 173          |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 9.973385e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.264       |
|    explained_variance   | 0.754        |
|    learning_rate        | 0.0003       |
|    loss                 | 95.7         |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.000105    |
|    value_loss           | 121          |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 160      |
|    ep_rew_mean     | 109      |
| time/              |          |
|    fps             | 1402     |
|    iterations      | 20       |
|    time_elapsed    | 29       |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 154          |
|    ep_rew_mean          | 106          |
| time/                   |              |
|    fps                  | 1406         |
|    iterations           | 21           |
|    time_elapsed         | 30           |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0014142767 |
|    clip_fraction        | 0.00142      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.249       |
|    explained_variance   | 0.714        |
|    learning_rate        | 0.0003       |
|    loss                 | 33.7         |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00046     |
|    value_loss           | 88.1         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 146          |
|    ep_rew_mean          | 100          |
| time/                   |              |
|    fps                  | 1409         |
|    iterations           | 22           |
|    time_elapsed         | 31           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0013278852 |
|    clip_fraction        | 0.0123       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.203       |
|    explained_variance   | 0.866        |
|    learning_rate        | 0.0003       |
|    loss                 | 59.4         |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.00249     |
|    value_loss           | 92.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 146           |
|    ep_rew_mean          | 103           |
| time/                   |               |
|    fps                  | 1411          |
|    iterations           | 23            |
|    time_elapsed         | 33            |
|    total_timesteps      | 47104         |
| train/                  |               |
|    approx_kl            | 1.3662269e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.203        |
|    explained_variance   | 0.831         |
|    learning_rate        | 0.0003        |
|    loss                 | 121           |
|    n_updates            | 220           |
|    policy_gradient_loss | 2.21e-05      |
|    value_loss           | 140           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 133          |
|    ep_rew_mean          | 91.2         |
| time/                   |              |
|    fps                  | 1413         |
|    iterations           | 24           |
|    time_elapsed         | 34           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0009726089 |
|    clip_fraction        | 0.0159       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.176       |
|    explained_variance   | 0.918        |
|    learning_rate        | 0.0003       |
|    loss                 | 21.8         |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.00234     |
|    value_loss           | 63.5         |
------------------------------------------
Eval num_timesteps=50000, episode_reward=79.77 +/- 112.44
Episode length: 110.00 +/- 88.23
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 110          |
|    mean_reward          | 79.8         |
| time/                   |              |
|    total_timesteps      | 50000        |
| train/                  |              |
|    approx_kl            | 0.0010981864 |
|    clip_fraction        | 0.0192       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.15        |
|    explained_variance   | 0.951        |
|    learning_rate        | 0.0003       |
|    loss                 | 13.9         |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.00218     |
|    value_loss           | 43.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 135      |
|    ep_rew_mean     | 95.1     |
| time/              |          |
|    fps             | 1378     |
|    iterations      | 25       |
|    time_elapsed    | 37       |
|    total_timesteps | 51200    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 129           |
|    ep_rew_mean          | 90.5          |
| time/                   |               |
|    fps                  | 1382          |
|    iterations           | 26            |
|    time_elapsed         | 38            |
|    total_timesteps      | 53248         |
| train/                  |               |
|    approx_kl            | 0.00061191455 |
|    clip_fraction        | 0.00264       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.124        |
|    explained_variance   | 0.871         |
|    learning_rate        | 0.0003        |
|    loss                 | 10.8          |
|    n_updates            | 250           |
|    policy_gradient_loss | -0.00071      |
|    value_loss           | 55.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 131          |
|    ep_rew_mean          | 94.5         |
| time/                   |              |
|    fps                  | 1385         |
|    iterations           | 27           |
|    time_elapsed         | 39           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 0.0005157743 |
|    clip_fraction        | 0.00103      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.107       |
|    explained_variance   | 0.913        |
|    learning_rate        | 0.0003       |
|    loss                 | 77.3         |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.000447    |
|    value_loss           | 58.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 121          |
|    ep_rew_mean          | 85.5         |
| time/                   |              |
|    fps                  | 1388         |
|    iterations           | 28           |
|    time_elapsed         | 41           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0004085692 |
|    clip_fraction        | 0.00503      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0885      |
|    explained_variance   | 0.842        |
|    learning_rate        | 0.0003       |
|    loss                 | 37.8         |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.00117     |
|    value_loss           | 96.6         |
------------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 121            |
|    ep_rew_mean          | 87.1           |
| time/                   |                |
|    fps                  | 1391           |
|    iterations           | 29             |
|    time_elapsed         | 42             |
|    total_timesteps      | 59392          |
| train/                  |                |
|    approx_kl            | 1.45334925e-05 |
|    clip_fraction        | 0              |
|    clip_range           | 0.2            |
|    entropy_loss         | -0.0869        |
|    explained_variance   | 0.948          |
|    learning_rate        | 0.0003         |
|    loss                 | 45.7           |
|    n_updates            | 280            |
|    policy_gradient_loss | -7.25e-05      |
|    value_loss           | 76.2           |
--------------------------------------------
Eval num_timesteps=60000, episode_reward=82.68 +/- 114.35
Episode length: 112.80 +/- 90.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 113          |
|    mean_reward          | 82.7         |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 8.911043e-05 |
|    clip_fraction        | 0.000293     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.077       |
|    explained_variance   | 0.918        |
|    learning_rate        | 0.0003       |
|    loss                 | 42.3         |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.000591    |
|    value_loss           | 60.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 127      |
|    ep_rew_mean     | 94.9     |
| time/              |          |
|    fps             | 1374     |
|    iterations      | 30       |
|    time_elapsed    | 44       |
|    total_timesteps | 61440    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 127           |
|    ep_rew_mean          | 95.3          |
| time/                   |               |
|    fps                  | 1377          |
|    iterations           | 31            |
|    time_elapsed         | 46            |
|    total_timesteps      | 63488         |
| train/                  |               |
|    approx_kl            | 0.00012785001 |
|    clip_fraction        | 0.000879      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0771       |
|    explained_variance   | 0.897         |
|    learning_rate        | 0.0003        |
|    loss                 | 96.3          |
|    n_updates            | 300           |
|    policy_gradient_loss | -0.00036      |
|    value_loss           | 85.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 119           |
|    ep_rew_mean          | 86.9          |
| time/                   |               |
|    fps                  | 1380          |
|    iterations           | 32            |
|    time_elapsed         | 47            |
|    total_timesteps      | 65536         |
| train/                  |               |
|    approx_kl            | 0.00047194766 |
|    clip_fraction        | 0.00479       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0686       |
|    explained_variance   | 0.82          |
|    learning_rate        | 0.0003        |
|    loss                 | 16.7          |
|    n_updates            | 310           |
|    policy_gradient_loss | -0.0012       |
|    value_loss           | 102           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 119           |
|    ep_rew_mean          | 87.2          |
| time/                   |               |
|    fps                  | 1383          |
|    iterations           | 33            |
|    time_elapsed         | 48            |
|    total_timesteps      | 67584         |
| train/                  |               |
|    approx_kl            | 0.00017520864 |
|    clip_fraction        | 0.00205       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0578       |
|    explained_variance   | 0.964         |
|    learning_rate        | 0.0003        |
|    loss                 | 3.06          |
|    n_updates            | 320           |
|    policy_gradient_loss | -0.0008       |
|    value_loss           | 16.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 130           |
|    ep_rew_mean          | 101           |
| time/                   |               |
|    fps                  | 1385          |
|    iterations           | 34            |
|    time_elapsed         | 50            |
|    total_timesteps      | 69632         |
| train/                  |               |
|    approx_kl            | 0.00019033361 |
|    clip_fraction        | 0.00122       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0489       |
|    explained_variance   | 0.892         |
|    learning_rate        | 0.0003        |
|    loss                 | 64.9          |
|    n_updates            | 330           |
|    policy_gradient_loss | -0.000578     |
|    value_loss           | 88            |
-------------------------------------------
Eval num_timesteps=70000, episode_reward=126.41 +/- 115.90
Episode length: 146.80 +/- 91.72
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 147           |
|    mean_reward          | 126           |
| time/                   |               |
|    total_timesteps      | 70000         |
| train/                  |               |
|    approx_kl            | 0.00012710385 |
|    clip_fraction        | 0.00117       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0406       |
|    explained_variance   | 0.964         |
|    learning_rate        | 0.0003        |
|    loss                 | 2.73          |
|    n_updates            | 340           |
|    policy_gradient_loss | -0.000473     |
|    value_loss           | 17.6          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 118      |
| time/              |          |
|    fps             | 1358     |
|    iterations      | 35       |
|    time_elapsed    | 52       |
|    total_timesteps | 71680    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 140           |
|    ep_rew_mean          | 113           |
| time/                   |               |
|    fps                  | 1361          |
|    iterations           | 36            |
|    time_elapsed         | 54            |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 3.1197706e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0394       |
|    explained_variance   | 0.885         |
|    learning_rate        | 0.0003        |
|    loss                 | 55.8          |
|    n_updates            | 350           |
|    policy_gradient_loss | -0.000166     |
|    value_loss           | 85.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 136           |
|    ep_rew_mean          | 109           |
| time/                   |               |
|    fps                  | 1364          |
|    iterations           | 37            |
|    time_elapsed         | 55            |
|    total_timesteps      | 75776         |
| train/                  |               |
|    approx_kl            | 4.0610525e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0405       |
|    explained_variance   | 0.945         |
|    learning_rate        | 0.0003        |
|    loss                 | 162           |
|    n_updates            | 360           |
|    policy_gradient_loss | -8.05e-05     |
|    value_loss           | 53.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 138           |
|    ep_rew_mean          | 112           |
| time/                   |               |
|    fps                  | 1367          |
|    iterations           | 38            |
|    time_elapsed         | 56            |
|    total_timesteps      | 77824         |
| train/                  |               |
|    approx_kl            | 0.00011200001 |
|    clip_fraction        | 4.88e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0341       |
|    explained_variance   | 0.968         |
|    learning_rate        | 0.0003        |
|    loss                 | 8.35          |
|    n_updates            | 370           |
|    policy_gradient_loss | -0.000391     |
|    value_loss           | 32.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 141          |
|    ep_rew_mean          | 117          |
| time/                   |              |
|    fps                  | 1370         |
|    iterations           | 39           |
|    time_elapsed         | 58           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 0.0001401036 |
|    clip_fraction        | 0.00127      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0262      |
|    explained_variance   | 0.949        |
|    learning_rate        | 0.0003       |
|    loss                 | 4.44         |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.000273    |
|    value_loss           | 38.7         |
------------------------------------------
Eval num_timesteps=80000, episode_reward=125.33 +/- 114.64
Episode length: 145.60 +/- 90.38
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 146          |
|    mean_reward          | 125          |
| time/                   |              |
|    total_timesteps      | 80000        |
| train/                  |              |
|    approx_kl            | 4.499132e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0235      |
|    explained_variance   | 0.907        |
|    learning_rate        | 0.0003       |
|    loss                 | 21.2         |
|    n_updates            | 390          |
|    policy_gradient_loss | -3.31e-05    |
|    value_loss           | 58.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 138      |
|    ep_rew_mean     | 113      |
| time/              |          |
|    fps             | 1367     |
|    iterations      | 40       |
|    time_elapsed    | 59       |
|    total_timesteps | 81920    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 126           |
|    ep_rew_mean          | 98.8          |
| time/                   |               |
|    fps                  | 1369          |
|    iterations           | 41            |
|    time_elapsed         | 61            |
|    total_timesteps      | 83968         |
| train/                  |               |
|    approx_kl            | 6.2716717e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0238       |
|    explained_variance   | 0.883         |
|    learning_rate        | 0.0003        |
|    loss                 | 12            |
|    n_updates            | 400           |
|    policy_gradient_loss | -3.35e-05     |
|    value_loss           | 46.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 132           |
|    ep_rew_mean          | 106           |
| time/                   |               |
|    fps                  | 1372          |
|    iterations           | 42            |
|    time_elapsed         | 62            |
|    total_timesteps      | 86016         |
| train/                  |               |
|    approx_kl            | 0.00016645601 |
|    clip_fraction        | 0.00356       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0212       |
|    explained_variance   | 0.954         |
|    learning_rate        | 0.0003        |
|    loss                 | 15.7          |
|    n_updates            | 410           |
|    policy_gradient_loss | -0.000597     |
|    value_loss           | 25.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 141           |
|    ep_rew_mean          | 118           |
| time/                   |               |
|    fps                  | 1374          |
|    iterations           | 43            |
|    time_elapsed         | 64            |
|    total_timesteps      | 88064         |
| train/                  |               |
|    approx_kl            | 0.00012329119 |
|    clip_fraction        | 0.00225       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.017        |
|    explained_variance   | 0.888         |
|    learning_rate        | 0.0003        |
|    loss                 | 2.07          |
|    n_updates            | 420           |
|    policy_gradient_loss | -0.000476     |
|    value_loss           | 46.6          |
-------------------------------------------
Eval num_timesteps=90000, episode_reward=33.66 +/- 96.37
Episode length: 73.80 +/- 76.65
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 73.8          |
|    mean_reward          | 33.7          |
| time/                   |               |
|    total_timesteps      | 90000         |
| train/                  |               |
|    approx_kl            | 6.6879176e-05 |
|    clip_fraction        | 0.00176       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0134       |
|    explained_variance   | 0.982         |
|    learning_rate        | 0.0003        |
|    loss                 | 1.68          |
|    n_updates            | 430           |
|    policy_gradient_loss | -0.000725     |
|    value_loss           | 7.82          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | 118      |
| time/              |          |
|    fps             | 1358     |
|    iterations      | 44       |
|    time_elapsed    | 66       |
|    total_timesteps | 90112    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 138          |
|    ep_rew_mean          | 114          |
| time/                   |              |
|    fps                  | 1361         |
|    iterations           | 45           |
|    time_elapsed         | 67           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 4.656613e-10 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0135      |
|    explained_variance   | 0.875        |
|    learning_rate        | 0.0003       |
|    loss                 | 97.1         |
|    n_updates            | 440          |
|    policy_gradient_loss | -1.2e-06     |
|    value_loss           | 113          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 140           |
|    ep_rew_mean          | 116           |
| time/                   |               |
|    fps                  | 1363          |
|    iterations           | 46            |
|    time_elapsed         | 69            |
|    total_timesteps      | 94208         |
| train/                  |               |
|    approx_kl            | 2.6654074e-05 |
|    clip_fraction        | 9.77e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0127       |
|    explained_variance   | 0.926         |
|    learning_rate        | 0.0003        |
|    loss                 | 8.72          |
|    n_updates            | 450           |
|    policy_gradient_loss | -0.000343     |
|    value_loss           | 70            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 145           |
|    ep_rew_mean          | 123           |
| time/                   |               |
|    fps                  | 1365          |
|    iterations           | 47            |
|    time_elapsed         | 70            |
|    total_timesteps      | 96256         |
| train/                  |               |
|    approx_kl            | 6.2891166e-05 |
|    clip_fraction        | 0.000537      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0108       |
|    explained_variance   | 0.898         |
|    learning_rate        | 0.0003        |
|    loss                 | 1.24          |
|    n_updates            | 460           |
|    policy_gradient_loss | -0.000216     |
|    value_loss           | 59.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 147           |
|    ep_rew_mean          | 126           |
| time/                   |               |
|    fps                  | 1367          |
|    iterations           | 48            |
|    time_elapsed         | 71            |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 4.0919986e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00989      |
|    explained_variance   | 0.943         |
|    learning_rate        | 0.0003        |
|    loss                 | 1.59          |
|    n_updates            | 470           |
|    policy_gradient_loss | -5.63e-06     |
|    value_loss           | 40.2          |
-------------------------------------------
Eval num_timesteps=100000, episode_reward=174.35 +/- 92.18
Episode length: 184.80 +/- 72.41
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 185       |
|    mean_reward          | 174       |
| time/                   |           |
|    total_timesteps      | 100000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00991  |
|    explained_variance   | 0.928     |
|    learning_rate        | 0.0003    |
|    loss                 | 46.6      |
|    n_updates            | 480       |
|    policy_gradient_loss | -6.46e-08 |
|    value_loss           | 74.2      |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 151      |
|    ep_rew_mean     | 131      |
| time/              |          |
|    fps             | 1358     |
|    iterations      | 49       |
|    time_elapsed    | 73       |
|    total_timesteps | 100352   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 151           |
|    ep_rew_mean          | 131           |
| time/                   |               |
|    fps                  | 1361          |
|    iterations           | 50            |
|    time_elapsed         | 75            |
|    total_timesteps      | 102400        |
| train/                  |               |
|    approx_kl            | 3.5490346e-05 |
|    clip_fraction        | 0.000195      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00891      |
|    explained_variance   | 0.992         |
|    learning_rate        | 0.0003        |
|    loss                 | 3.03          |
|    n_updates            | 490           |
|    policy_gradient_loss | -0.000176     |
|    value_loss           | 7.04          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 149           |
|    ep_rew_mean          | 129           |
| time/                   |               |
|    fps                  | 1363          |
|    iterations           | 51            |
|    time_elapsed         | 76            |
|    total_timesteps      | 104448        |
| train/                  |               |
|    approx_kl            | 1.9264087e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00794      |
|    explained_variance   | 0.877         |
|    learning_rate        | 0.0003        |
|    loss                 | 21.6          |
|    n_updates            | 500           |
|    policy_gradient_loss | -8.38e-05     |
|    value_loss           | 97.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 153          |
|    ep_rew_mean          | 133          |
| time/                   |              |
|    fps                  | 1365         |
|    iterations           | 52           |
|    time_elapsed         | 78           |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 5.527516e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00731     |
|    explained_variance   | 0.964        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.16         |
|    n_updates            | 510          |
|    policy_gradient_loss | -1.54e-05    |
|    value_loss           | 41.3         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 149           |
|    ep_rew_mean          | 129           |
| time/                   |               |
|    fps                  | 1366          |
|    iterations           | 53            |
|    time_elapsed         | 79            |
|    total_timesteps      | 108544        |
| train/                  |               |
|    approx_kl            | 2.8619252e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00664      |
|    explained_variance   | 0.914         |
|    learning_rate        | 0.0003        |
|    loss                 | 3.6           |
|    n_updates            | 520           |
|    policy_gradient_loss | -1.95e-05     |
|    value_loss           | 65.4          |
-------------------------------------------
Eval num_timesteps=110000, episode_reward=126.09 +/- 114.80
Episode length: 146.40 +/- 90.56
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 146       |
|    mean_reward          | 126       |
| time/                   |           |
|    total_timesteps      | 110000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00657  |
|    explained_variance   | 0.959     |
|    learning_rate        | 0.0003    |
|    loss                 | 23.3      |
|    n_updates            | 530       |
|    policy_gradient_loss | -2.98e-06 |
|    value_loss           | 37.4      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 140      |
|    ep_rew_mean     | 117      |
| time/              |          |
|    fps             | 1352     |
|    iterations      | 54       |
|    time_elapsed    | 81       |
|    total_timesteps | 110592   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 129           |
|    ep_rew_mean          | 103           |
| time/                   |               |
|    fps                  | 1354          |
|    iterations           | 55            |
|    time_elapsed         | 83            |
|    total_timesteps      | 112640        |
| train/                  |               |
|    approx_kl            | 1.7919228e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00668      |
|    explained_variance   | 0.963         |
|    learning_rate        | 0.0003        |
|    loss                 | 3.06          |
|    n_updates            | 540           |
|    policy_gradient_loss | -2.33e-06     |
|    value_loss           | 49.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 127          |
|    ep_rew_mean          | 101          |
| time/                   |              |
|    fps                  | 1356         |
|    iterations           | 56           |
|    time_elapsed         | 84           |
|    total_timesteps      | 114688       |
| train/                  |              |
|    approx_kl            | 2.689194e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00654     |
|    explained_variance   | 0.91         |
|    learning_rate        | 0.0003       |
|    loss                 | 74.1         |
|    n_updates            | 550          |
|    policy_gradient_loss | -3.57e-07    |
|    value_loss           | 106          |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 127       |
|    ep_rew_mean          | 101       |
| time/                   |           |
|    fps                  | 1358      |
|    iterations           | 57        |
|    time_elapsed         | 85        |
|    total_timesteps      | 116736    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00663  |
|    explained_variance   | 0.874     |
|    learning_rate        | 0.0003    |
|    loss                 | 10.3      |
|    n_updates            | 560       |
|    policy_gradient_loss | -8.51e-08 |
|    value_loss           | 142       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 125           |
|    ep_rew_mean          | 98.6          |
| time/                   |               |
|    fps                  | 1360          |
|    iterations           | 58            |
|    time_elapsed         | 87            |
|    total_timesteps      | 118784        |
| train/                  |               |
|    approx_kl            | 3.0340743e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00643      |
|    explained_variance   | 0.87          |
|    learning_rate        | 0.0003        |
|    loss                 | 97.9          |
|    n_updates            | 570           |
|    policy_gradient_loss | -4.51e-06     |
|    value_loss           | 121           |
-------------------------------------------
Eval num_timesteps=120000, episode_reward=78.17 +/- 115.34
Episode length: 108.40 +/- 91.12
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 108          |
|    mean_reward          | 78.2         |
| time/                   |              |
|    total_timesteps      | 120000       |
| train/                  |              |
|    approx_kl            | 1.941336e-05 |
|    clip_fraction        | 0.000244     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00571     |
|    explained_variance   | 0.964        |
|    learning_rate        | 0.0003       |
|    loss                 | 2.82         |
|    n_updates            | 580          |
|    policy_gradient_loss | -0.00028     |
|    value_loss           | 27           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 134      |
|    ep_rew_mean     | 110      |
| time/              |          |
|    fps             | 1342     |
|    iterations      | 59       |
|    time_elapsed    | 90       |
|    total_timesteps | 120832   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 133       |
|    ep_rew_mean          | 108       |
| time/                   |           |
|    fps                  | 1344      |
|    iterations           | 60        |
|    time_elapsed         | 91        |
|    total_timesteps      | 122880    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00533  |
|    explained_variance   | 0.923     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.82      |
|    n_updates            | 590       |
|    policy_gradient_loss | -3.83e-07 |
|    value_loss           | 21.1      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 142          |
|    ep_rew_mean          | 120          |
| time/                   |              |
|    fps                  | 1346         |
|    iterations           | 61           |
|    time_elapsed         | 92           |
|    total_timesteps      | 124928       |
| train/                  |              |
|    approx_kl            | 6.437008e-05 |
|    clip_fraction        | 0.00083      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0047      |
|    explained_variance   | 0.884        |
|    learning_rate        | 0.0003       |
|    loss                 | 5.09         |
|    n_updates            | 600          |
|    policy_gradient_loss | -0.00047     |
|    value_loss           | 68.2         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 142       |
|    ep_rew_mean          | 120       |
| time/                   |           |
|    fps                  | 1348      |
|    iterations           | 62        |
|    time_elapsed         | 94        |
|    total_timesteps      | 126976    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00433  |
|    explained_variance   | 0.912     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.13      |
|    n_updates            | 610       |
|    policy_gradient_loss | -2.46e-07 |
|    value_loss           | 25        |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 147          |
|    ep_rew_mean          | 127          |
| time/                   |              |
|    fps                  | 1350         |
|    iterations           | 63           |
|    time_elapsed         | 95           |
|    total_timesteps      | 129024       |
| train/                  |              |
|    approx_kl            | 8.236384e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00438     |
|    explained_variance   | 0.764        |
|    learning_rate        | 0.0003       |
|    loss                 | 25.1         |
|    n_updates            | 620          |
|    policy_gradient_loss | -1.56e-06    |
|    value_loss           | 127          |
------------------------------------------
Eval num_timesteps=130000, episode_reward=79.07 +/- 117.67
Episode length: 109.20 +/- 93.33
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 109          |
|    mean_reward          | 79.1         |
| time/                   |              |
|    total_timesteps      | 130000       |
| train/                  |              |
|    approx_kl            | 5.288195e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00423     |
|    explained_variance   | 0.958        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.82         |
|    n_updates            | 630          |
|    policy_gradient_loss | -1.49e-05    |
|    value_loss           | 13.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | 124      |
| time/              |          |
|    fps             | 1344     |
|    iterations      | 64       |
|    time_elapsed    | 97       |
|    total_timesteps | 131072   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 141           |
|    ep_rew_mean          | 119           |
| time/                   |               |
|    fps                  | 1346          |
|    iterations           | 65            |
|    time_elapsed         | 98            |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 2.7719041e-05 |
|    clip_fraction        | 0.000342      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00358      |
|    explained_variance   | 0.988         |
|    learning_rate        | 0.0003        |
|    loss                 | 2.2           |
|    n_updates            | 640           |
|    policy_gradient_loss | -0.000201     |
|    value_loss           | 8.29          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 138       |
|    ep_rew_mean          | 115       |
| time/                   |           |
|    fps                  | 1348      |
|    iterations           | 66        |
|    time_elapsed         | 100       |
|    total_timesteps      | 135168    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00339  |
|    explained_variance   | 0.883     |
|    learning_rate        | 0.0003    |
|    loss                 | 62.3      |
|    n_updates            | 650       |
|    policy_gradient_loss | -1.38e-07 |
|    value_loss           | 115       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 137           |
|    ep_rew_mean          | 114           |
| time/                   |               |
|    fps                  | 1350          |
|    iterations           | 67            |
|    time_elapsed         | 101           |
|    total_timesteps      | 137216        |
| train/                  |               |
|    approx_kl            | 1.7929415e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00331      |
|    explained_variance   | 0.89          |
|    learning_rate        | 0.0003        |
|    loss                 | 37            |
|    n_updates            | 660           |
|    policy_gradient_loss | -4.95e-06     |
|    value_loss           | 87.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 130           |
|    ep_rew_mean          | 105           |
| time/                   |               |
|    fps                  | 1351          |
|    iterations           | 68            |
|    time_elapsed         | 103           |
|    total_timesteps      | 139264        |
| train/                  |               |
|    approx_kl            | 1.0421209e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00335      |
|    explained_variance   | 0.935         |
|    learning_rate        | 0.0003        |
|    loss                 | 6.62          |
|    n_updates            | 670           |
|    policy_gradient_loss | -1.49e-05     |
|    value_loss           | 65.3          |
-------------------------------------------
Eval num_timesteps=140000, episode_reward=32.54 +/- 94.12
Episode length: 72.60 +/- 74.24
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 72.6      |
|    mean_reward          | 32.5      |
| time/                   |           |
|    total_timesteps      | 140000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0035   |
|    explained_variance   | 0.971     |
|    learning_rate        | 0.0003    |
|    loss                 | 92.8      |
|    n_updates            | 680       |
|    policy_gradient_loss | -2.37e-07 |
|    value_loss           | 36.1      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 134      |
|    ep_rew_mean     | 110      |
| time/              |          |
|    fps             | 1343     |
|    iterations      | 69       |
|    time_elapsed    | 105      |
|    total_timesteps | 141312   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 132       |
|    ep_rew_mean          | 108       |
| time/                   |           |
|    fps                  | 1345      |
|    iterations           | 70        |
|    time_elapsed         | 106       |
|    total_timesteps      | 143360    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00353  |
|    explained_variance   | 0.902     |
|    learning_rate        | 0.0003    |
|    loss                 | 85.3      |
|    n_updates            | 690       |
|    policy_gradient_loss | -1.71e-07 |
|    value_loss           | 96.1      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 134          |
|    ep_rew_mean          | 110          |
| time/                   |              |
|    fps                  | 1347         |
|    iterations           | 71           |
|    time_elapsed         | 107          |
|    total_timesteps      | 145408       |
| train/                  |              |
|    approx_kl            | 2.106215e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00346     |
|    explained_variance   | 0.973        |
|    learning_rate        | 0.0003       |
|    loss                 | 17.4         |
|    n_updates            | 700          |
|    policy_gradient_loss | -1.42e-05    |
|    value_loss           | 30.3         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 130       |
|    ep_rew_mean          | 106       |
| time/                   |           |
|    fps                  | 1349      |
|    iterations           | 72        |
|    time_elapsed         | 109       |
|    total_timesteps      | 147456    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0032   |
|    explained_variance   | 0.952     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.43      |
|    n_updates            | 710       |
|    policy_gradient_loss | -8.58e-08 |
|    value_loss           | 17.9      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 121      |
|    ep_rew_mean          | 94.1     |
| time/                   |          |
|    fps                  | 1350     |
|    iterations           | 73       |
|    time_elapsed         | 110      |
|    total_timesteps      | 149504   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00321 |
|    explained_variance   | 0.9      |
|    learning_rate        | 0.0003   |
|    loss                 | 11.7     |
|    n_updates            | 720      |
|    policy_gradient_loss | 7.85e-10 |
|    value_loss           | 71.6     |
--------------------------------------
Eval num_timesteps=150000, episode_reward=129.39 +/- 116.68
Episode length: 149.60 +/- 92.35
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 150           |
|    mean_reward          | 129           |
| time/                   |               |
|    total_timesteps      | 150000        |
| train/                  |               |
|    approx_kl            | 1.1453696e-05 |
|    clip_fraction        | 0.000342      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00298      |
|    explained_variance   | 0.919         |
|    learning_rate        | 0.0003        |
|    loss                 | 4.41          |
|    n_updates            | 730           |
|    policy_gradient_loss | -0.000157     |
|    value_loss           | 24.9          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 131      |
|    ep_rew_mean     | 106      |
| time/              |          |
|    fps             | 1348     |
|    iterations      | 74       |
|    time_elapsed    | 112      |
|    total_timesteps | 151552   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 129           |
|    ep_rew_mean          | 103           |
| time/                   |               |
|    fps                  | 1350          |
|    iterations           | 75            |
|    time_elapsed         | 113           |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 1.0684016e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00286      |
|    explained_variance   | 0.863         |
|    learning_rate        | 0.0003        |
|    loss                 | 3.38          |
|    n_updates            | 740           |
|    policy_gradient_loss | -6.42e-07     |
|    value_loss           | 51.3          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 136       |
|    ep_rew_mean          | 113       |
| time/                   |           |
|    fps                  | 1352      |
|    iterations           | 76        |
|    time_elapsed         | 115       |
|    total_timesteps      | 155648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00283  |
|    explained_variance   | 0.963     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.28      |
|    n_updates            | 750       |
|    policy_gradient_loss | -7.83e-09 |
|    value_loss           | 11.3      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 140          |
|    ep_rew_mean          | 117          |
| time/                   |              |
|    fps                  | 1353         |
|    iterations           | 77           |
|    time_elapsed         | 116          |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 9.627547e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00283     |
|    explained_variance   | 0.916        |
|    learning_rate        | 0.0003       |
|    loss                 | 4.03         |
|    n_updates            | 760          |
|    policy_gradient_loss | -1.94e-06    |
|    value_loss           | 66.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 140           |
|    ep_rew_mean          | 117           |
| time/                   |               |
|    fps                  | 1355          |
|    iterations           | 78            |
|    time_elapsed         | 117           |
|    total_timesteps      | 159744        |
| train/                  |               |
|    approx_kl            | 1.4743593e-05 |
|    clip_fraction        | 0.000195      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0025       |
|    explained_variance   | 0.87          |
|    learning_rate        | 0.0003        |
|    loss                 | 122           |
|    n_updates            | 770           |
|    policy_gradient_loss | -0.00021      |
|    value_loss           | 69            |
-------------------------------------------
Eval num_timesteps=160000, episode_reward=127.67 +/- 113.27
Episode length: 147.80 +/- 88.89
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 148         |
|    mean_reward          | 128         |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 8.73243e-06 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00232    |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.0003      |
|    loss                 | 20.1        |
|    n_updates            | 780         |
|    policy_gradient_loss | -3.52e-05   |
|    value_loss           | 73.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | 127      |
| time/              |          |
|    fps             | 1352     |
|    iterations      | 79       |
|    time_elapsed    | 119      |
|    total_timesteps | 161792   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 149       |
|    ep_rew_mean          | 129       |
| time/                   |           |
|    fps                  | 1353      |
|    iterations           | 80        |
|    time_elapsed         | 121       |
|    total_timesteps      | 163840    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00216  |
|    explained_variance   | 0.903     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.52      |
|    n_updates            | 790       |
|    policy_gradient_loss | -7.55e-08 |
|    value_loss           | 37.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 153       |
|    ep_rew_mean          | 134       |
| time/                   |           |
|    fps                  | 1355      |
|    iterations           | 81        |
|    time_elapsed         | 122       |
|    total_timesteps      | 165888    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00218  |
|    explained_variance   | 0.78      |
|    learning_rate        | 0.0003    |
|    loss                 | 68.8      |
|    n_updates            | 800       |
|    policy_gradient_loss | -2.44e-08 |
|    value_loss           | 167       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 149       |
|    ep_rew_mean          | 129       |
| time/                   |           |
|    fps                  | 1356      |
|    iterations           | 82        |
|    time_elapsed         | 123       |
|    total_timesteps      | 167936    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00219  |
|    explained_variance   | 0.964     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.05      |
|    n_updates            | 810       |
|    policy_gradient_loss | -2.48e-08 |
|    value_loss           | 7.72      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 136       |
|    ep_rew_mean          | 113       |
| time/                   |           |
|    fps                  | 1357      |
|    iterations           | 83        |
|    time_elapsed         | 125       |
|    total_timesteps      | 169984    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00221  |
|    explained_variance   | 0.987     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.52      |
|    n_updates            | 820       |
|    policy_gradient_loss | -2.26e-08 |
|    value_loss           | 9.68      |
---------------------------------------
Eval num_timesteps=170000, episode_reward=79.33 +/- 115.53
Episode length: 109.60 +/- 91.37
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 110           |
|    mean_reward          | 79.3          |
| time/                   |               |
|    total_timesteps      | 170000        |
| train/                  |               |
|    approx_kl            | 4.3655746e-10 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00226      |
|    explained_variance   | 0.908         |
|    learning_rate        | 0.0003        |
|    loss                 | 103           |
|    n_updates            | 830           |
|    policy_gradient_loss | 3.89e-09      |
|    value_loss           | 131           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 140      |
|    ep_rew_mean     | 117      |
| time/              |          |
|    fps             | 1357     |
|    iterations      | 84       |
|    time_elapsed    | 126      |
|    total_timesteps | 172032   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 132       |
|    ep_rew_mean          | 108       |
| time/                   |           |
|    fps                  | 1358      |
|    iterations           | 85        |
|    time_elapsed         | 128       |
|    total_timesteps      | 174080    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0022   |
|    explained_variance   | 0.893     |
|    learning_rate        | 0.0003    |
|    loss                 | 78.5      |
|    n_updates            | 840       |
|    policy_gradient_loss | -1.56e-08 |
|    value_loss           | 47.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 133       |
|    ep_rew_mean          | 108       |
| time/                   |           |
|    fps                  | 1359      |
|    iterations           | 86        |
|    time_elapsed         | 129       |
|    total_timesteps      | 176128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00225  |
|    explained_variance   | 0.897     |
|    learning_rate        | 0.0003    |
|    loss                 | 37.5      |
|    n_updates            | 850       |
|    policy_gradient_loss | -3.86e-08 |
|    value_loss           | 85.2      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 125         |
|    ep_rew_mean          | 98.7        |
| time/                   |             |
|    fps                  | 1361        |
|    iterations           | 87          |
|    time_elapsed         | 130         |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 6.53381e-08 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0022     |
|    explained_variance   | 0.862       |
|    learning_rate        | 0.0003      |
|    loss                 | 15.7        |
|    n_updates            | 860         |
|    policy_gradient_loss | -7.12e-07   |
|    value_loss           | 108         |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=175.41 +/- 96.22
Episode length: 185.80 +/- 76.42
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 186          |
|    mean_reward          | 175          |
| time/                   |              |
|    total_timesteps      | 180000       |
| train/                  |              |
|    approx_kl            | 1.618173e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0022      |
|    explained_variance   | 0.907        |
|    learning_rate        | 0.0003       |
|    loss                 | 4.24         |
|    n_updates            | 870          |
|    policy_gradient_loss | -1.72e-06    |
|    value_loss           | 69           |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 131      |
|    ep_rew_mean     | 106      |
| time/              |          |
|    fps             | 1359     |
|    iterations      | 88       |
|    time_elapsed    | 132      |
|    total_timesteps | 180224   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 134       |
|    ep_rew_mean          | 111       |
| time/                   |           |
|    fps                  | 1361      |
|    iterations           | 89        |
|    time_elapsed         | 133       |
|    total_timesteps      | 182272    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00216  |
|    explained_variance   | 0.939     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.04      |
|    n_updates            | 880       |
|    policy_gradient_loss | -2.41e-08 |
|    value_loss           | 18.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 144       |
|    ep_rew_mean          | 122       |
| time/                   |           |
|    fps                  | 1362      |
|    iterations           | 90        |
|    time_elapsed         | 135       |
|    total_timesteps      | 184320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00215  |
|    explained_variance   | 0.957     |
|    learning_rate        | 0.0003    |
|    loss                 | 35.4      |
|    n_updates            | 890       |
|    policy_gradient_loss | -6.52e-08 |
|    value_loss           | 28        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 147       |
|    ep_rew_mean          | 127       |
| time/                   |           |
|    fps                  | 1363      |
|    iterations           | 91        |
|    time_elapsed         | 136       |
|    total_timesteps      | 186368    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00216  |
|    explained_variance   | 0.938     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.22      |
|    n_updates            | 900       |
|    policy_gradient_loss | -1.77e-07 |
|    value_loss           | 26.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 149       |
|    ep_rew_mean          | 129       |
| time/                   |           |
|    fps                  | 1364      |
|    iterations           | 92        |
|    time_elapsed         | 138       |
|    total_timesteps      | 188416    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0022   |
|    explained_variance   | 0.979     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.76      |
|    n_updates            | 910       |
|    policy_gradient_loss | -8.13e-08 |
|    value_loss           | 2.77      |
---------------------------------------
Eval num_timesteps=190000, episode_reward=172.42 +/- 93.73
Episode length: 182.80 +/- 73.92
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 183       |
|    mean_reward          | 172       |
| time/                   |           |
|    total_timesteps      | 190000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0022   |
|    explained_variance   | 0.898     |
|    learning_rate        | 0.0003    |
|    loss                 | 15.5      |
|    n_updates            | 920       |
|    policy_gradient_loss | -1.14e-07 |
|    value_loss           | 70.4      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 156      |
|    ep_rew_mean     | 138      |
| time/              |          |
|    fps             | 1360     |
|    iterations      | 93       |
|    time_elapsed    | 139      |
|    total_timesteps | 190464   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 156       |
|    ep_rew_mean          | 138       |
| time/                   |           |
|    fps                  | 1362      |
|    iterations           | 94        |
|    time_elapsed         | 141       |
|    total_timesteps      | 192512    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00225  |
|    explained_variance   | 0.891     |
|    learning_rate        | 0.0003    |
|    loss                 | 7.18      |
|    n_updates            | 930       |
|    policy_gradient_loss | -1.01e-07 |
|    value_loss           | 48.1      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 158          |
|    ep_rew_mean          | 140          |
| time/                   |              |
|    fps                  | 1363         |
|    iterations           | 95           |
|    time_elapsed         | 142          |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 1.956377e-05 |
|    clip_fraction        | 0.000195     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00247     |
|    explained_variance   | 0.965        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.32         |
|    n_updates            | 940          |
|    policy_gradient_loss | -8.98e-05    |
|    value_loss           | 11.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 158           |
|    ep_rew_mean          | 141           |
| time/                   |               |
|    fps                  | 1364          |
|    iterations           | 96            |
|    time_elapsed         | 144           |
|    total_timesteps      | 196608        |
| train/                  |               |
|    approx_kl            | 3.6670826e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00275      |
|    explained_variance   | 0.862         |
|    learning_rate        | 0.0003        |
|    loss                 | 7.15          |
|    n_updates            | 950           |
|    policy_gradient_loss | -8.86e-07     |
|    value_loss           | 112           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 158           |
|    ep_rew_mean          | 140           |
| time/                   |               |
|    fps                  | 1365          |
|    iterations           | 97            |
|    time_elapsed         | 145           |
|    total_timesteps      | 198656        |
| train/                  |               |
|    approx_kl            | 5.8149453e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00277      |
|    explained_variance   | 0.827         |
|    learning_rate        | 0.0003        |
|    loss                 | 87.3          |
|    n_updates            | 960           |
|    policy_gradient_loss | -1.06e-06     |
|    value_loss           | 87            |
-------------------------------------------
Eval num_timesteps=200000, episode_reward=129.79 +/- 113.73
Episode length: 150.00 +/- 89.41
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 150       |
|    mean_reward          | 130       |
| time/                   |           |
|    total_timesteps      | 200000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00274  |
|    explained_variance   | 0.906     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.51      |
|    n_updates            | 970       |
|    policy_gradient_loss | -2.77e-08 |
|    value_loss           | 67.4      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 160      |
|    ep_rew_mean     | 143      |
| time/              |          |
|    fps             | 1356     |
|    iterations      | 98       |
|    time_elapsed    | 147      |
|    total_timesteps | 200704   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 156       |
|    ep_rew_mean          | 139       |
| time/                   |           |
|    fps                  | 1358      |
|    iterations           | 99        |
|    time_elapsed         | 149       |
|    total_timesteps      | 202752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00274  |
|    explained_variance   | 0.951     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.3       |
|    n_updates            | 980       |
|    policy_gradient_loss | -6.56e-08 |
|    value_loss           | 27.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 156       |
|    ep_rew_mean          | 139       |
| time/                   |           |
|    fps                  | 1359      |
|    iterations           | 100       |
|    time_elapsed         | 150       |
|    total_timesteps      | 204800    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00278  |
|    explained_variance   | 0.844     |
|    learning_rate        | 0.0003    |
|    loss                 | 40.8      |
|    n_updates            | 990       |
|    policy_gradient_loss | -1.03e-07 |
|    value_loss           | 86.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 151       |
|    ep_rew_mean          | 132       |
| time/                   |           |
|    fps                  | 1360      |
|    iterations           | 101       |
|    time_elapsed         | 152       |
|    total_timesteps      | 206848    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00273  |
|    explained_variance   | 0.975     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.37      |
|    n_updates            | 1000      |
|    policy_gradient_loss | -3.51e-08 |
|    value_loss           | 10.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 153       |
|    ep_rew_mean          | 135       |
| time/                   |           |
|    fps                  | 1361      |
|    iterations           | 102       |
|    time_elapsed         | 153       |
|    total_timesteps      | 208896    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00278  |
|    explained_variance   | 0.956     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.84      |
|    n_updates            | 1010      |
|    policy_gradient_loss | -5.66e-08 |
|    value_loss           | 23.2      |
---------------------------------------
Eval num_timesteps=210000, episode_reward=127.87 +/- 114.65
Episode length: 148.20 +/- 90.43
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 148       |
|    mean_reward          | 128       |
| time/                   |           |
|    total_timesteps      | 210000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00283  |
|    explained_variance   | 0.846     |
|    learning_rate        | 0.0003    |
|    loss                 | 9.55      |
|    n_updates            | 1020      |
|    policy_gradient_loss | -7.42e-08 |
|    value_loss           | 118       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 155      |
|    ep_rew_mean     | 137      |
| time/              |          |
|    fps             | 1354     |
|    iterations      | 103      |
|    time_elapsed    | 155      |
|    total_timesteps | 210944   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 153      |
|    ep_rew_mean          | 134      |
| time/                   |          |
|    fps                  | 1356     |
|    iterations           | 104      |
|    time_elapsed         | 157      |
|    total_timesteps      | 212992   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00279 |
|    explained_variance   | 0.885    |
|    learning_rate        | 0.0003   |
|    loss                 | 1.01     |
|    n_updates            | 1030     |
|    policy_gradient_loss | 7.87e-09 |
|    value_loss           | 43.7     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 148       |
|    ep_rew_mean          | 127       |
| time/                   |           |
|    fps                  | 1357      |
|    iterations           | 105       |
|    time_elapsed         | 158       |
|    total_timesteps      | 215040    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00286  |
|    explained_variance   | 0.853     |
|    learning_rate        | 0.0003    |
|    loss                 | 183       |
|    n_updates            | 1040      |
|    policy_gradient_loss | -1.27e-08 |
|    value_loss           | 125       |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 149           |
|    ep_rew_mean          | 130           |
| time/                   |               |
|    fps                  | 1358          |
|    iterations           | 106           |
|    time_elapsed         | 159           |
|    total_timesteps      | 217088        |
| train/                  |               |
|    approx_kl            | 1.9062136e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00273      |
|    explained_variance   | 0.946         |
|    learning_rate        | 0.0003        |
|    loss                 | 1.51          |
|    n_updates            | 1050          |
|    policy_gradient_loss | -1.48e-05     |
|    value_loss           | 13.5          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 157      |
|    ep_rew_mean          | 139      |
| time/                   |          |
|    fps                  | 1359     |
|    iterations           | 107      |
|    time_elapsed         | 161      |
|    total_timesteps      | 219136   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00259 |
|    explained_variance   | 0.796    |
|    learning_rate        | 0.0003   |
|    loss                 | 53.4     |
|    n_updates            | 1060     |
|    policy_gradient_loss | 1.5e-09  |
|    value_loss           | 97.3     |
--------------------------------------
Eval num_timesteps=220000, episode_reward=129.85 +/- 116.23
Episode length: 150.00 +/- 91.86
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 150           |
|    mean_reward          | 130           |
| time/                   |               |
|    total_timesteps      | 220000        |
| train/                  |               |
|    approx_kl            | 2.3435103e-05 |
|    clip_fraction        | 4.88e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00245      |
|    explained_variance   | 0.982         |
|    learning_rate        | 0.0003        |
|    loss                 | 1.62          |
|    n_updates            | 1070          |
|    policy_gradient_loss | -8.94e-05     |
|    value_loss           | 4.45          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | 129      |
| time/              |          |
|    fps             | 1350     |
|    iterations      | 108      |
|    time_elapsed    | 163      |
|    total_timesteps | 221184   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 155       |
|    ep_rew_mean          | 137       |
| time/                   |           |
|    fps                  | 1351      |
|    iterations           | 109       |
|    time_elapsed         | 165       |
|    total_timesteps      | 223232    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0023   |
|    explained_variance   | 0.942     |
|    learning_rate        | 0.0003    |
|    loss                 | 23.2      |
|    n_updates            | 1080      |
|    policy_gradient_loss | -6.62e-08 |
|    value_loss           | 42.3      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 153           |
|    ep_rew_mean          | 134           |
| time/                   |               |
|    fps                  | 1352          |
|    iterations           | 110           |
|    time_elapsed         | 166           |
|    total_timesteps      | 225280        |
| train/                  |               |
|    approx_kl            | 2.1915184e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00232      |
|    explained_variance   | 0.774         |
|    learning_rate        | 0.0003        |
|    loss                 | 60.1          |
|    n_updates            | 1090          |
|    policy_gradient_loss | -5.35e-07     |
|    value_loss           | 156           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 153           |
|    ep_rew_mean          | 134           |
| time/                   |               |
|    fps                  | 1353          |
|    iterations           | 111           |
|    time_elapsed         | 167           |
|    total_timesteps      | 227328        |
| train/                  |               |
|    approx_kl            | 1.0195014e-05 |
|    clip_fraction        | 0.000391      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00248      |
|    explained_variance   | 0.943         |
|    learning_rate        | 0.0003        |
|    loss                 | 1.76          |
|    n_updates            | 1100          |
|    policy_gradient_loss | -0.000164     |
|    value_loss           | 44            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 155           |
|    ep_rew_mean          | 136           |
| time/                   |               |
|    fps                  | 1354          |
|    iterations           | 112           |
|    time_elapsed         | 169           |
|    total_timesteps      | 229376        |
| train/                  |               |
|    approx_kl            | 2.6864436e-05 |
|    clip_fraction        | 4.88e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00232      |
|    explained_variance   | 0.964         |
|    learning_rate        | 0.0003        |
|    loss                 | 9.76          |
|    n_updates            | 1110          |
|    policy_gradient_loss | -0.000134     |
|    value_loss           | 38.3          |
-------------------------------------------
Eval num_timesteps=230000, episode_reward=81.07 +/- 114.86
Episode length: 111.40 +/- 90.78
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 111          |
|    mean_reward          | 81.1         |
| time/                   |              |
|    total_timesteps      | 230000       |
| train/                  |              |
|    approx_kl            | 6.046321e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00211     |
|    explained_variance   | 0.929        |
|    learning_rate        | 0.0003       |
|    loss                 | 73.5         |
|    n_updates            | 1120         |
|    policy_gradient_loss | -9.81e-06    |
|    value_loss           | 53.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 157      |
|    ep_rew_mean     | 139      |
| time/              |          |
|    fps             | 1344     |
|    iterations      | 113      |
|    time_elapsed    | 172      |
|    total_timesteps | 231424   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 155       |
|    ep_rew_mean          | 136       |
| time/                   |           |
|    fps                  | 1345      |
|    iterations           | 114       |
|    time_elapsed         | 173       |
|    total_timesteps      | 233472    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00209  |
|    explained_variance   | 0.939     |
|    learning_rate        | 0.0003    |
|    loss                 | 23.9      |
|    n_updates            | 1130      |
|    policy_gradient_loss | -4.15e-09 |
|    value_loss           | 53.7      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 153           |
|    ep_rew_mean          | 134           |
| time/                   |               |
|    fps                  | 1346          |
|    iterations           | 115           |
|    time_elapsed         | 174           |
|    total_timesteps      | 235520        |
| train/                  |               |
|    approx_kl            | 1.5586586e-05 |
|    clip_fraction        | 9.77e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00193      |
|    explained_variance   | 0.965         |
|    learning_rate        | 0.0003        |
|    loss                 | 1.48          |
|    n_updates            | 1140          |
|    policy_gradient_loss | -8.98e-05     |
|    value_loss           | 19            |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 149       |
|    ep_rew_mean          | 129       |
| time/                   |           |
|    fps                  | 1347      |
|    iterations           | 116       |
|    time_elapsed         | 176       |
|    total_timesteps      | 237568    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00187  |
|    explained_variance   | 0.941     |
|    learning_rate        | 0.0003    |
|    loss                 | 31.8      |
|    n_updates            | 1150      |
|    policy_gradient_loss | -1.34e-08 |
|    value_loss           | 35.8      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 144          |
|    ep_rew_mean          | 122          |
| time/                   |              |
|    fps                  | 1348         |
|    iterations           | 117          |
|    time_elapsed         | 177          |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 3.160676e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00189     |
|    explained_variance   | 0.98         |
|    learning_rate        | 0.0003       |
|    loss                 | 5.68         |
|    n_updates            | 1160         |
|    policy_gradient_loss | -2.98e-07    |
|    value_loss           | 16.7         |
------------------------------------------
Eval num_timesteps=240000, episode_reward=32.86 +/- 93.75
Episode length: 73.00 +/- 74.04
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 73        |
|    mean_reward          | 32.9      |
| time/                   |           |
|    total_timesteps      | 240000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00188  |
|    explained_variance   | 0.876     |
|    learning_rate        | 0.0003    |
|    loss                 | 61.4      |
|    n_updates            | 1170      |
|    policy_gradient_loss | -8.63e-09 |
|    value_loss           | 80        |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 138      |
|    ep_rew_mean     | 115      |
| time/              |          |
|    fps             | 1344     |
|    iterations      | 118      |
|    time_elapsed    | 179      |
|    total_timesteps | 241664   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 130       |
|    ep_rew_mean          | 106       |
| time/                   |           |
|    fps                  | 1345      |
|    iterations           | 119       |
|    time_elapsed         | 181       |
|    total_timesteps      | 243712    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00189  |
|    explained_variance   | 0.937     |
|    learning_rate        | 0.0003    |
|    loss                 | 16.8      |
|    n_updates            | 1180      |
|    policy_gradient_loss | -1.34e-08 |
|    value_loss           | 60        |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 127           |
|    ep_rew_mean          | 101           |
| time/                   |               |
|    fps                  | 1346          |
|    iterations           | 120           |
|    time_elapsed         | 182           |
|    total_timesteps      | 245760        |
| train/                  |               |
|    approx_kl            | 3.8713333e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00181      |
|    explained_variance   | 0.981         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.607         |
|    n_updates            | 1190          |
|    policy_gradient_loss | -3.77e-05     |
|    value_loss           | 16.8          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 128      |
|    ep_rew_mean          | 103      |
| time/                   |          |
|    fps                  | 1347     |
|    iterations           | 121      |
|    time_elapsed         | 183      |
|    total_timesteps      | 247808   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00167 |
|    explained_variance   | 0.977    |
|    learning_rate        | 0.0003   |
|    loss                 | 1.73     |
|    n_updates            | 1200     |
|    policy_gradient_loss | -4.6e-09 |
|    value_loss           | 12.1     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 129       |
|    ep_rew_mean          | 103       |
| time/                   |           |
|    fps                  | 1348      |
|    iterations           | 122       |
|    time_elapsed         | 185       |
|    total_timesteps      | 249856    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00168  |
|    explained_variance   | 0.94      |
|    learning_rate        | 0.0003    |
|    loss                 | 12        |
|    n_updates            | 1210      |
|    policy_gradient_loss | -5.57e-08 |
|    value_loss           | 57.9      |
---------------------------------------
Eval num_timesteps=250000, episode_reward=81.18 +/- 113.33
Episode length: 111.40 +/- 89.11
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 111           |
|    mean_reward          | 81.2          |
| time/                   |               |
|    total_timesteps      | 250000        |
| train/                  |               |
|    approx_kl            | 8.0055906e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00166      |
|    explained_variance   | 0.984         |
|    learning_rate        | 0.0003        |
|    loss                 | 1.71          |
|    n_updates            | 1220          |
|    policy_gradient_loss | -1.62e-05     |
|    value_loss           | 8.18          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 140      |
|    ep_rew_mean     | 117      |
| time/              |          |
|    fps             | 1344     |
|    iterations      | 123      |
|    time_elapsed    | 187      |
|    total_timesteps | 251904   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 136       |
|    ep_rew_mean          | 113       |
| time/                   |           |
|    fps                  | 1345      |
|    iterations           | 124       |
|    time_elapsed         | 188       |
|    total_timesteps      | 253952    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00158  |
|    explained_variance   | 0.996     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.351     |
|    n_updates            | 1230      |
|    policy_gradient_loss | -2.34e-08 |
|    value_loss           | 2.31      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 140      |
|    ep_rew_mean          | 117      |
| time/                   |          |
|    fps                  | 1346     |
|    iterations           | 125      |
|    time_elapsed         | 190      |
|    total_timesteps      | 256000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00159 |
|    explained_variance   | 0.992    |
|    learning_rate        | 0.0003   |
|    loss                 | 15.6     |
|    n_updates            | 1240     |
|    policy_gradient_loss | -1.3e-08 |
|    value_loss           | 9.26     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 147           |
|    ep_rew_mean          | 127           |
| time/                   |               |
|    fps                  | 1347          |
|    iterations           | 126           |
|    time_elapsed         | 191           |
|    total_timesteps      | 258048        |
| train/                  |               |
|    approx_kl            | 1.5210913e-05 |
|    clip_fraction        | 0.000146      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00152      |
|    explained_variance   | 0.964         |
|    learning_rate        | 0.0003        |
|    loss                 | 24.8          |
|    n_updates            | 1250          |
|    policy_gradient_loss | -0.000105     |
|    value_loss           | 44.1          |
-------------------------------------------
Eval num_timesteps=260000, episode_reward=126.37 +/- 116.27
Episode length: 146.80 +/- 92.14
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 147       |
|    mean_reward          | 126       |
| time/                   |           |
|    total_timesteps      | 260000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00143  |
|    explained_variance   | 0.915     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.54      |
|    n_updates            | 1260      |
|    policy_gradient_loss | -1.92e-08 |
|    value_loss           | 50.1      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 155      |
|    ep_rew_mean     | 137      |
| time/              |          |
|    fps             | 1346     |
|    iterations      | 127      |
|    time_elapsed    | 193      |
|    total_timesteps | 260096   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 149       |
|    ep_rew_mean          | 129       |
| time/                   |           |
|    fps                  | 1347      |
|    iterations           | 128       |
|    time_elapsed         | 194       |
|    total_timesteps      | 262144    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00144  |
|    explained_variance   | 0.982     |
|    learning_rate        | 0.0003    |
|    loss                 | 11.8      |
|    n_updates            | 1270      |
|    policy_gradient_loss | -1.12e-08 |
|    value_loss           | 7.29      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 153          |
|    ep_rew_mean          | 134          |
| time/                   |              |
|    fps                  | 1348         |
|    iterations           | 129          |
|    time_elapsed         | 195          |
|    total_timesteps      | 264192       |
| train/                  |              |
|    approx_kl            | 8.119969e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00146     |
|    explained_variance   | 0.901        |
|    learning_rate        | 0.0003       |
|    loss                 | 91.9         |
|    n_updates            | 1280         |
|    policy_gradient_loss | -1.63e-06    |
|    value_loss           | 109          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 148           |
|    ep_rew_mean          | 127           |
| time/                   |               |
|    fps                  | 1349          |
|    iterations           | 130           |
|    time_elapsed         | 197           |
|    total_timesteps      | 266240        |
| train/                  |               |
|    approx_kl            | 2.0733569e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00144      |
|    explained_variance   | 0.99          |
|    learning_rate        | 0.0003        |
|    loss                 | 2.76          |
|    n_updates            | 1290          |
|    policy_gradient_loss | -2.59e-06     |
|    value_loss           | 3.83          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 148       |
|    ep_rew_mean          | 127       |
| time/                   |           |
|    fps                  | 1350      |
|    iterations           | 131       |
|    time_elapsed         | 198       |
|    total_timesteps      | 268288    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00145  |
|    explained_variance   | 0.965     |
|    learning_rate        | 0.0003    |
|    loss                 | 34.1      |
|    n_updates            | 1300      |
|    policy_gradient_loss | -5.84e-09 |
|    value_loss           | 42.8      |
---------------------------------------
Eval num_timesteps=270000, episode_reward=78.48 +/- 114.90
Episode length: 108.60 +/- 90.56
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 109          |
|    mean_reward          | 78.5         |
| time/                   |              |
|    total_timesteps      | 270000       |
| train/                  |              |
|    approx_kl            | 8.547795e-08 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00144     |
|    explained_variance   | 0.908        |
|    learning_rate        | 0.0003       |
|    loss                 | 18.1         |
|    n_updates            | 1310         |
|    policy_gradient_loss | -1.77e-06    |
|    value_loss           | 66.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | 122      |
| time/              |          |
|    fps             | 1347     |
|    iterations      | 132      |
|    time_elapsed    | 200      |
|    total_timesteps | 270336   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 142       |
|    ep_rew_mean          | 120       |
| time/                   |           |
|    fps                  | 1347      |
|    iterations           | 133       |
|    time_elapsed         | 202       |
|    total_timesteps      | 272384    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00142  |
|    explained_variance   | 0.936     |
|    learning_rate        | 0.0003    |
|    loss                 | 11.5      |
|    n_updates            | 1320      |
|    policy_gradient_loss | -1.82e-08 |
|    value_loss           | 55.1      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 138      |
|    ep_rew_mean          | 115      |
| time/                   |          |
|    fps                  | 1348     |
|    iterations           | 134      |
|    time_elapsed         | 203      |
|    total_timesteps      | 274432   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00141 |
|    explained_variance   | 0.962    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.586    |
|    n_updates            | 1330     |
|    policy_gradient_loss | 1.25e-09 |
|    value_loss           | 18.6     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 138           |
|    ep_rew_mean          | 115           |
| time/                   |               |
|    fps                  | 1349          |
|    iterations           | 135           |
|    time_elapsed         | 204           |
|    total_timesteps      | 276480        |
| train/                  |               |
|    approx_kl            | 1.0963413e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00142      |
|    explained_variance   | 0.906         |
|    learning_rate        | 0.0003        |
|    loss                 | 74            |
|    n_updates            | 1340          |
|    policy_gradient_loss | -7.23e-07     |
|    value_loss           | 96.4          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 138       |
|    ep_rew_mean          | 115       |
| time/                   |           |
|    fps                  | 1350      |
|    iterations           | 136       |
|    time_elapsed         | 206       |
|    total_timesteps      | 278528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0014   |
|    explained_variance   | 0.971     |
|    learning_rate        | 0.0003    |
|    loss                 | 5.79      |
|    n_updates            | 1350      |
|    policy_gradient_loss | -1.42e-08 |
|    value_loss           | 7.28      |
---------------------------------------
Eval num_timesteps=280000, episode_reward=126.39 +/- 117.92
Episode length: 146.80 +/- 93.77
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 147           |
|    mean_reward          | 126           |
| time/                   |               |
|    total_timesteps      | 280000        |
| train/                  |               |
|    approx_kl            | 1.2647797e-05 |
|    clip_fraction        | 0.000146      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00132      |
|    explained_variance   | 0.897         |
|    learning_rate        | 0.0003        |
|    loss                 | 18            |
|    n_updates            | 1360          |
|    policy_gradient_loss | -6.68e-05     |
|    value_loss           | 97.4          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | 120      |
| time/              |          |
|    fps             | 1345     |
|    iterations      | 137      |
|    time_elapsed    | 208      |
|    total_timesteps | 280576   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 142       |
|    ep_rew_mean          | 120       |
| time/                   |           |
|    fps                  | 1346      |
|    iterations           | 138       |
|    time_elapsed         | 209       |
|    total_timesteps      | 282624    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00129  |
|    explained_variance   | 0.912     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.12      |
|    n_updates            | 1370      |
|    policy_gradient_loss | -1.01e-08 |
|    value_loss           | 72.4      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 144          |
|    ep_rew_mean          | 123          |
| time/                   |              |
|    fps                  | 1347         |
|    iterations           | 139          |
|    time_elapsed         | 211          |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 4.572823e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00123     |
|    explained_variance   | 0.968        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.84         |
|    n_updates            | 1380         |
|    policy_gradient_loss | -4.2e-05     |
|    value_loss           | 7.93         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 137       |
|    ep_rew_mean          | 113       |
| time/                   |           |
|    fps                  | 1347      |
|    iterations           | 140       |
|    time_elapsed         | 212       |
|    total_timesteps      | 286720    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00116  |
|    explained_variance   | 0.989     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.88      |
|    n_updates            | 1390      |
|    policy_gradient_loss | -1.74e-08 |
|    value_loss           | 12.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 139       |
|    ep_rew_mean          | 116       |
| time/                   |           |
|    fps                  | 1346      |
|    iterations           | 141       |
|    time_elapsed         | 214       |
|    total_timesteps      | 288768    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00117  |
|    explained_variance   | 0.914     |
|    learning_rate        | 0.0003    |
|    loss                 | 73.4      |
|    n_updates            | 1400      |
|    policy_gradient_loss | -3.92e-10 |
|    value_loss           | 101       |
---------------------------------------
Eval num_timesteps=290000, episode_reward=33.84 +/- 94.68
Episode length: 74.00 +/- 75.01
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 74        |
|    mean_reward          | 33.8      |
| time/                   |           |
|    total_timesteps      | 290000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00117  |
|    explained_variance   | 0.99      |
|    learning_rate        | 0.0003    |
|    loss                 | 2.74      |
|    n_updates            | 1410      |
|    policy_gradient_loss | -1.98e-09 |
|    value_loss           | 5.38      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 141      |
|    ep_rew_mean     | 118      |
| time/              |          |
|    fps             | 1340     |
|    iterations      | 142      |
|    time_elapsed    | 217      |
|    total_timesteps | 290816   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 146           |
|    ep_rew_mean          | 125           |
| time/                   |               |
|    fps                  | 1341          |
|    iterations           | 143           |
|    time_elapsed         | 218           |
|    total_timesteps      | 292864        |
| train/                  |               |
|    approx_kl            | 1.2078177e-05 |
|    clip_fraction        | 0.000146      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.000995     |
|    explained_variance   | 0.915         |
|    learning_rate        | 0.0003        |
|    loss                 | 1.72          |
|    n_updates            | 1420          |
|    policy_gradient_loss | -5.93e-05     |
|    value_loss           | 63            |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 142       |
|    ep_rew_mean          | 120       |
| time/                   |           |
|    fps                  | 1341      |
|    iterations           | 144       |
|    time_elapsed         | 219       |
|    total_timesteps      | 294912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000986 |
|    explained_variance   | 0.993     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.811     |
|    n_updates            | 1430      |
|    policy_gradient_loss | -4.05e-09 |
|    value_loss           | 3.95      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 142       |
|    ep_rew_mean          | 120       |
| time/                   |           |
|    fps                  | 1342      |
|    iterations           | 145       |
|    time_elapsed         | 221       |
|    total_timesteps      | 296960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000984 |
|    explained_variance   | 0.923     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.5       |
|    n_updates            | 1440      |
|    policy_gradient_loss | -8.05e-10 |
|    value_loss           | 82.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 146       |
|    ep_rew_mean          | 125       |
| time/                   |           |
|    fps                  | 1343      |
|    iterations           | 146       |
|    time_elapsed         | 222       |
|    total_timesteps      | 299008    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000977 |
|    explained_variance   | 0.991     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.646     |
|    n_updates            | 1450      |
|    policy_gradient_loss | -1.08e-08 |
|    value_loss           | 2.71      |
---------------------------------------
Eval num_timesteps=300000, episode_reward=128.14 +/- 113.64
Episode length: 148.40 +/- 89.37
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 148       |
|    mean_reward          | 128       |
| time/                   |           |
|    total_timesteps      | 300000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000985 |
|    explained_variance   | 0.986     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.55      |
|    n_updates            | 1460      |
|    policy_gradient_loss | -2e-08    |
|    value_loss           | 16.1      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 151      |
|    ep_rew_mean     | 132      |
| time/              |          |
|    fps             | 1335     |
|    iterations      | 147      |
|    time_elapsed    | 225      |
|    total_timesteps | 301056   |
---------------------------------

Training complete!
Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-09_01-14-35

