Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-07_23-21-32

Map saved at: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-07_23-21-32/map_visualization.png

Using cpu device
Wrapping the env in a DummyVecEnv.
Logging to /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-07_23-21-32/tensorboard/PPO_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 181      |
|    ep_rew_mean     | 119      |
| time/              |          |
|    fps             | 2612     |
|    iterations      | 1        |
|    time_elapsed    | 0        |
|    total_timesteps | 2048     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 193          |
|    ep_rew_mean          | 136          |
| time/                   |              |
|    fps                  | 1903         |
|    iterations           | 2            |
|    time_elapsed         | 2            |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0077062454 |
|    clip_fraction        | 0.00786      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.69        |
|    explained_variance   | -0.00299     |
|    learning_rate        | 0.0003       |
|    loss                 | 37.3         |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00107     |
|    value_loss           | 107          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 191         |
|    ep_rew_mean          | 135         |
| time/                   |             |
|    fps                  | 1762        |
|    iterations           | 3           |
|    time_elapsed         | 3           |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.002778533 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.685      |
|    explained_variance   | -0.031      |
|    learning_rate        | 0.0003      |
|    loss                 | 13.9        |
|    n_updates            | 20          |
|    policy_gradient_loss | 2.69e-05    |
|    value_loss           | 85.1        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 188        |
|    ep_rew_mean          | 130        |
| time/                   |            |
|    fps                  | 1698       |
|    iterations           | 4          |
|    time_elapsed         | 4          |
|    total_timesteps      | 8192       |
| train/                  |            |
|    approx_kl            | 0.01018589 |
|    clip_fraction        | 0.0191     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.689     |
|    explained_variance   | -0.00865   |
|    learning_rate        | 0.0003     |
|    loss                 | 82.8       |
|    n_updates            | 30         |
|    policy_gradient_loss | -0.00158   |
|    value_loss           | 102        |
----------------------------------------
Eval num_timesteps=10000, episode_reward=104.84 +/- 79.30
Episode length: 163.00 +/- 71.90
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 163         |
|    mean_reward          | 105         |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.009743431 |
|    clip_fraction        | 0.037       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.679      |
|    explained_variance   | -0.00377    |
|    learning_rate        | 0.0003      |
|    loss                 | 60.1        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.000268   |
|    value_loss           | 149         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 185      |
|    ep_rew_mean     | 127      |
| time/              |          |
|    fps             | 1596     |
|    iterations      | 5        |
|    time_elapsed    | 6        |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 184         |
|    ep_rew_mean          | 126         |
| time/                   |             |
|    fps                  | 1586        |
|    iterations           | 6           |
|    time_elapsed         | 7           |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.001345492 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.69       |
|    explained_variance   | -0.000986   |
|    learning_rate        | 0.0003      |
|    loss                 | 101         |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.000662   |
|    value_loss           | 163         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 177          |
|    ep_rew_mean          | 119          |
| time/                   |              |
|    fps                  | 1577         |
|    iterations           | 7            |
|    time_elapsed         | 9            |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 0.0013347574 |
|    clip_fraction        | 0.0298       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.688       |
|    explained_variance   | -0.000928    |
|    learning_rate        | 0.0003       |
|    loss                 | 140          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00125     |
|    value_loss           | 150          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 176         |
|    ep_rew_mean          | 119         |
| time/                   |             |
|    fps                  | 1572        |
|    iterations           | 8           |
|    time_elapsed         | 10          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.004440477 |
|    clip_fraction        | 0.0244      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.683      |
|    explained_variance   | -0.000349   |
|    learning_rate        | 0.0003      |
|    loss                 | 173         |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00158    |
|    value_loss           | 277         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 178          |
|    ep_rew_mean          | 121          |
| time/                   |              |
|    fps                  | 1567         |
|    iterations           | 9            |
|    time_elapsed         | 11           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0047505256 |
|    clip_fraction        | 0.0134       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.674       |
|    explained_variance   | -0.000202    |
|    learning_rate        | 0.0003       |
|    loss                 | 86           |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00153     |
|    value_loss           | 158          |
------------------------------------------
Eval num_timesteps=20000, episode_reward=26.42 +/- 1.98
Episode length: 77.80 +/- 1.17
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 77.8         |
|    mean_reward          | 26.4         |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0046303626 |
|    clip_fraction        | 0.0156       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.672       |
|    explained_variance   | -0.000223    |
|    learning_rate        | 0.0003       |
|    loss                 | 22.9         |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.000639    |
|    value_loss           | 120          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 175      |
|    ep_rew_mean     | 119      |
| time/              |          |
|    fps             | 1550     |
|    iterations      | 10       |
|    time_elapsed    | 13       |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 171          |
|    ep_rew_mean          | 114          |
| time/                   |              |
|    fps                  | 1549         |
|    iterations           | 11           |
|    time_elapsed         | 14           |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0065658437 |
|    clip_fraction        | 0.0126       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.689       |
|    explained_variance   | -0.000147    |
|    learning_rate        | 0.0003       |
|    loss                 | 157          |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00209     |
|    value_loss           | 256          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 169         |
|    ep_rew_mean          | 111         |
| time/                   |             |
|    fps                  | 1547        |
|    iterations           | 12          |
|    time_elapsed         | 15          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.005487805 |
|    clip_fraction        | 0.0292      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.69       |
|    explained_variance   | -9.95e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 73.5        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00194    |
|    value_loss           | 175         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 169          |
|    ep_rew_mean          | 111          |
| time/                   |              |
|    fps                  | 1546         |
|    iterations           | 13           |
|    time_elapsed         | 17           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0109491125 |
|    clip_fraction        | 0.0281       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.673       |
|    explained_variance   | -5.53e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 192          |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00279     |
|    value_loss           | 258          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 170          |
|    ep_rew_mean          | 112          |
| time/                   |              |
|    fps                  | 1545         |
|    iterations           | 14           |
|    time_elapsed         | 18           |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 0.0045887055 |
|    clip_fraction        | 0.0192       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.643       |
|    explained_variance   | -2.84e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 101          |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00109     |
|    value_loss           | 225          |
------------------------------------------
Eval num_timesteps=30000, episode_reward=138.63 +/- 63.93
Episode length: 194.40 +/- 57.75
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 194          |
|    mean_reward          | 139          |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0030762567 |
|    clip_fraction        | 0.059        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.672       |
|    explained_variance   | -5.2e-05     |
|    learning_rate        | 0.0003       |
|    loss                 | 69.9         |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00209     |
|    value_loss           | 152          |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 173      |
|    ep_rew_mean     | 116      |
| time/              |          |
|    fps             | 1524     |
|    iterations      | 15       |
|    time_elapsed    | 20       |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 173         |
|    ep_rew_mean          | 115         |
| time/                   |             |
|    fps                  | 1525        |
|    iterations           | 16          |
|    time_elapsed         | 21          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.007759938 |
|    clip_fraction        | 0.0528      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.684      |
|    explained_variance   | -5.59e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 189         |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.0041     |
|    value_loss           | 157         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 173          |
|    ep_rew_mean          | 115          |
| time/                   |              |
|    fps                  | 1525         |
|    iterations           | 17           |
|    time_elapsed         | 22           |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0056711626 |
|    clip_fraction        | 0.0135       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.671       |
|    explained_variance   | -2.26e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 233          |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00199     |
|    value_loss           | 294          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 174          |
|    ep_rew_mean          | 116          |
| time/                   |              |
|    fps                  | 1525         |
|    iterations           | 18           |
|    time_elapsed         | 24           |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 0.0075174463 |
|    clip_fraction        | 0.0254       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.672       |
|    explained_variance   | -1.99e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 31.1         |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00154     |
|    value_loss           | 185          |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 178        |
|    ep_rew_mean          | 121        |
| time/                   |            |
|    fps                  | 1526       |
|    iterations           | 19         |
|    time_elapsed         | 25         |
|    total_timesteps      | 38912      |
| train/                  |            |
|    approx_kl            | 0.00811303 |
|    clip_fraction        | 0.0477     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.686     |
|    explained_variance   | -1.92e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 106        |
|    n_updates            | 180        |
|    policy_gradient_loss | -0.00444   |
|    value_loss           | 153        |
----------------------------------------
Eval num_timesteps=40000, episode_reward=23.12 +/- 3.53
Episode length: 74.40 +/- 3.50
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 74.4        |
|    mean_reward          | 23.1        |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.004662851 |
|    clip_fraction        | 0.0443      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.692      |
|    explained_variance   | -3.05e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 31.6        |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.00146    |
|    value_loss           | 107         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 177      |
|    ep_rew_mean     | 119      |
| time/              |          |
|    fps             | 1520     |
|    iterations      | 20       |
|    time_elapsed    | 26       |
|    total_timesteps | 40960    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 183           |
|    ep_rew_mean          | 126           |
| time/                   |               |
|    fps                  | 1521          |
|    iterations           | 21            |
|    time_elapsed         | 28            |
|    total_timesteps      | 43008         |
| train/                  |               |
|    approx_kl            | 0.00023643841 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.692        |
|    explained_variance   | -1.42e-05     |
|    learning_rate        | 0.0003        |
|    loss                 | 165           |
|    n_updates            | 200           |
|    policy_gradient_loss | -0.000105     |
|    value_loss           | 255           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 182          |
|    ep_rew_mean          | 126          |
| time/                   |              |
|    fps                  | 1521         |
|    iterations           | 22           |
|    time_elapsed         | 29           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0024469807 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.69        |
|    explained_variance   | -1.48e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 22.1         |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.000999    |
|    value_loss           | 137          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 181         |
|    ep_rew_mean          | 124         |
| time/                   |             |
|    fps                  | 1522        |
|    iterations           | 23          |
|    time_elapsed         | 30          |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.005350955 |
|    clip_fraction        | 0.00684     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.689      |
|    explained_variance   | -8.23e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 92.4        |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0019     |
|    value_loss           | 231         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 182          |
|    ep_rew_mean          | 124          |
| time/                   |              |
|    fps                  | 1522         |
|    iterations           | 24           |
|    time_elapsed         | 32           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0037952391 |
|    clip_fraction        | 0.00273      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.68        |
|    explained_variance   | -8.23e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 64.3         |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.00161     |
|    value_loss           | 227          |
------------------------------------------
Eval num_timesteps=50000, episode_reward=80.66 +/- 74.04
Episode length: 144.40 +/- 65.77
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 144         |
|    mean_reward          | 80.7        |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.008357277 |
|    clip_fraction        | 0.00625     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.662      |
|    explained_variance   | -4.65e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 65.2        |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.00137    |
|    value_loss           | 187         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 185      |
|    ep_rew_mean     | 128      |
| time/              |          |
|    fps             | 1513     |
|    iterations      | 25       |
|    time_elapsed    | 33       |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 186         |
|    ep_rew_mean          | 129         |
| time/                   |             |
|    fps                  | 1514        |
|    iterations           | 26          |
|    time_elapsed         | 35          |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.008896319 |
|    clip_fraction        | 0.0333      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.671      |
|    explained_variance   | -7.15e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 145         |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00138    |
|    value_loss           | 198         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 186          |
|    ep_rew_mean          | 128          |
| time/                   |              |
|    fps                  | 1515         |
|    iterations           | 27           |
|    time_elapsed         | 36           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 0.0022138935 |
|    clip_fraction        | 0.00142      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.665       |
|    explained_variance   | -3.93e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 106          |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.00199     |
|    value_loss           | 163          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 181         |
|    ep_rew_mean          | 123         |
| time/                   |             |
|    fps                  | 1515        |
|    iterations           | 28          |
|    time_elapsed         | 37          |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.011664798 |
|    clip_fraction        | 0.0841      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.685      |
|    explained_variance   | -3.34e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 71.9        |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.00189    |
|    value_loss           | 204         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 183         |
|    ep_rew_mean          | 126         |
| time/                   |             |
|    fps                  | 1516        |
|    iterations           | 29          |
|    time_elapsed         | 39          |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.007710969 |
|    clip_fraction        | 0.0412      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.688      |
|    explained_variance   | -4.41e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 63.9        |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00172    |
|    value_loss           | 255         |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=106.03 +/- 80.07
Episode length: 164.40 +/- 72.63
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 164          |
|    mean_reward          | 106          |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0014375895 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.685       |
|    explained_variance   | -2.5e-06     |
|    learning_rate        | 0.0003       |
|    loss                 | 38           |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.000595    |
|    value_loss           | 162          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 179      |
|    ep_rew_mean     | 121      |
| time/              |          |
|    fps             | 1505     |
|    iterations      | 30       |
|    time_elapsed    | 40       |
|    total_timesteps | 61440    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 182          |
|    ep_rew_mean          | 124          |
| time/                   |              |
|    fps                  | 1506         |
|    iterations           | 31           |
|    time_elapsed         | 42           |
|    total_timesteps      | 63488        |
| train/                  |              |
|    approx_kl            | 0.0031989769 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.685       |
|    explained_variance   | -1.79e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 137          |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.00041     |
|    value_loss           | 229          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 181         |
|    ep_rew_mean          | 124         |
| time/                   |             |
|    fps                  | 1507        |
|    iterations           | 32          |
|    time_elapsed         | 43          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.012268069 |
|    clip_fraction        | 0.0498      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.669      |
|    explained_variance   | -1.67e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 134         |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.00598    |
|    value_loss           | 168         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 181         |
|    ep_rew_mean          | 125         |
| time/                   |             |
|    fps                  | 1507        |
|    iterations           | 33          |
|    time_elapsed         | 44          |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.012975998 |
|    clip_fraction        | 0.0436      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.678      |
|    explained_variance   | -1.31e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 88.4        |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.00182    |
|    value_loss           | 234         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 182         |
|    ep_rew_mean          | 125         |
| time/                   |             |
|    fps                  | 1508        |
|    iterations           | 34          |
|    time_elapsed         | 46          |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.009845998 |
|    clip_fraction        | 0.048       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.685      |
|    explained_variance   | -2.15e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 32.8        |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.00313    |
|    value_loss           | 137         |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=185.28 +/- 1.98
Episode length: 222.60 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 223         |
|    mean_reward          | 185         |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.009743713 |
|    clip_fraction        | 0.029       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.686      |
|    explained_variance   | -8.34e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 220         |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.00111    |
|    value_loss           | 199         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 183      |
|    ep_rew_mean     | 127      |
| time/              |          |
|    fps             | 1499     |
|    iterations      | 35       |
|    time_elapsed    | 47       |
|    total_timesteps | 71680    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 185          |
|    ep_rew_mean          | 130          |
| time/                   |              |
|    fps                  | 1500         |
|    iterations           | 36           |
|    time_elapsed         | 49           |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 0.0030333728 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.688       |
|    explained_variance   | -1.55e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 69.7         |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.00127     |
|    value_loss           | 114          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 187         |
|    ep_rew_mean          | 132         |
| time/                   |             |
|    fps                  | 1501        |
|    iterations           | 37          |
|    time_elapsed         | 50          |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.007307293 |
|    clip_fraction        | 0.0183      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.69       |
|    explained_variance   | -7.15e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 214         |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.00405    |
|    value_loss           | 145         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 186          |
|    ep_rew_mean          | 132          |
| time/                   |              |
|    fps                  | 1501         |
|    iterations           | 38           |
|    time_elapsed         | 51           |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 0.0042048334 |
|    clip_fraction        | 0.0153       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.689       |
|    explained_variance   | -9.54e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 24           |
|    n_updates            | 370          |
|    policy_gradient_loss | -0.00111     |
|    value_loss           | 177          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 186          |
|    ep_rew_mean          | 132          |
| time/                   |              |
|    fps                  | 1502         |
|    iterations           | 39           |
|    time_elapsed         | 53           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 0.0090244785 |
|    clip_fraction        | 0.0225       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.691       |
|    explained_variance   | -2.38e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 74.7         |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.00045     |
|    value_loss           | 211          |
------------------------------------------
Eval num_timesteps=80000, episode_reward=113.94 +/- 71.88
Episode length: 175.00 +/- 63.16
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 175          |
|    mean_reward          | 114          |
| time/                   |              |
|    total_timesteps      | 80000        |
| train/                  |              |
|    approx_kl            | 0.0008618289 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.691       |
|    explained_variance   | -8.34e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 121          |
|    n_updates            | 390          |
|    policy_gradient_loss | -8.98e-05    |
|    value_loss           | 245          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | 131      |
| time/              |          |
|    fps             | 1496     |
|    iterations      | 40       |
|    time_elapsed    | 54       |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 189         |
|    ep_rew_mean          | 135         |
| time/                   |             |
|    fps                  | 1497        |
|    iterations           | 41          |
|    time_elapsed         | 56          |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.009283921 |
|    clip_fraction        | 0.0632      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.688      |
|    explained_variance   | -7.15e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 61.6        |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.00506    |
|    value_loss           | 169         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 186          |
|    ep_rew_mean          | 133          |
| time/                   |              |
|    fps                  | 1498         |
|    iterations           | 42           |
|    time_elapsed         | 57           |
|    total_timesteps      | 86016        |
| train/                  |              |
|    approx_kl            | 0.0028129155 |
|    clip_fraction        | 0.000244     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.688       |
|    explained_variance   | -7.15e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 44           |
|    n_updates            | 410          |
|    policy_gradient_loss | -0.000364    |
|    value_loss           | 144          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 189         |
|    ep_rew_mean          | 136         |
| time/                   |             |
|    fps                  | 1498        |
|    iterations           | 43          |
|    time_elapsed         | 58          |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.007507479 |
|    clip_fraction        | 0.00308     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.684      |
|    explained_variance   | -4.77e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 79.6        |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.000645   |
|    value_loss           | 245         |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=81.42 +/- 3.56
Episode length: 132.80 +/- 2.71
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 133         |
|    mean_reward          | 81.4        |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.007046666 |
|    clip_fraction        | 0.0151      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.683      |
|    explained_variance   | -7.15e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 52.2        |
|    n_updates            | 430         |
|    policy_gradient_loss | 0.000412    |
|    value_loss           | 81.6        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | 132      |
| time/              |          |
|    fps             | 1495     |
|    iterations      | 44       |
|    time_elapsed    | 60       |
|    total_timesteps | 90112    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 185          |
|    ep_rew_mean          | 131          |
| time/                   |              |
|    fps                  | 1495         |
|    iterations           | 45           |
|    time_elapsed         | 61           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0069608577 |
|    clip_fraction        | 0.00122      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.685       |
|    explained_variance   | -3.58e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 27.3         |
|    n_updates            | 440          |
|    policy_gradient_loss | 6.1e-05      |
|    value_loss           | 247          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 185          |
|    ep_rew_mean          | 131          |
| time/                   |              |
|    fps                  | 1496         |
|    iterations           | 46           |
|    time_elapsed         | 62           |
|    total_timesteps      | 94208        |
| train/                  |              |
|    approx_kl            | 0.0033142995 |
|    clip_fraction        | 0.00835      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.681       |
|    explained_variance   | -3.58e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 78.5         |
|    n_updates            | 450          |
|    policy_gradient_loss | -0.00157     |
|    value_loss           | 179          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 184         |
|    ep_rew_mean          | 130         |
| time/                   |             |
|    fps                  | 1497        |
|    iterations           | 47          |
|    time_elapsed         | 64          |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.014071412 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.659      |
|    explained_variance   | -2.38e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 42.4        |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00763    |
|    value_loss           | 178         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 187         |
|    ep_rew_mean          | 133         |
| time/                   |             |
|    fps                  | 1498        |
|    iterations           | 48          |
|    time_elapsed         | 65          |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.000848241 |
|    clip_fraction        | 0.00806     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.645      |
|    explained_variance   | -2.38e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 86.5        |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.000679   |
|    value_loss           | 210         |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=84.34 +/- 4.36
Episode length: 134.80 +/- 3.71
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 135          |
|    mean_reward          | 84.3         |
| time/                   |              |
|    total_timesteps      | 100000       |
| train/                  |              |
|    approx_kl            | 0.0043486226 |
|    clip_fraction        | 0.0106       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.64        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 46           |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.00153     |
|    value_loss           | 144          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 189      |
|    ep_rew_mean     | 136      |
| time/              |          |
|    fps             | 1494     |
|    iterations      | 49       |
|    time_elapsed    | 67       |
|    total_timesteps | 100352   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 186          |
|    ep_rew_mean          | 132          |
| time/                   |              |
|    fps                  | 1495         |
|    iterations           | 50           |
|    time_elapsed         | 68           |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 0.0048667723 |
|    clip_fraction        | 0.0432       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.639       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 69.4         |
|    n_updates            | 490          |
|    policy_gradient_loss | -0.000599    |
|    value_loss           | 111          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 188          |
|    ep_rew_mean          | 134          |
| time/                   |              |
|    fps                  | 1495         |
|    iterations           | 51           |
|    time_elapsed         | 69           |
|    total_timesteps      | 104448       |
| train/                  |              |
|    approx_kl            | 0.0021558292 |
|    clip_fraction        | 0.00127      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.665       |
|    explained_variance   | -3.58e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 103          |
|    n_updates            | 500          |
|    policy_gradient_loss | -0.00141     |
|    value_loss           | 246          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 182           |
|    ep_rew_mean          | 125           |
| time/                   |               |
|    fps                  | 1496          |
|    iterations           | 52            |
|    time_elapsed         | 71            |
|    total_timesteps      | 106496        |
| train/                  |               |
|    approx_kl            | 0.00036156666 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.651        |
|    explained_variance   | -2.38e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 43.6          |
|    n_updates            | 510           |
|    policy_gradient_loss | -0.000227     |
|    value_loss           | 238           |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 185         |
|    ep_rew_mean          | 130         |
| time/                   |             |
|    fps                  | 1497        |
|    iterations           | 53          |
|    time_elapsed         | 72          |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.004700958 |
|    clip_fraction        | 0.0248      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.671      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 83.6        |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.00277    |
|    value_loss           | 259         |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=36.28 +/- 24.19
Episode length: 111.00 +/- 30.07
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 111         |
|    mean_reward          | 36.3        |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.005216974 |
|    clip_fraction        | 0.002       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.681      |
|    explained_variance   | -2.38e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 53.6        |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0019     |
|    value_loss           | 143         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 185      |
|    ep_rew_mean     | 129      |
| time/              |          |
|    fps             | 1494     |
|    iterations      | 54       |
|    time_elapsed    | 74       |
|    total_timesteps | 110592   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 185          |
|    ep_rew_mean          | 129          |
| time/                   |              |
|    fps                  | 1495         |
|    iterations           | 55           |
|    time_elapsed         | 75           |
|    total_timesteps      | 112640       |
| train/                  |              |
|    approx_kl            | 0.0054077776 |
|    clip_fraction        | 0.0171       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.69        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 128          |
|    n_updates            | 540          |
|    policy_gradient_loss | -0.00147     |
|    value_loss           | 174          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 184          |
|    ep_rew_mean          | 128          |
| time/                   |              |
|    fps                  | 1495         |
|    iterations           | 56           |
|    time_elapsed         | 76           |
|    total_timesteps      | 114688       |
| train/                  |              |
|    approx_kl            | 0.0031037764 |
|    clip_fraction        | 0.000146     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.69        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 36.9         |
|    n_updates            | 550          |
|    policy_gradient_loss | -0.00154     |
|    value_loss           | 177          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 184          |
|    ep_rew_mean          | 128          |
| time/                   |              |
|    fps                  | 1496         |
|    iterations           | 57           |
|    time_elapsed         | 78           |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 0.0013996367 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.689       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 130          |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.000503    |
|    value_loss           | 233          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 184          |
|    ep_rew_mean          | 128          |
| time/                   |              |
|    fps                  | 1496         |
|    iterations           | 58           |
|    time_elapsed         | 79           |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 0.0018836845 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.688       |
|    explained_variance   | -2.38e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 135          |
|    n_updates            | 570          |
|    policy_gradient_loss | -0.000933    |
|    value_loss           | 141          |
------------------------------------------
Eval num_timesteps=120000, episode_reward=24.54 +/- 3.13
Episode length: 75.00 +/- 3.29
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 75          |
|    mean_reward          | 24.5        |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.005515979 |
|    clip_fraction        | 0.0333      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.69       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 44.1        |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.00241    |
|    value_loss           | 117         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 183      |
|    ep_rew_mean     | 128      |
| time/              |          |
|    fps             | 1495     |
|    iterations      | 59       |
|    time_elapsed    | 80       |
|    total_timesteps | 120832   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 185         |
|    ep_rew_mean          | 130         |
| time/                   |             |
|    fps                  | 1496        |
|    iterations           | 60          |
|    time_elapsed         | 82          |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.009252289 |
|    clip_fraction        | 0.0289      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.684      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 117         |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.00156    |
|    value_loss           | 242         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 185          |
|    ep_rew_mean          | 131          |
| time/                   |              |
|    fps                  | 1496         |
|    iterations           | 61           |
|    time_elapsed         | 83           |
|    total_timesteps      | 124928       |
| train/                  |              |
|    approx_kl            | 0.0013680261 |
|    clip_fraction        | 0.0116       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.681       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 174          |
|    n_updates            | 600          |
|    policy_gradient_loss | -0.000461    |
|    value_loss           | 204          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 184          |
|    ep_rew_mean          | 130          |
| time/                   |              |
|    fps                  | 1496         |
|    iterations           | 62           |
|    time_elapsed         | 84           |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 0.0037760949 |
|    clip_fraction        | 0.0183       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.685       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 259          |
|    n_updates            | 610          |
|    policy_gradient_loss | -0.00202     |
|    value_loss           | 234          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 181         |
|    ep_rew_mean          | 126         |
| time/                   |             |
|    fps                  | 1497        |
|    iterations           | 63          |
|    time_elapsed         | 86          |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.005335832 |
|    clip_fraction        | 0.0486      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.667      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 19.7        |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.000906   |
|    value_loss           | 174         |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=23.42 +/- 2.88
Episode length: 74.80 +/- 3.87
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 74.8         |
|    mean_reward          | 23.4         |
| time/                   |              |
|    total_timesteps      | 130000       |
| train/                  |              |
|    approx_kl            | 0.0032283135 |
|    clip_fraction        | 0.00605      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.681       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 94.9         |
|    n_updates            | 630          |
|    policy_gradient_loss | -0.00115     |
|    value_loss           | 282          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 180      |
|    ep_rew_mean     | 124      |
| time/              |          |
|    fps             | 1495     |
|    iterations      | 64       |
|    time_elapsed    | 87       |
|    total_timesteps | 131072   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 182          |
|    ep_rew_mean          | 127          |
| time/                   |              |
|    fps                  | 1496         |
|    iterations           | 65           |
|    time_elapsed         | 88           |
|    total_timesteps      | 133120       |
| train/                  |              |
|    approx_kl            | 0.0051459167 |
|    clip_fraction        | 0.0141       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.675       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 103          |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.000917    |
|    value_loss           | 203          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 172          |
|    ep_rew_mean          | 116          |
| time/                   |              |
|    fps                  | 1497         |
|    iterations           | 66           |
|    time_elapsed         | 90           |
|    total_timesteps      | 135168       |
| train/                  |              |
|    approx_kl            | 0.0044471435 |
|    clip_fraction        | 0.0324       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.657       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 104          |
|    n_updates            | 650          |
|    policy_gradient_loss | -0.000653    |
|    value_loss           | 202          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 174          |
|    ep_rew_mean          | 119          |
| time/                   |              |
|    fps                  | 1497         |
|    iterations           | 67           |
|    time_elapsed         | 91           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 0.0019002624 |
|    clip_fraction        | 0.000488     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.675       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 157          |
|    n_updates            | 660          |
|    policy_gradient_loss | -0.000196    |
|    value_loss           | 307          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 175          |
|    ep_rew_mean          | 120          |
| time/                   |              |
|    fps                  | 1497         |
|    iterations           | 68           |
|    time_elapsed         | 92           |
|    total_timesteps      | 139264       |
| train/                  |              |
|    approx_kl            | 0.0018110442 |
|    clip_fraction        | 0.0162       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.65        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 34.4         |
|    n_updates            | 670          |
|    policy_gradient_loss | -0.00102     |
|    value_loss           | 98.6         |
------------------------------------------
Eval num_timesteps=140000, episode_reward=22.60 +/- 2.15
Episode length: 72.60 +/- 2.15
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 72.6         |
|    mean_reward          | 22.6         |
| time/                   |              |
|    total_timesteps      | 140000       |
| train/                  |              |
|    approx_kl            | 0.0043856693 |
|    clip_fraction        | 0.0187       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.646       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 69.6         |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.00113     |
|    value_loss           | 205          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 177      |
|    ep_rew_mean     | 123      |
| time/              |          |
|    fps             | 1494     |
|    iterations      | 69       |
|    time_elapsed    | 94       |
|    total_timesteps | 141312   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 175          |
|    ep_rew_mean          | 120          |
| time/                   |              |
|    fps                  | 1494         |
|    iterations           | 70           |
|    time_elapsed         | 95           |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 0.0013548094 |
|    clip_fraction        | 4.88e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.639       |
|    explained_variance   | -2.38e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 40.5         |
|    n_updates            | 690          |
|    policy_gradient_loss | 5.81e-05     |
|    value_loss           | 141          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 176         |
|    ep_rew_mean          | 122         |
| time/                   |             |
|    fps                  | 1495        |
|    iterations           | 71          |
|    time_elapsed         | 97          |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.006417281 |
|    clip_fraction        | 0.045       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.671      |
|    explained_variance   | 1.19e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 123         |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.00352    |
|    value_loss           | 293         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 176         |
|    ep_rew_mean          | 122         |
| time/                   |             |
|    fps                  | 1495        |
|    iterations           | 72          |
|    time_elapsed         | 98          |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.005910953 |
|    clip_fraction        | 0.0331      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.685      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 122         |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.00278    |
|    value_loss           | 170         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 181          |
|    ep_rew_mean          | 128          |
| time/                   |              |
|    fps                  | 1496         |
|    iterations           | 73           |
|    time_elapsed         | 99           |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 0.0016489944 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 141          |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.000559    |
|    value_loss           | 198          |
------------------------------------------
Eval num_timesteps=150000, episode_reward=21.82 +/- 3.01
Episode length: 73.20 +/- 2.86
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 73.2         |
|    mean_reward          | 21.8         |
| time/                   |              |
|    total_timesteps      | 150000       |
| train/                  |              |
|    approx_kl            | 0.0021127658 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.68        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 20.8         |
|    n_updates            | 730          |
|    policy_gradient_loss | -0.00087     |
|    value_loss           | 114          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 182      |
|    ep_rew_mean     | 129      |
| time/              |          |
|    fps             | 1494     |
|    iterations      | 74       |
|    time_elapsed    | 101      |
|    total_timesteps | 151552   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 187          |
|    ep_rew_mean          | 134          |
| time/                   |              |
|    fps                  | 1495         |
|    iterations           | 75           |
|    time_elapsed         | 102          |
|    total_timesteps      | 153600       |
| train/                  |              |
|    approx_kl            | 0.0006830744 |
|    clip_fraction        | 0.00083      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.68        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 148          |
|    n_updates            | 740          |
|    policy_gradient_loss | -0.000519    |
|    value_loss           | 179          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 183         |
|    ep_rew_mean          | 130         |
| time/                   |             |
|    fps                  | 1495        |
|    iterations           | 76          |
|    time_elapsed         | 104         |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.008480996 |
|    clip_fraction        | 0.0448      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.682      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 67.8        |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.00124    |
|    value_loss           | 147         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 182         |
|    ep_rew_mean          | 128         |
| time/                   |             |
|    fps                  | 1496        |
|    iterations           | 77          |
|    time_elapsed         | 105         |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.008515608 |
|    clip_fraction        | 0.0126      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.684      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 208         |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.00089    |
|    value_loss           | 274         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 184          |
|    ep_rew_mean          | 130          |
| time/                   |              |
|    fps                  | 1496         |
|    iterations           | 78           |
|    time_elapsed         | 106          |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 0.0022713793 |
|    clip_fraction        | 0.000537     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.669       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 134          |
|    n_updates            | 770          |
|    policy_gradient_loss | 0.000286     |
|    value_loss           | 232          |
------------------------------------------
Eval num_timesteps=160000, episode_reward=21.95 +/- 2.35
Episode length: 73.80 +/- 2.86
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 73.8         |
|    mean_reward          | 22           |
| time/                   |              |
|    total_timesteps      | 160000       |
| train/                  |              |
|    approx_kl            | 0.0073025106 |
|    clip_fraction        | 0.0606       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.666       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 70.2         |
|    n_updates            | 780          |
|    policy_gradient_loss | -0.0033      |
|    value_loss           | 114          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 188      |
|    ep_rew_mean     | 135      |
| time/              |          |
|    fps             | 1492     |
|    iterations      | 79       |
|    time_elapsed    | 108      |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 185         |
|    ep_rew_mean          | 131         |
| time/                   |             |
|    fps                  | 1492        |
|    iterations           | 80          |
|    time_elapsed         | 109         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.008683004 |
|    clip_fraction        | 0.0696      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.64       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 93.9        |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.00621    |
|    value_loss           | 173         |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 184           |
|    ep_rew_mean          | 131           |
| time/                   |               |
|    fps                  | 1493          |
|    iterations           | 81            |
|    time_elapsed         | 111           |
|    total_timesteps      | 165888        |
| train/                  |               |
|    approx_kl            | 0.00074625283 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.632        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 115           |
|    n_updates            | 800           |
|    policy_gradient_loss | -2.51e-05     |
|    value_loss           | 272           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 181          |
|    ep_rew_mean          | 128          |
| time/                   |              |
|    fps                  | 1493         |
|    iterations           | 82           |
|    time_elapsed         | 112          |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 0.0051380927 |
|    clip_fraction        | 0.03         |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.616       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 106          |
|    n_updates            | 810          |
|    policy_gradient_loss | -0.00139     |
|    value_loss           | 206          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 179          |
|    ep_rew_mean          | 126          |
| time/                   |              |
|    fps                  | 1494         |
|    iterations           | 83           |
|    time_elapsed         | 113          |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 0.0030906037 |
|    clip_fraction        | 0.00767      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.634       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 272          |
|    n_updates            | 820          |
|    policy_gradient_loss | -0.000691    |
|    value_loss           | 174          |
------------------------------------------
Eval num_timesteps=170000, episode_reward=25.42 +/- 1.73
Episode length: 76.80 +/- 1.17
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 76.8         |
|    mean_reward          | 25.4         |
| time/                   |              |
|    total_timesteps      | 170000       |
| train/                  |              |
|    approx_kl            | 0.0048935357 |
|    clip_fraction        | 0.0609       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.671       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 213          |
|    n_updates            | 830          |
|    policy_gradient_loss | -0.00292     |
|    value_loss           | 203          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 180      |
|    ep_rew_mean     | 127      |
| time/              |          |
|    fps             | 1492     |
|    iterations      | 84       |
|    time_elapsed    | 115      |
|    total_timesteps | 172032   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 181          |
|    ep_rew_mean          | 129          |
| time/                   |              |
|    fps                  | 1493         |
|    iterations           | 85           |
|    time_elapsed         | 116          |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 0.0041793208 |
|    clip_fraction        | 0.00464      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.661       |
|    explained_variance   | -2.38e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 47.1         |
|    n_updates            | 840          |
|    policy_gradient_loss | -0.00123     |
|    value_loss           | 151          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 182         |
|    ep_rew_mean          | 130         |
| time/                   |             |
|    fps                  | 1493        |
|    iterations           | 86          |
|    time_elapsed         | 117         |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.006254756 |
|    clip_fraction        | 0.0542      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.62       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 180         |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.000496   |
|    value_loss           | 208         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 180        |
|    ep_rew_mean          | 128        |
| time/                   |            |
|    fps                  | 1494       |
|    iterations           | 87         |
|    time_elapsed         | 119        |
|    total_timesteps      | 178176     |
| train/                  |            |
|    approx_kl            | 0.00523647 |
|    clip_fraction        | 0.0414     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.643     |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 77.3       |
|    n_updates            | 860        |
|    policy_gradient_loss | 9.39e-05   |
|    value_loss           | 240        |
----------------------------------------
Eval num_timesteps=180000, episode_reward=60.80 +/- 30.62
Episode length: 110.80 +/- 30.62
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 111         |
|    mean_reward          | 60.8        |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.002580631 |
|    clip_fraction        | 0.0152      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.662      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 75.4        |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.00172    |
|    value_loss           | 142         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 181      |
|    ep_rew_mean     | 130      |
| time/              |          |
|    fps             | 1492     |
|    iterations      | 88       |
|    time_elapsed    | 120      |
|    total_timesteps | 180224   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 179          |
|    ep_rew_mean          | 127          |
| time/                   |              |
|    fps                  | 1492         |
|    iterations           | 89           |
|    time_elapsed         | 122          |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 0.0041619996 |
|    clip_fraction        | 0.00352      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.666       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 35.6         |
|    n_updates            | 880          |
|    policy_gradient_loss | -0.00138     |
|    value_loss           | 186          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 176         |
|    ep_rew_mean          | 122         |
| time/                   |             |
|    fps                  | 1493        |
|    iterations           | 90          |
|    time_elapsed         | 123         |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.008645639 |
|    clip_fraction        | 0.0381      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.684      |
|    explained_variance   | 1.19e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 172         |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.00175    |
|    value_loss           | 297         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 173          |
|    ep_rew_mean          | 119          |
| time/                   |              |
|    fps                  | 1493         |
|    iterations           | 91           |
|    time_elapsed         | 124          |
|    total_timesteps      | 186368       |
| train/                  |              |
|    approx_kl            | 0.0036343972 |
|    clip_fraction        | 0.00923      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 117          |
|    n_updates            | 900          |
|    policy_gradient_loss | -0.00202     |
|    value_loss           | 279          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 173         |
|    ep_rew_mean          | 119         |
| time/                   |             |
|    fps                  | 1494        |
|    iterations           | 92          |
|    time_elapsed         | 126         |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.007593912 |
|    clip_fraction        | 0.0252      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.683      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 143         |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.00224    |
|    value_loss           | 276         |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=21.35 +/- 4.13
Episode length: 73.20 +/- 3.43
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 73.2         |
|    mean_reward          | 21.4         |
| time/                   |              |
|    total_timesteps      | 190000       |
| train/                  |              |
|    approx_kl            | 0.0009953727 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.681       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 136          |
|    n_updates            | 920          |
|    policy_gradient_loss | -0.000997    |
|    value_loss           | 136          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 171      |
|    ep_rew_mean     | 117      |
| time/              |          |
|    fps             | 1485     |
|    iterations      | 93       |
|    time_elapsed    | 128      |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 174         |
|    ep_rew_mean          | 120         |
| time/                   |             |
|    fps                  | 1486        |
|    iterations           | 94          |
|    time_elapsed         | 129         |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.005062702 |
|    clip_fraction        | 0.0154      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.683      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 81.6        |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.0015     |
|    value_loss           | 198         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 170          |
|    ep_rew_mean          | 115          |
| time/                   |              |
|    fps                  | 1486         |
|    iterations           | 95           |
|    time_elapsed         | 130          |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 0.0027145622 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.68        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 61           |
|    n_updates            | 940          |
|    policy_gradient_loss | -0.000149    |
|    value_loss           | 161          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 172          |
|    ep_rew_mean          | 116          |
| time/                   |              |
|    fps                  | 1487         |
|    iterations           | 96           |
|    time_elapsed         | 132          |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0040410366 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.681       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 128          |
|    n_updates            | 950          |
|    policy_gradient_loss | -0.000613    |
|    value_loss           | 259          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 174          |
|    ep_rew_mean          | 118          |
| time/                   |              |
|    fps                  | 1487         |
|    iterations           | 97           |
|    time_elapsed         | 133          |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 0.0037134613 |
|    clip_fraction        | 0.0084       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.668       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 58.5         |
|    n_updates            | 960          |
|    policy_gradient_loss | -0.00164     |
|    value_loss           | 193          |
------------------------------------------
Eval num_timesteps=200000, episode_reward=23.74 +/- 3.96
Episode length: 74.20 +/- 3.31
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 74.2         |
|    mean_reward          | 23.7         |
| time/                   |              |
|    total_timesteps      | 200000       |
| train/                  |              |
|    approx_kl            | 0.0067443512 |
|    clip_fraction        | 0.00898      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.672       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 68.6         |
|    n_updates            | 970          |
|    policy_gradient_loss | -0.00139     |
|    value_loss           | 110          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 175      |
|    ep_rew_mean     | 121      |
| time/              |          |
|    fps             | 1481     |
|    iterations      | 98       |
|    time_elapsed    | 135      |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 174         |
|    ep_rew_mean          | 120         |
| time/                   |             |
|    fps                  | 1482        |
|    iterations           | 99          |
|    time_elapsed         | 136         |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.009725597 |
|    clip_fraction        | 0.044       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.664      |
|    explained_variance   | 1.19e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 121         |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.00268    |
|    value_loss           | 263         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 170         |
|    ep_rew_mean          | 115         |
| time/                   |             |
|    fps                  | 1482        |
|    iterations           | 100         |
|    time_elapsed         | 138         |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.004472228 |
|    clip_fraction        | 0.0258      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.677      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 70.6        |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.00252    |
|    value_loss           | 256         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 166          |
|    ep_rew_mean          | 111          |
| time/                   |              |
|    fps                  | 1483         |
|    iterations           | 101          |
|    time_elapsed         | 139          |
|    total_timesteps      | 206848       |
| train/                  |              |
|    approx_kl            | 0.0036901913 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.68        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 105          |
|    n_updates            | 1000         |
|    policy_gradient_loss | -9.36e-06    |
|    value_loss           | 275          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 172          |
|    ep_rew_mean          | 118          |
| time/                   |              |
|    fps                  | 1483         |
|    iterations           | 102          |
|    time_elapsed         | 140          |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 0.0072319238 |
|    clip_fraction        | 0.00156      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 91.5         |
|    n_updates            | 1010         |
|    policy_gradient_loss | -0.000795    |
|    value_loss           | 243          |
------------------------------------------
Eval num_timesteps=210000, episode_reward=23.94 +/- 3.29
Episode length: 74.40 +/- 3.38
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 74.4        |
|    mean_reward          | 23.9        |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.004576156 |
|    clip_fraction        | 0.0148      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.687      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 43.3        |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.00191    |
|    value_loss           | 102         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 173      |
|    ep_rew_mean     | 119      |
| time/              |          |
|    fps             | 1482     |
|    iterations      | 103      |
|    time_elapsed    | 142      |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 176         |
|    ep_rew_mean          | 123         |
| time/                   |             |
|    fps                  | 1483        |
|    iterations           | 104         |
|    time_elapsed         | 143         |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.004836496 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.688      |
|    explained_variance   | 1.19e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 175         |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.000169   |
|    value_loss           | 167         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 176         |
|    ep_rew_mean          | 123         |
| time/                   |             |
|    fps                  | 1483        |
|    iterations           | 105         |
|    time_elapsed         | 144         |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.003680091 |
|    clip_fraction        | 0.02        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.674      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 48.6        |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.00028    |
|    value_loss           | 111         |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 179           |
|    ep_rew_mean          | 125           |
| time/                   |               |
|    fps                  | 1483          |
|    iterations           | 106           |
|    time_elapsed         | 146           |
|    total_timesteps      | 217088        |
| train/                  |               |
|    approx_kl            | 0.00077206636 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.676        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 65.4          |
|    n_updates            | 1050          |
|    policy_gradient_loss | -0.000423     |
|    value_loss           | 145           |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 180         |
|    ep_rew_mean          | 126         |
| time/                   |             |
|    fps                  | 1484        |
|    iterations           | 107         |
|    time_elapsed         | 147         |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.004882194 |
|    clip_fraction        | 0.0355      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.657      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 54.6        |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.00353    |
|    value_loss           | 146         |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=169.28 +/- 1.42
Episode length: 221.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 221         |
|    mean_reward          | 169         |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.004598232 |
|    clip_fraction        | 0.0114      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.675      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 235         |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.000182   |
|    value_loss           | 237         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | 132      |
| time/              |          |
|    fps             | 1478     |
|    iterations      | 108      |
|    time_elapsed    | 149      |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 189         |
|    ep_rew_mean          | 135         |
| time/                   |             |
|    fps                  | 1478        |
|    iterations           | 109         |
|    time_elapsed         | 150         |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.004917168 |
|    clip_fraction        | 0.0119      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.675      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 68.1        |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.0014     |
|    value_loss           | 114         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 192        |
|    ep_rew_mean          | 139        |
| time/                   |            |
|    fps                  | 1479       |
|    iterations           | 110        |
|    time_elapsed         | 152        |
|    total_timesteps      | 225280     |
| train/                  |            |
|    approx_kl            | 0.00837631 |
|    clip_fraction        | 0.0388     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.673     |
|    explained_variance   | 5.96e-08   |
|    learning_rate        | 0.0003     |
|    loss                 | 64.9       |
|    n_updates            | 1090       |
|    policy_gradient_loss | -0.00196   |
|    value_loss           | 122        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 192         |
|    ep_rew_mean          | 138         |
| time/                   |             |
|    fps                  | 1479        |
|    iterations           | 111         |
|    time_elapsed         | 153         |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.004372705 |
|    clip_fraction        | 0.0286      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.669      |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 171         |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.00192    |
|    value_loss           | 224         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 194         |
|    ep_rew_mean          | 141         |
| time/                   |             |
|    fps                  | 1479        |
|    iterations           | 112         |
|    time_elapsed         | 154         |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.009620191 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.649      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 49.8        |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.00718    |
|    value_loss           | 271         |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=22.94 +/- 2.68
Episode length: 73.40 +/- 2.24
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 73.4         |
|    mean_reward          | 22.9         |
| time/                   |              |
|    total_timesteps      | 230000       |
| train/                  |              |
|    approx_kl            | 0.0024861377 |
|    clip_fraction        | 0.0212       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.658       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 33.9         |
|    n_updates            | 1120         |
|    policy_gradient_loss | -0.00206     |
|    value_loss           | 153          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 191      |
|    ep_rew_mean     | 137      |
| time/              |          |
|    fps             | 1479     |
|    iterations      | 113      |
|    time_elapsed    | 156      |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 189         |
|    ep_rew_mean          | 136         |
| time/                   |             |
|    fps                  | 1479        |
|    iterations           | 114         |
|    time_elapsed         | 157         |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.006868607 |
|    clip_fraction        | 0.0475      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.612      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 210         |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.00522    |
|    value_loss           | 207         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 183         |
|    ep_rew_mean          | 130         |
| time/                   |             |
|    fps                  | 1480        |
|    iterations           | 115         |
|    time_elapsed         | 159         |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.005767455 |
|    clip_fraction        | 0.0293      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.598      |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 63.2        |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.00368    |
|    value_loss           | 180         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 181         |
|    ep_rew_mean          | 128         |
| time/                   |             |
|    fps                  | 1480        |
|    iterations           | 116         |
|    time_elapsed         | 160         |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.008398579 |
|    clip_fraction        | 0.0548      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.563      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 185         |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.00132    |
|    value_loss           | 241         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 176          |
|    ep_rew_mean          | 124          |
| time/                   |              |
|    fps                  | 1480         |
|    iterations           | 117          |
|    time_elapsed         | 161          |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 0.0021728668 |
|    clip_fraction        | 0.026        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.563       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 107          |
|    n_updates            | 1160         |
|    policy_gradient_loss | -0.00205     |
|    value_loss           | 266          |
------------------------------------------
Eval num_timesteps=240000, episode_reward=37.40 +/- 25.44
Episode length: 87.40 +/- 25.44
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 87.4        |
|    mean_reward          | 37.4        |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.006525171 |
|    clip_fraction        | 0.0259      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.59       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 93.1        |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.00147    |
|    value_loss           | 204         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 176      |
|    ep_rew_mean     | 124      |
| time/              |          |
|    fps             | 1480     |
|    iterations      | 118      |
|    time_elapsed    | 163      |
|    total_timesteps | 241664   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 176          |
|    ep_rew_mean          | 125          |
| time/                   |              |
|    fps                  | 1480         |
|    iterations           | 119          |
|    time_elapsed         | 164          |
|    total_timesteps      | 243712       |
| train/                  |              |
|    approx_kl            | 0.0042841164 |
|    clip_fraction        | 0.0249       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.597       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 137          |
|    n_updates            | 1180         |
|    policy_gradient_loss | -0.000849    |
|    value_loss           | 142          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 176         |
|    ep_rew_mean          | 125         |
| time/                   |             |
|    fps                  | 1480        |
|    iterations           | 120         |
|    time_elapsed         | 165         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.005525474 |
|    clip_fraction        | 0.0497      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.599      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 99.8        |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.00207    |
|    value_loss           | 212         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 172          |
|    ep_rew_mean          | 121          |
| time/                   |              |
|    fps                  | 1481         |
|    iterations           | 121          |
|    time_elapsed         | 167          |
|    total_timesteps      | 247808       |
| train/                  |              |
|    approx_kl            | 0.0030839776 |
|    clip_fraction        | 0.0408       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.624       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 43.3         |
|    n_updates            | 1200         |
|    policy_gradient_loss | -0.00234     |
|    value_loss           | 238          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 170          |
|    ep_rew_mean          | 119          |
| time/                   |              |
|    fps                  | 1481         |
|    iterations           | 122          |
|    time_elapsed         | 168          |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 0.0014034039 |
|    clip_fraction        | 0.00332      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.594       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 78.9         |
|    n_updates            | 1210         |
|    policy_gradient_loss | -0.00036     |
|    value_loss           | 241          |
------------------------------------------
Eval num_timesteps=250000, episode_reward=73.00 +/- 24.06
Episode length: 123.00 +/- 24.06
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 123          |
|    mean_reward          | 73           |
| time/                   |              |
|    total_timesteps      | 250000       |
| train/                  |              |
|    approx_kl            | 0.0006812257 |
|    clip_fraction        | 0.00371      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.606       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 47.6         |
|    n_updates            | 1220         |
|    policy_gradient_loss | 0.000246     |
|    value_loss           | 200          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 173      |
|    ep_rew_mean     | 122      |
| time/              |          |
|    fps             | 1480     |
|    iterations      | 123      |
|    time_elapsed    | 170      |
|    total_timesteps | 251904   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 174          |
|    ep_rew_mean          | 124          |
| time/                   |              |
|    fps                  | 1480         |
|    iterations           | 124          |
|    time_elapsed         | 171          |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 0.0049109086 |
|    clip_fraction        | 0.0571       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.57        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 90.6         |
|    n_updates            | 1230         |
|    policy_gradient_loss | -0.00378     |
|    value_loss           | 176          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 178          |
|    ep_rew_mean          | 129          |
| time/                   |              |
|    fps                  | 1481         |
|    iterations           | 125          |
|    time_elapsed         | 172          |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 0.0031279842 |
|    clip_fraction        | 0.0151       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.573       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 142          |
|    n_updates            | 1240         |
|    policy_gradient_loss | -0.000643    |
|    value_loss           | 236          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 177         |
|    ep_rew_mean          | 127         |
| time/                   |             |
|    fps                  | 1481        |
|    iterations           | 126         |
|    time_elapsed         | 174         |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.001151851 |
|    clip_fraction        | 0.0114      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.561      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 56          |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.00143    |
|    value_loss           | 150         |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=60.60 +/- 31.23
Episode length: 110.60 +/- 31.23
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 111          |
|    mean_reward          | 60.6         |
| time/                   |              |
|    total_timesteps      | 260000       |
| train/                  |              |
|    approx_kl            | 0.0026391242 |
|    clip_fraction        | 0.0346       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.607       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 107          |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.00199     |
|    value_loss           | 266          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 174      |
|    ep_rew_mean     | 123      |
| time/              |          |
|    fps             | 1474     |
|    iterations      | 127      |
|    time_elapsed    | 176      |
|    total_timesteps | 260096   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 174          |
|    ep_rew_mean          | 123          |
| time/                   |              |
|    fps                  | 1475         |
|    iterations           | 128          |
|    time_elapsed         | 177          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0036606814 |
|    clip_fraction        | 0.0211       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.605       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 146          |
|    n_updates            | 1270         |
|    policy_gradient_loss | -0.0024      |
|    value_loss           | 232          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 176         |
|    ep_rew_mean          | 126         |
| time/                   |             |
|    fps                  | 1475        |
|    iterations           | 129         |
|    time_elapsed         | 179         |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.002018691 |
|    clip_fraction        | 0.00972     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.622      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 107         |
|    n_updates            | 1280        |
|    policy_gradient_loss | 0.000529    |
|    value_loss           | 236         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 180          |
|    ep_rew_mean          | 129          |
| time/                   |              |
|    fps                  | 1476         |
|    iterations           | 130          |
|    time_elapsed         | 180          |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 0.0035461648 |
|    clip_fraction        | 0.00347      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.627       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 52.4         |
|    n_updates            | 1290         |
|    policy_gradient_loss | 0.000457     |
|    value_loss           | 106          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 183          |
|    ep_rew_mean          | 134          |
| time/                   |              |
|    fps                  | 1476         |
|    iterations           | 131          |
|    time_elapsed         | 181          |
|    total_timesteps      | 268288       |
| train/                  |              |
|    approx_kl            | 0.0068670013 |
|    clip_fraction        | 0.0323       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.662       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 79.9         |
|    n_updates            | 1300         |
|    policy_gradient_loss | -0.000882    |
|    value_loss           | 151          |
------------------------------------------
Eval num_timesteps=270000, episode_reward=71.00 +/- 26.12
Episode length: 121.00 +/- 26.12
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 121         |
|    mean_reward          | 71          |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.010612225 |
|    clip_fraction        | 0.0616      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.654      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 41.1        |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.00235    |
|    value_loss           | 122         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | 136      |
| time/              |          |
|    fps             | 1475     |
|    iterations      | 132      |
|    time_elapsed    | 183      |
|    total_timesteps | 270336   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 188          |
|    ep_rew_mean          | 139          |
| time/                   |              |
|    fps                  | 1475         |
|    iterations           | 133          |
|    time_elapsed         | 184          |
|    total_timesteps      | 272384       |
| train/                  |              |
|    approx_kl            | 0.0064372323 |
|    clip_fraction        | 0.00859      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.643       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 34.4         |
|    n_updates            | 1320         |
|    policy_gradient_loss | -0.000485    |
|    value_loss           | 127          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 189          |
|    ep_rew_mean          | 140          |
| time/                   |              |
|    fps                  | 1476         |
|    iterations           | 134          |
|    time_elapsed         | 185          |
|    total_timesteps      | 274432       |
| train/                  |              |
|    approx_kl            | 0.0031374546 |
|    clip_fraction        | 0.00562      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.653       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 88.5         |
|    n_updates            | 1330         |
|    policy_gradient_loss | -0.000617    |
|    value_loss           | 187          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 192         |
|    ep_rew_mean          | 142         |
| time/                   |             |
|    fps                  | 1476        |
|    iterations           | 135         |
|    time_elapsed         | 187         |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.004407667 |
|    clip_fraction        | 0.00854     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.664      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 35.7        |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.00121    |
|    value_loss           | 130         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 194         |
|    ep_rew_mean          | 144         |
| time/                   |             |
|    fps                  | 1476        |
|    iterations           | 136         |
|    time_elapsed         | 188         |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.011423526 |
|    clip_fraction        | 0.0878      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.675      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 150         |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.00367    |
|    value_loss           | 196         |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=81.48 +/- 2.32
Episode length: 132.40 +/- 2.65
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 132          |
|    mean_reward          | 81.5         |
| time/                   |              |
|    total_timesteps      | 280000       |
| train/                  |              |
|    approx_kl            | 0.0051858155 |
|    clip_fraction        | 0.0128       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.664       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 77.4         |
|    n_updates            | 1360         |
|    policy_gradient_loss | -0.00148     |
|    value_loss           | 186          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 197      |
|    ep_rew_mean     | 147      |
| time/              |          |
|    fps             | 1475     |
|    iterations      | 137      |
|    time_elapsed    | 190      |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 201         |
|    ep_rew_mean          | 152         |
| time/                   |             |
|    fps                  | 1476        |
|    iterations           | 138         |
|    time_elapsed         | 191         |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.007887995 |
|    clip_fraction        | 0.0326      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.656      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 41.6        |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.00175    |
|    value_loss           | 123         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 200         |
|    ep_rew_mean          | 151         |
| time/                   |             |
|    fps                  | 1476        |
|    iterations           | 139         |
|    time_elapsed         | 192         |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.005035919 |
|    clip_fraction        | 0.0245      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.642      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 143         |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.0018     |
|    value_loss           | 133         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 201         |
|    ep_rew_mean          | 152         |
| time/                   |             |
|    fps                  | 1476        |
|    iterations           | 140         |
|    time_elapsed         | 194         |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.010691108 |
|    clip_fraction        | 0.0625      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.642      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 148         |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.00134    |
|    value_loss           | 171         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 194          |
|    ep_rew_mean          | 144          |
| time/                   |              |
|    fps                  | 1477         |
|    iterations           | 141          |
|    time_elapsed         | 195          |
|    total_timesteps      | 288768       |
| train/                  |              |
|    approx_kl            | 0.0071157627 |
|    clip_fraction        | 0.0116       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.65        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 36.3         |
|    n_updates            | 1400         |
|    policy_gradient_loss | -0.00078     |
|    value_loss           | 163          |
------------------------------------------
Eval num_timesteps=290000, episode_reward=83.68 +/- 3.60
Episode length: 134.60 +/- 3.77
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 135          |
|    mean_reward          | 83.7         |
| time/                   |              |
|    total_timesteps      | 290000       |
| train/                  |              |
|    approx_kl            | 0.0068699624 |
|    clip_fraction        | 0.0272       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.65        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 240          |
|    n_updates            | 1410         |
|    policy_gradient_loss | 0.000124     |
|    value_loss           | 323          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 191      |
|    ep_rew_mean     | 140      |
| time/              |          |
|    fps             | 1476     |
|    iterations      | 142      |
|    time_elapsed    | 197      |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 187         |
|    ep_rew_mean          | 135         |
| time/                   |             |
|    fps                  | 1476        |
|    iterations           | 143         |
|    time_elapsed         | 198         |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.005052752 |
|    clip_fraction        | 0.04        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.623      |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 137         |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.00254    |
|    value_loss           | 220         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 187          |
|    ep_rew_mean          | 135          |
| time/                   |              |
|    fps                  | 1476         |
|    iterations           | 144          |
|    time_elapsed         | 199          |
|    total_timesteps      | 294912       |
| train/                  |              |
|    approx_kl            | 0.0019717729 |
|    clip_fraction        | 0.00532      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.616       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 97.3         |
|    n_updates            | 1430         |
|    policy_gradient_loss | 7.68e-05     |
|    value_loss           | 216          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 188         |
|    ep_rew_mean          | 137         |
| time/                   |             |
|    fps                  | 1477        |
|    iterations           | 145         |
|    time_elapsed         | 201         |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.008163062 |
|    clip_fraction        | 0.0369      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.626      |
|    explained_variance   | 1.19e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 20.4        |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.00265    |
|    value_loss           | 147         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 189          |
|    ep_rew_mean          | 138          |
| time/                   |              |
|    fps                  | 1477         |
|    iterations           | 146          |
|    time_elapsed         | 202          |
|    total_timesteps      | 299008       |
| train/                  |              |
|    approx_kl            | 0.0063742613 |
|    clip_fraction        | 0.0292       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.628       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 147          |
|    n_updates            | 1450         |
|    policy_gradient_loss | -0.000864    |
|    value_loss           | 185          |
------------------------------------------
Eval num_timesteps=300000, episode_reward=81.29 +/- 3.83
Episode length: 133.60 +/- 3.83
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 134          |
|    mean_reward          | 81.3         |
| time/                   |              |
|    total_timesteps      | 300000       |
| train/                  |              |
|    approx_kl            | 0.0041178437 |
|    clip_fraction        | 0.0292       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.62        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 20.9         |
|    n_updates            | 1460         |
|    policy_gradient_loss | 4.01e-05     |
|    value_loss           | 116          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 183      |
|    ep_rew_mean     | 130      |
| time/              |          |
|    fps             | 1476     |
|    iterations      | 147      |
|    time_elapsed    | 203      |
|    total_timesteps | 301056   |
---------------------------------

Training complete!
Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-07_23-21-32

