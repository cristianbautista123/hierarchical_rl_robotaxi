Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-07_23-38-32

Map saved at: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-07_23-38-32/map_visualization.png

Using cpu device
Wrapping the env in a DummyVecEnv.
Logging to /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-07_23-38-32/tensorboard/PPO_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 178      |
|    ep_rew_mean     | 106      |
| time/              |          |
|    fps             | 2784     |
|    iterations      | 1        |
|    time_elapsed    | 0        |
|    total_timesteps | 2048     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 182          |
|    ep_rew_mean          | 111          |
| time/                   |              |
|    fps                  | 1875         |
|    iterations           | 2            |
|    time_elapsed         | 2            |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0047497675 |
|    clip_fraction        | 0.0374       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | -0.00261     |
|    learning_rate        | 0.0003       |
|    loss                 | 37.2         |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00214     |
|    value_loss           | 81           |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 184         |
|    ep_rew_mean          | 113         |
| time/                   |             |
|    fps                  | 1729        |
|    iterations           | 3           |
|    time_elapsed         | 3           |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.005126547 |
|    clip_fraction        | 0.00195     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.685      |
|    explained_variance   | -0.0128     |
|    learning_rate        | 0.0003      |
|    loss                 | 8.19        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.000295   |
|    value_loss           | 80.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 180         |
|    ep_rew_mean          | 109         |
| time/                   |             |
|    fps                  | 1666        |
|    iterations           | 4           |
|    time_elapsed         | 4           |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.011330193 |
|    clip_fraction        | 0.0198      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.692      |
|    explained_variance   | -0.00662    |
|    learning_rate        | 0.0003      |
|    loss                 | 86.3        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00207    |
|    value_loss           | 88.4        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=47.80 +/- 28.88
Episode length: 97.80 +/- 28.88
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 97.8        |
|    mean_reward          | 47.8        |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.014567109 |
|    clip_fraction        | 0.0697      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.672      |
|    explained_variance   | -0.00466    |
|    learning_rate        | 0.0003      |
|    loss                 | 82.1        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00242    |
|    value_loss           | 136         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 177      |
|    ep_rew_mean     | 106      |
| time/              |          |
|    fps             | 1592     |
|    iterations      | 5        |
|    time_elapsed    | 6        |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 182          |
|    ep_rew_mean          | 112          |
| time/                   |              |
|    fps                  | 1576         |
|    iterations           | 6            |
|    time_elapsed         | 7            |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0042706174 |
|    clip_fraction        | 0.0231       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.688       |
|    explained_variance   | -0.000309    |
|    learning_rate        | 0.0003       |
|    loss                 | 35           |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.000603    |
|    value_loss           | 146          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 180         |
|    ep_rew_mean          | 110         |
| time/                   |             |
|    fps                  | 1563        |
|    iterations           | 7           |
|    time_elapsed         | 9           |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.004477009 |
|    clip_fraction        | 0.0227      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.665      |
|    explained_variance   | -0.00166    |
|    learning_rate        | 0.0003      |
|    loss                 | 25.3        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00316    |
|    value_loss           | 68.3        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 177          |
|    ep_rew_mean          | 106          |
| time/                   |              |
|    fps                  | 1553         |
|    iterations           | 8            |
|    time_elapsed         | 10           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0065108677 |
|    clip_fraction        | 0.0283       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.678       |
|    explained_variance   | -0.000767    |
|    learning_rate        | 0.0003       |
|    loss                 | 36.6         |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.000652    |
|    value_loss           | 169          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 177           |
|    ep_rew_mean          | 106           |
| time/                   |               |
|    fps                  | 1547          |
|    iterations           | 9             |
|    time_elapsed         | 11            |
|    total_timesteps      | 18432         |
| train/                  |               |
|    approx_kl            | 0.00034844497 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.686        |
|    explained_variance   | -0.000276     |
|    learning_rate        | 0.0003        |
|    loss                 | 137           |
|    n_updates            | 80            |
|    policy_gradient_loss | 4.04e-05      |
|    value_loss           | 218           |
-------------------------------------------
Eval num_timesteps=20000, episode_reward=219.29 +/- 2.07
Episode length: 223.00 +/- 2.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 223          |
|    mean_reward          | 219          |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0076501714 |
|    clip_fraction        | 0.0591       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.69        |
|    explained_variance   | -0.000271    |
|    learning_rate        | 0.0003       |
|    loss                 | 79.9         |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00285     |
|    value_loss           | 147          |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 179      |
|    ep_rew_mean     | 107      |
| time/              |          |
|    fps             | 1505     |
|    iterations      | 10       |
|    time_elapsed    | 13       |
|    total_timesteps | 20480    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 178         |
|    ep_rew_mean          | 106         |
| time/                   |             |
|    fps                  | 1505        |
|    iterations           | 11          |
|    time_elapsed         | 14          |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.008056843 |
|    clip_fraction        | 0.0339      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.689      |
|    explained_variance   | -0.000116   |
|    learning_rate        | 0.0003      |
|    loss                 | 73.7        |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.0049     |
|    value_loss           | 176         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 179        |
|    ep_rew_mean          | 108        |
| time/                   |            |
|    fps                  | 1504       |
|    iterations           | 12         |
|    time_elapsed         | 16         |
|    total_timesteps      | 24576      |
| train/                  |            |
|    approx_kl            | 0.00623914 |
|    clip_fraction        | 0.0221     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.689     |
|    explained_variance   | -0.000107  |
|    learning_rate        | 0.0003     |
|    loss                 | 85         |
|    n_updates            | 110        |
|    policy_gradient_loss | 0.000391   |
|    value_loss           | 130        |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 183          |
|    ep_rew_mean          | 112          |
| time/                   |              |
|    fps                  | 1504         |
|    iterations           | 13           |
|    time_elapsed         | 17           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0059579136 |
|    clip_fraction        | 0.0263       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | -0.00016     |
|    learning_rate        | 0.0003       |
|    loss                 | 47.7         |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00287     |
|    value_loss           | 113          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 188         |
|    ep_rew_mean          | 116         |
| time/                   |             |
|    fps                  | 1503        |
|    iterations           | 14          |
|    time_elapsed         | 19          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.004058549 |
|    clip_fraction        | 0.00547     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.675      |
|    explained_variance   | -8.52e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 86.9        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.000296   |
|    value_loss           | 84.1        |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=159.57 +/- 2.06
Episode length: 219.40 +/- 2.33
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 219          |
|    mean_reward          | 160          |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0019177108 |
|    clip_fraction        | 0.000342     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.681       |
|    explained_variance   | -8.71e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 22.2         |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.000862    |
|    value_loss           | 93.7         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 188      |
|    ep_rew_mean     | 116      |
| time/              |          |
|    fps             | 1481     |
|    iterations      | 15       |
|    time_elapsed    | 20       |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 190         |
|    ep_rew_mean          | 117         |
| time/                   |             |
|    fps                  | 1482        |
|    iterations           | 16          |
|    time_elapsed         | 22          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.008163579 |
|    clip_fraction        | 0.00767     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.676      |
|    explained_variance   | -5.61e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 62          |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00273    |
|    value_loss           | 122         |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 192       |
|    ep_rew_mean          | 119       |
| time/                   |           |
|    fps                  | 1483      |
|    iterations           | 17        |
|    time_elapsed         | 23        |
|    total_timesteps      | 34816     |
| train/                  |           |
|    approx_kl            | 0.0023522 |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.664    |
|    explained_variance   | -5.13e-05 |
|    learning_rate        | 0.0003    |
|    loss                 | 91.1      |
|    n_updates            | 160       |
|    policy_gradient_loss | 0.0001    |
|    value_loss           | 156       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 193          |
|    ep_rew_mean          | 120          |
| time/                   |              |
|    fps                  | 1484         |
|    iterations           | 18           |
|    time_elapsed         | 24           |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 0.0051181177 |
|    clip_fraction        | 0.0172       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.654       |
|    explained_variance   | -2.72e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 235          |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.001       |
|    value_loss           | 178          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 196          |
|    ep_rew_mean          | 123          |
| time/                   |              |
|    fps                  | 1484         |
|    iterations           | 19           |
|    time_elapsed         | 26           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 0.0004468928 |
|    clip_fraction        | 0.00249      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.63        |
|    explained_variance   | -1.8e-05     |
|    learning_rate        | 0.0003       |
|    loss                 | 72.3         |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.000581    |
|    value_loss           | 176          |
------------------------------------------
Eval num_timesteps=40000, episode_reward=125.60 +/- 44.24
Episode length: 203.00 +/- 37.06
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 203          |
|    mean_reward          | 126          |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0035777134 |
|    clip_fraction        | 0.0622       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.653       |
|    explained_variance   | -2.74e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 87           |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.00229     |
|    value_loss           | 119          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 197      |
|    ep_rew_mean     | 124      |
| time/              |          |
|    fps             | 1455     |
|    iterations      | 20       |
|    time_elapsed    | 28       |
|    total_timesteps | 40960    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 198           |
|    ep_rew_mean          | 125           |
| time/                   |               |
|    fps                  | 1457          |
|    iterations           | 21            |
|    time_elapsed         | 29            |
|    total_timesteps      | 43008         |
| train/                  |               |
|    approx_kl            | 0.00042789002 |
|    clip_fraction        | 0.0153        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.648        |
|    explained_variance   | -2.26e-05     |
|    learning_rate        | 0.0003        |
|    loss                 | 80.6          |
|    n_updates            | 200           |
|    policy_gradient_loss | 0.000465      |
|    value_loss           | 122           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 196          |
|    ep_rew_mean          | 123          |
| time/                   |              |
|    fps                  | 1459         |
|    iterations           | 22           |
|    time_elapsed         | 30           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0019827858 |
|    clip_fraction        | 0.0148       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.654       |
|    explained_variance   | -1.18e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 94.4         |
|    n_updates            | 210          |
|    policy_gradient_loss | 0.000332     |
|    value_loss           | 129          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 192         |
|    ep_rew_mean          | 119         |
| time/                   |             |
|    fps                  | 1461        |
|    iterations           | 23          |
|    time_elapsed         | 32          |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.004271731 |
|    clip_fraction        | 0.00396     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.647      |
|    explained_variance   | -9.54e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 98.7        |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.00147    |
|    value_loss           | 154         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 188          |
|    ep_rew_mean          | 114          |
| time/                   |              |
|    fps                  | 1463         |
|    iterations           | 24           |
|    time_elapsed         | 33           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0081055015 |
|    clip_fraction        | 0.011        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.619       |
|    explained_variance   | -5.36e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 105          |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.000589    |
|    value_loss           | 178          |
------------------------------------------
Eval num_timesteps=50000, episode_reward=147.56 +/- 1.67
Episode length: 221.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 222         |
|    mean_reward          | 148         |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.003121976 |
|    clip_fraction        | 0.0283      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.603      |
|    explained_variance   | -5.48e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 87.6        |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.00171    |
|    value_loss           | 206         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | 112      |
| time/              |          |
|    fps             | 1442     |
|    iterations      | 25       |
|    time_elapsed    | 35       |
|    total_timesteps | 51200    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 184          |
|    ep_rew_mean          | 111          |
| time/                   |              |
|    fps                  | 1444         |
|    iterations           | 26           |
|    time_elapsed         | 36           |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0038337705 |
|    clip_fraction        | 0.0167       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.62        |
|    explained_variance   | -1.67e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 67.2         |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.000839    |
|    value_loss           | 167          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 183         |
|    ep_rew_mean          | 110         |
| time/                   |             |
|    fps                  | 1446        |
|    iterations           | 27          |
|    time_elapsed         | 38          |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.006815413 |
|    clip_fraction        | 0.0542      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.656      |
|    explained_variance   | -4.53e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 62.9        |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.00139    |
|    value_loss           | 193         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 183         |
|    ep_rew_mean          | 109         |
| time/                   |             |
|    fps                  | 1449        |
|    iterations           | 28          |
|    time_elapsed         | 39          |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.005206625 |
|    clip_fraction        | 0.00586     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.66       |
|    explained_variance   | -3.81e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 35.4        |
|    n_updates            | 270         |
|    policy_gradient_loss | -6.81e-05   |
|    value_loss           | 185         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 182         |
|    ep_rew_mean          | 109         |
| time/                   |             |
|    fps                  | 1450        |
|    iterations           | 29          |
|    time_elapsed         | 40          |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.013085707 |
|    clip_fraction        | 0.0867      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.689      |
|    explained_variance   | -3.34e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 129         |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00458    |
|    value_loss           | 111         |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=21.82 +/- 3.40
Episode length: 73.80 +/- 4.35
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 73.8         |
|    mean_reward          | 21.8         |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0012259299 |
|    clip_fraction        | 0.012        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | -3.34e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 46.8         |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.000569    |
|    value_loss           | 115          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 181      |
|    ep_rew_mean     | 108      |
| time/              |          |
|    fps             | 1448     |
|    iterations      | 30       |
|    time_elapsed    | 42       |
|    total_timesteps | 61440    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 181          |
|    ep_rew_mean          | 108          |
| time/                   |              |
|    fps                  | 1450         |
|    iterations           | 31           |
|    time_elapsed         | 43           |
|    total_timesteps      | 63488        |
| train/                  |              |
|    approx_kl            | 0.0011951928 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.689       |
|    explained_variance   | -3.1e-06     |
|    learning_rate        | 0.0003       |
|    loss                 | 41.6         |
|    n_updates            | 300          |
|    policy_gradient_loss | 0.000115     |
|    value_loss           | 149          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 178         |
|    ep_rew_mean          | 105         |
| time/                   |             |
|    fps                  | 1452        |
|    iterations           | 32          |
|    time_elapsed         | 45          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.009342199 |
|    clip_fraction        | 0.0317      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.684      |
|    explained_variance   | -7.15e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 78.3        |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.00222    |
|    value_loss           | 174         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 183         |
|    ep_rew_mean          | 110         |
| time/                   |             |
|    fps                  | 1453        |
|    iterations           | 33          |
|    time_elapsed         | 46          |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.008611457 |
|    clip_fraction        | 0.0126      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.679      |
|    explained_variance   | -1.67e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 166         |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.00206    |
|    value_loss           | 248         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 183          |
|    ep_rew_mean          | 110          |
| time/                   |              |
|    fps                  | 1455         |
|    iterations           | 34           |
|    time_elapsed         | 47           |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 0.0025213738 |
|    clip_fraction        | 0.00732      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.661       |
|    explained_variance   | -3.34e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 18.9         |
|    n_updates            | 330          |
|    policy_gradient_loss | -0.00208     |
|    value_loss           | 81.7         |
------------------------------------------
Eval num_timesteps=70000, episode_reward=147.06 +/- 1.01
Episode length: 221.80 +/- 1.17
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 222         |
|    mean_reward          | 147         |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.004374056 |
|    clip_fraction        | 0.0228      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.656      |
|    explained_variance   | -7.15e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 48.9        |
|    n_updates            | 340         |
|    policy_gradient_loss | 0.000872    |
|    value_loss           | 202         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 185      |
|    ep_rew_mean     | 112      |
| time/              |          |
|    fps             | 1447     |
|    iterations      | 35       |
|    time_elapsed    | 49       |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 185         |
|    ep_rew_mean          | 114         |
| time/                   |             |
|    fps                  | 1449        |
|    iterations           | 36          |
|    time_elapsed         | 50          |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.011369275 |
|    clip_fraction        | 0.0933      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.672      |
|    explained_variance   | -1.91e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 81.5        |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00264    |
|    value_loss           | 113         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 185        |
|    ep_rew_mean          | 113        |
| time/                   |            |
|    fps                  | 1450       |
|    iterations           | 37         |
|    time_elapsed         | 52         |
|    total_timesteps      | 75776      |
| train/                  |            |
|    approx_kl            | 0.01187725 |
|    clip_fraction        | 0.0209     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.68      |
|    explained_variance   | -1.31e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 89.5       |
|    n_updates            | 360        |
|    policy_gradient_loss | -0.00208   |
|    value_loss           | 147        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 183         |
|    ep_rew_mean          | 111         |
| time/                   |             |
|    fps                  | 1451        |
|    iterations           | 38          |
|    time_elapsed         | 53          |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.006423575 |
|    clip_fraction        | 0.00342     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.676      |
|    explained_variance   | -9.54e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 44          |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.000416   |
|    value_loss           | 149         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 178          |
|    ep_rew_mean          | 106          |
| time/                   |              |
|    fps                  | 1452         |
|    iterations           | 39           |
|    time_elapsed         | 54           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 0.0028302546 |
|    clip_fraction        | 0.0423       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.643       |
|    explained_variance   | -1.19e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 182          |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.00203     |
|    value_loss           | 173          |
------------------------------------------
Eval num_timesteps=80000, episode_reward=24.48 +/- 3.46
Episode length: 75.80 +/- 2.93
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 75.8          |
|    mean_reward          | 24.5          |
| time/                   |               |
|    total_timesteps      | 80000         |
| train/                  |               |
|    approx_kl            | 0.00045782723 |
|    clip_fraction        | 0.0175        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.624        |
|    explained_variance   | -5.96e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 152           |
|    n_updates            | 390           |
|    policy_gradient_loss | 0.000634      |
|    value_loss           | 228           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 178      |
|    ep_rew_mean     | 107      |
| time/              |          |
|    fps             | 1450     |
|    iterations      | 40       |
|    time_elapsed    | 56       |
|    total_timesteps | 81920    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 183          |
|    ep_rew_mean          | 113          |
| time/                   |              |
|    fps                  | 1452         |
|    iterations           | 41           |
|    time_elapsed         | 57           |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 0.0070114275 |
|    clip_fraction        | 0.0378       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.631       |
|    explained_variance   | -2.38e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 137          |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.0019      |
|    value_loss           | 217          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 181          |
|    ep_rew_mean          | 111          |
| time/                   |              |
|    fps                  | 1453         |
|    iterations           | 42           |
|    time_elapsed         | 59           |
|    total_timesteps      | 86016        |
| train/                  |              |
|    approx_kl            | 0.0011287013 |
|    clip_fraction        | 0.004        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.647       |
|    explained_variance   | -7.15e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 149          |
|    n_updates            | 410          |
|    policy_gradient_loss | -6.79e-05    |
|    value_loss           | 89.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 184          |
|    ep_rew_mean          | 115          |
| time/                   |              |
|    fps                  | 1454         |
|    iterations           | 43           |
|    time_elapsed         | 60           |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 0.0020602643 |
|    clip_fraction        | 0.049        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.651       |
|    explained_variance   | -4.77e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 152          |
|    n_updates            | 420          |
|    policy_gradient_loss | -0.0014      |
|    value_loss           | 176          |
------------------------------------------
Eval num_timesteps=90000, episode_reward=23.74 +/- 3.98
Episode length: 74.40 +/- 2.87
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 74.4        |
|    mean_reward          | 23.7        |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.005617087 |
|    clip_fraction        | 0.0499      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.628      |
|    explained_variance   | -3.58e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 18.6        |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.00236    |
|    value_loss           | 93.6        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | 118      |
| time/              |          |
|    fps             | 1452     |
|    iterations      | 44       |
|    time_elapsed    | 62       |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 182         |
|    ep_rew_mean          | 113         |
| time/                   |             |
|    fps                  | 1453        |
|    iterations           | 45          |
|    time_elapsed         | 63          |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.011284313 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.644      |
|    explained_variance   | -7.15e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 55          |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00924    |
|    value_loss           | 67          |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 180          |
|    ep_rew_mean          | 111          |
| time/                   |              |
|    fps                  | 1454         |
|    iterations           | 46           |
|    time_elapsed         | 64           |
|    total_timesteps      | 94208        |
| train/                  |              |
|    approx_kl            | 0.0057944786 |
|    clip_fraction        | 0.0042       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.644       |
|    explained_variance   | -4.77e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 114          |
|    n_updates            | 450          |
|    policy_gradient_loss | 0.00013      |
|    value_loss           | 268          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 178          |
|    ep_rew_mean          | 110          |
| time/                   |              |
|    fps                  | 1455         |
|    iterations           | 47           |
|    time_elapsed         | 66           |
|    total_timesteps      | 96256        |
| train/                  |              |
|    approx_kl            | 0.0018326229 |
|    clip_fraction        | 0.00347      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.611       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 47.8         |
|    n_updates            | 460          |
|    policy_gradient_loss | -5.31e-05    |
|    value_loss           | 182          |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 180        |
|    ep_rew_mean          | 113        |
| time/                   |            |
|    fps                  | 1456       |
|    iterations           | 48         |
|    time_elapsed         | 67         |
|    total_timesteps      | 98304      |
| train/                  |            |
|    approx_kl            | 0.00517074 |
|    clip_fraction        | 0.0161     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.59      |
|    explained_variance   | -1.19e-07  |
|    learning_rate        | 0.0003     |
|    loss                 | 65.4       |
|    n_updates            | 470        |
|    policy_gradient_loss | -0.00104   |
|    value_loss           | 258        |
----------------------------------------
Eval num_timesteps=100000, episode_reward=23.22 +/- 3.19
Episode length: 75.20 +/- 3.66
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 75.2         |
|    mean_reward          | 23.2         |
| time/                   |              |
|    total_timesteps      | 100000       |
| train/                  |              |
|    approx_kl            | 0.0019202486 |
|    clip_fraction        | 0.0105       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.571       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 54.1         |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.000389    |
|    value_loss           | 124          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 181      |
|    ep_rew_mean     | 116      |
| time/              |          |
|    fps             | 1454     |
|    iterations      | 49       |
|    time_elapsed    | 68       |
|    total_timesteps | 100352   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 180        |
|    ep_rew_mean          | 115        |
| time/                   |            |
|    fps                  | 1455       |
|    iterations           | 50         |
|    time_elapsed         | 70         |
|    total_timesteps      | 102400     |
| train/                  |            |
|    approx_kl            | 0.00374323 |
|    clip_fraction        | 0.0174     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.549     |
|    explained_variance   | -1.19e-07  |
|    learning_rate        | 0.0003     |
|    loss                 | 80         |
|    n_updates            | 490        |
|    policy_gradient_loss | -0.00143   |
|    value_loss           | 182        |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 177          |
|    ep_rew_mean          | 113          |
| time/                   |              |
|    fps                  | 1456         |
|    iterations           | 51           |
|    time_elapsed         | 71           |
|    total_timesteps      | 104448       |
| train/                  |              |
|    approx_kl            | 0.0016626045 |
|    clip_fraction        | 0.0241       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.557       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 34.5         |
|    n_updates            | 500          |
|    policy_gradient_loss | -0.000546    |
|    value_loss           | 174          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 163         |
|    ep_rew_mean          | 99          |
| time/                   |             |
|    fps                  | 1457        |
|    iterations           | 52          |
|    time_elapsed         | 73          |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.004921383 |
|    clip_fraction        | 0.0111      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.514      |
|    explained_variance   | -2.38e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 45.2        |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.00159    |
|    value_loss           | 183         |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 165           |
|    ep_rew_mean          | 103           |
| time/                   |               |
|    fps                  | 1458          |
|    iterations           | 53            |
|    time_elapsed         | 74            |
|    total_timesteps      | 108544        |
| train/                  |               |
|    approx_kl            | 0.00069877156 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.461        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 197           |
|    n_updates            | 520           |
|    policy_gradient_loss | 0.00022       |
|    value_loss           | 382           |
-------------------------------------------
Eval num_timesteps=110000, episode_reward=22.88 +/- 4.10
Episode length: 74.20 +/- 3.87
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 74.2         |
|    mean_reward          | 22.9         |
| time/                   |              |
|    total_timesteps      | 110000       |
| train/                  |              |
|    approx_kl            | 0.0007977712 |
|    clip_fraction        | 0.00439      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.497       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 33.4         |
|    n_updates            | 530          |
|    policy_gradient_loss | -0.0008      |
|    value_loss           | 148          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 162      |
|    ep_rew_mean     | 101      |
| time/              |          |
|    fps             | 1450     |
|    iterations      | 54       |
|    time_elapsed    | 76       |
|    total_timesteps | 110592   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 167          |
|    ep_rew_mean          | 107          |
| time/                   |              |
|    fps                  | 1451         |
|    iterations           | 55           |
|    time_elapsed         | 77           |
|    total_timesteps      | 112640       |
| train/                  |              |
|    approx_kl            | 0.0027622255 |
|    clip_fraction        | 0.011        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.454       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 217          |
|    n_updates            | 540          |
|    policy_gradient_loss | -0.00138     |
|    value_loss           | 282          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 160         |
|    ep_rew_mean          | 101         |
| time/                   |             |
|    fps                  | 1452        |
|    iterations           | 56          |
|    time_elapsed         | 78          |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.003983818 |
|    clip_fraction        | 0.0291      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.454      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 20.1        |
|    n_updates            | 550         |
|    policy_gradient_loss | -7.67e-05   |
|    value_loss           | 151         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 160         |
|    ep_rew_mean          | 101         |
| time/                   |             |
|    fps                  | 1453        |
|    iterations           | 57          |
|    time_elapsed         | 80          |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.003571753 |
|    clip_fraction        | 0.0138      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.48       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 168         |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.00168    |
|    value_loss           | 256         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 158          |
|    ep_rew_mean          | 98.6         |
| time/                   |              |
|    fps                  | 1454         |
|    iterations           | 58           |
|    time_elapsed         | 81           |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 0.0019179641 |
|    clip_fraction        | 0.019        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.503       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 76.7         |
|    n_updates            | 570          |
|    policy_gradient_loss | 0.000202     |
|    value_loss           | 174          |
------------------------------------------
Eval num_timesteps=120000, episode_reward=22.35 +/- 1.90
Episode length: 75.00 +/- 1.79
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 75           |
|    mean_reward          | 22.4         |
| time/                   |              |
|    total_timesteps      | 120000       |
| train/                  |              |
|    approx_kl            | 0.0023273428 |
|    clip_fraction        | 0.0255       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.552       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 93.8         |
|    n_updates            | 580          |
|    policy_gradient_loss | -0.00153     |
|    value_loss           | 231          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 160      |
|    ep_rew_mean     | 100      |
| time/              |          |
|    fps             | 1451     |
|    iterations      | 59       |
|    time_elapsed    | 83       |
|    total_timesteps | 120832   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 167          |
|    ep_rew_mean          | 108          |
| time/                   |              |
|    fps                  | 1452         |
|    iterations           | 60           |
|    time_elapsed         | 84           |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 0.0050638816 |
|    clip_fraction        | 0.0443       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.534       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 101          |
|    n_updates            | 590          |
|    policy_gradient_loss | -0.00362     |
|    value_loss           | 141          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 163           |
|    ep_rew_mean          | 103           |
| time/                   |               |
|    fps                  | 1453          |
|    iterations           | 61            |
|    time_elapsed         | 85            |
|    total_timesteps      | 124928        |
| train/                  |               |
|    approx_kl            | 0.00033998885 |
|    clip_fraction        | 0.00474       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.483        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 141           |
|    n_updates            | 600           |
|    policy_gradient_loss | -4.04e-05     |
|    value_loss           | 234           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 162          |
|    ep_rew_mean          | 102          |
| time/                   |              |
|    fps                  | 1453         |
|    iterations           | 62           |
|    time_elapsed         | 87           |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 0.0018583953 |
|    clip_fraction        | 0.0137       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.499       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 125          |
|    n_updates            | 610          |
|    policy_gradient_loss | 0.000508     |
|    value_loss           | 229          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 159          |
|    ep_rew_mean          | 98.3         |
| time/                   |              |
|    fps                  | 1454         |
|    iterations           | 63           |
|    time_elapsed         | 88           |
|    total_timesteps      | 129024       |
| train/                  |              |
|    approx_kl            | 0.0007906513 |
|    clip_fraction        | 0.00415      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.449       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 64.5         |
|    n_updates            | 620          |
|    policy_gradient_loss | -0.000348    |
|    value_loss           | 260          |
------------------------------------------
Eval num_timesteps=130000, episode_reward=20.48 +/- 2.87
Episode length: 71.80 +/- 1.47
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 71.8         |
|    mean_reward          | 20.5         |
| time/                   |              |
|    total_timesteps      | 130000       |
| train/                  |              |
|    approx_kl            | 0.0022959737 |
|    clip_fraction        | 0.0338       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.443       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 88.5         |
|    n_updates            | 630          |
|    policy_gradient_loss | -0.000727    |
|    value_loss           | 247          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 160      |
|    ep_rew_mean     | 100      |
| time/              |          |
|    fps             | 1444     |
|    iterations      | 64       |
|    time_elapsed    | 90       |
|    total_timesteps | 131072   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 154         |
|    ep_rew_mean          | 93.7        |
| time/                   |             |
|    fps                  | 1445        |
|    iterations           | 65          |
|    time_elapsed         | 92          |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.003220901 |
|    clip_fraction        | 0.0198      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.389      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 80.4        |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.00166    |
|    value_loss           | 228         |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 152           |
|    ep_rew_mean          | 93.6          |
| time/                   |               |
|    fps                  | 1445          |
|    iterations           | 66            |
|    time_elapsed         | 93            |
|    total_timesteps      | 135168        |
| train/                  |               |
|    approx_kl            | 0.00051061827 |
|    clip_fraction        | 0.0109        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.383        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 218           |
|    n_updates            | 650           |
|    policy_gradient_loss | -1.52e-05     |
|    value_loss           | 293           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 149          |
|    ep_rew_mean          | 91.6         |
| time/                   |              |
|    fps                  | 1446         |
|    iterations           | 67           |
|    time_elapsed         | 94           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 0.0004020309 |
|    clip_fraction        | 0.0127       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.36        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 205          |
|    n_updates            | 660          |
|    policy_gradient_loss | 0.000213     |
|    value_loss           | 264          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 145          |
|    ep_rew_mean          | 88.8         |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 68           |
|    time_elapsed         | 96           |
|    total_timesteps      | 139264       |
| train/                  |              |
|    approx_kl            | 0.0011829278 |
|    clip_fraction        | 0.00332      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.324       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 196          |
|    n_updates            | 670          |
|    policy_gradient_loss | -0.0007      |
|    value_loss           | 222          |
------------------------------------------
Eval num_timesteps=140000, episode_reward=24.75 +/- 1.88
Episode length: 77.40 +/- 3.20
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 77.4         |
|    mean_reward          | 24.8         |
| time/                   |              |
|    total_timesteps      | 140000       |
| train/                  |              |
|    approx_kl            | 0.0011099743 |
|    clip_fraction        | 0.0207       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.342       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 51.7         |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.000403    |
|    value_loss           | 303          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | 90.1     |
| time/              |          |
|    fps             | 1446     |
|    iterations      | 69       |
|    time_elapsed    | 97       |
|    total_timesteps | 141312   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 138          |
|    ep_rew_mean          | 83.2         |
| time/                   |              |
|    fps                  | 1446         |
|    iterations           | 70           |
|    time_elapsed         | 99           |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 0.0010253852 |
|    clip_fraction        | 0.0082       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.357       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 92           |
|    n_updates            | 690          |
|    policy_gradient_loss | -0.000414    |
|    value_loss           | 271          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 131          |
|    ep_rew_mean          | 77.1         |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 71           |
|    time_elapsed         | 100          |
|    total_timesteps      | 145408       |
| train/                  |              |
|    approx_kl            | 0.0021002202 |
|    clip_fraction        | 0.00796      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.313       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 191          |
|    n_updates            | 700          |
|    policy_gradient_loss | -0.000463    |
|    value_loss           | 353          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 130           |
|    ep_rew_mean          | 76            |
| time/                   |               |
|    fps                  | 1448          |
|    iterations           | 72            |
|    time_elapsed         | 101           |
|    total_timesteps      | 147456        |
| train/                  |               |
|    approx_kl            | 0.00013730167 |
|    clip_fraction        | 0.00303       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.291        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 136           |
|    n_updates            | 710           |
|    policy_gradient_loss | -7.54e-06     |
|    value_loss           | 378           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 124          |
|    ep_rew_mean          | 69.7         |
| time/                   |              |
|    fps                  | 1448         |
|    iterations           | 73           |
|    time_elapsed         | 103          |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 0.0010328458 |
|    clip_fraction        | 0.0318       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.347       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 154          |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.000934    |
|    value_loss           | 322          |
------------------------------------------
Eval num_timesteps=150000, episode_reward=20.15 +/- 2.24
Episode length: 72.80 +/- 2.64
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 72.8          |
|    mean_reward          | 20.2          |
| time/                   |               |
|    total_timesteps      | 150000        |
| train/                  |               |
|    approx_kl            | 0.00075811776 |
|    clip_fraction        | 0.0181        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.351        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 159           |
|    n_updates            | 730           |
|    policy_gradient_loss | -0.000495     |
|    value_loss           | 276           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 127      |
|    ep_rew_mean     | 73       |
| time/              |          |
|    fps             | 1447     |
|    iterations      | 74       |
|    time_elapsed    | 104      |
|    total_timesteps | 151552   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 128          |
|    ep_rew_mean          | 73.9         |
| time/                   |              |
|    fps                  | 1448         |
|    iterations           | 75           |
|    time_elapsed         | 106          |
|    total_timesteps      | 153600       |
| train/                  |              |
|    approx_kl            | 0.0019769336 |
|    clip_fraction        | 0.0183       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.347       |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 162          |
|    n_updates            | 740          |
|    policy_gradient_loss | -0.000551    |
|    value_loss           | 214          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 129           |
|    ep_rew_mean          | 75.5          |
| time/                   |               |
|    fps                  | 1448          |
|    iterations           | 76            |
|    time_elapsed         | 107           |
|    total_timesteps      | 155648        |
| train/                  |               |
|    approx_kl            | 0.00037166133 |
|    clip_fraction        | 0.0109        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.366        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 59.2          |
|    n_updates            | 750           |
|    policy_gradient_loss | 8.53e-05      |
|    value_loss           | 206           |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 136         |
|    ep_rew_mean          | 83.8        |
| time/                   |             |
|    fps                  | 1449        |
|    iterations           | 77          |
|    time_elapsed         | 108         |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.002394536 |
|    clip_fraction        | 0.0269      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.328      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 104         |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.00169    |
|    value_loss           | 276         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 139          |
|    ep_rew_mean          | 84.6         |
| time/                   |              |
|    fps                  | 1450         |
|    iterations           | 78           |
|    time_elapsed         | 110          |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 0.0012105932 |
|    clip_fraction        | 0.0104       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.351       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 112          |
|    n_updates            | 770          |
|    policy_gradient_loss | -6.5e-05     |
|    value_loss           | 186          |
------------------------------------------
Eval num_timesteps=160000, episode_reward=73.80 +/- 22.23
Episode length: 123.80 +/- 22.23
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 124         |
|    mean_reward          | 73.8        |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.002789944 |
|    clip_fraction        | 0.0293      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.373      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 200         |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.00138    |
|    value_loss           | 332         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 89.6     |
| time/              |          |
|    fps             | 1448     |
|    iterations      | 79       |
|    time_elapsed    | 111      |
|    total_timesteps | 161792   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 153          |
|    ep_rew_mean          | 99.3         |
| time/                   |              |
|    fps                  | 1448         |
|    iterations           | 80           |
|    time_elapsed         | 113          |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 0.0018123712 |
|    clip_fraction        | 0.0248       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.381       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 84.7         |
|    n_updates            | 790          |
|    policy_gradient_loss | -0.00185     |
|    value_loss           | 206          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 156          |
|    ep_rew_mean          | 102          |
| time/                   |              |
|    fps                  | 1449         |
|    iterations           | 81           |
|    time_elapsed         | 114          |
|    total_timesteps      | 165888       |
| train/                  |              |
|    approx_kl            | 0.0011362194 |
|    clip_fraction        | 0.0209       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.384       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 36.9         |
|    n_updates            | 800          |
|    policy_gradient_loss | 0.000127     |
|    value_loss           | 86.2         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 156          |
|    ep_rew_mean          | 101          |
| time/                   |              |
|    fps                  | 1449         |
|    iterations           | 82           |
|    time_elapsed         | 115          |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 0.0014398567 |
|    clip_fraction        | 0.0149       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.386       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 81.7         |
|    n_updates            | 810          |
|    policy_gradient_loss | -0.00107     |
|    value_loss           | 205          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 161          |
|    ep_rew_mean          | 107          |
| time/                   |              |
|    fps                  | 1450         |
|    iterations           | 83           |
|    time_elapsed         | 117          |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 0.0047096126 |
|    clip_fraction        | 0.0165       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.335       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 119          |
|    n_updates            | 820          |
|    policy_gradient_loss | -0.000707    |
|    value_loss           | 262          |
------------------------------------------
Eval num_timesteps=170000, episode_reward=70.60 +/- 25.09
Episode length: 120.60 +/- 25.09
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 121          |
|    mean_reward          | 70.6         |
| time/                   |              |
|    total_timesteps      | 170000       |
| train/                  |              |
|    approx_kl            | 0.0023752078 |
|    clip_fraction        | 0.0249       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.322       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 28.4         |
|    n_updates            | 830          |
|    policy_gradient_loss | -0.0012      |
|    value_loss           | 183          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 161      |
|    ep_rew_mean     | 106      |
| time/              |          |
|    fps             | 1448     |
|    iterations      | 84       |
|    time_elapsed    | 118      |
|    total_timesteps | 172032   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 157          |
|    ep_rew_mean          | 103          |
| time/                   |              |
|    fps                  | 1449         |
|    iterations           | 85           |
|    time_elapsed         | 120          |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 0.0030938382 |
|    clip_fraction        | 0.0271       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.279       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 173          |
|    n_updates            | 840          |
|    policy_gradient_loss | -0.00124     |
|    value_loss           | 292          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 162           |
|    ep_rew_mean          | 110           |
| time/                   |               |
|    fps                  | 1449          |
|    iterations           | 86            |
|    time_elapsed         | 121           |
|    total_timesteps      | 176128        |
| train/                  |               |
|    approx_kl            | 0.00092587486 |
|    clip_fraction        | 0.0151        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.276        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 135           |
|    n_updates            | 850           |
|    policy_gradient_loss | 0.000239      |
|    value_loss           | 307           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 154          |
|    ep_rew_mean          | 100          |
| time/                   |              |
|    fps                  | 1450         |
|    iterations           | 87           |
|    time_elapsed         | 122          |
|    total_timesteps      | 178176       |
| train/                  |              |
|    approx_kl            | 0.0019030822 |
|    clip_fraction        | 0.0175       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.314       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 52.9         |
|    n_updates            | 860          |
|    policy_gradient_loss | -0.000606    |
|    value_loss           | 185          |
------------------------------------------
Eval num_timesteps=180000, episode_reward=49.00 +/- 28.71
Episode length: 99.00 +/- 28.71
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 99           |
|    mean_reward          | 49           |
| time/                   |              |
|    total_timesteps      | 180000       |
| train/                  |              |
|    approx_kl            | 0.0014009294 |
|    clip_fraction        | 0.0157       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.323       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 211          |
|    n_updates            | 870          |
|    policy_gradient_loss | -0.000531    |
|    value_loss           | 383          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | 92.9     |
| time/              |          |
|    fps             | 1443     |
|    iterations      | 88       |
|    time_elapsed    | 124      |
|    total_timesteps | 180224   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 147          |
|    ep_rew_mean          | 93.7         |
| time/                   |              |
|    fps                  | 1444         |
|    iterations           | 89           |
|    time_elapsed         | 126          |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 0.0034553448 |
|    clip_fraction        | 0.0254       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.331       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 116          |
|    n_updates            | 880          |
|    policy_gradient_loss | -0.00179     |
|    value_loss           | 291          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 136         |
|    ep_rew_mean          | 81.4        |
| time/                   |             |
|    fps                  | 1444        |
|    iterations           | 90          |
|    time_elapsed         | 127         |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.004182476 |
|    clip_fraction        | 0.0304      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.342      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 154         |
|    n_updates            | 890         |
|    policy_gradient_loss | -4.4e-06    |
|    value_loss           | 270         |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 142           |
|    ep_rew_mean          | 88.7          |
| time/                   |               |
|    fps                  | 1445          |
|    iterations           | 91            |
|    time_elapsed         | 128           |
|    total_timesteps      | 186368        |
| train/                  |               |
|    approx_kl            | 0.00089456444 |
|    clip_fraction        | 0.0166        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.264        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 131           |
|    n_updates            | 900           |
|    policy_gradient_loss | -0.000402     |
|    value_loss           | 349           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 134          |
|    ep_rew_mean          | 79.1         |
| time/                   |              |
|    fps                  | 1445         |
|    iterations           | 92           |
|    time_elapsed         | 130          |
|    total_timesteps      | 188416       |
| train/                  |              |
|    approx_kl            | 0.0011321264 |
|    clip_fraction        | 0.00996      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.244       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 81.1         |
|    n_updates            | 910          |
|    policy_gradient_loss | -9.67e-05    |
|    value_loss           | 185          |
------------------------------------------
Eval num_timesteps=190000, episode_reward=48.80 +/- 30.47
Episode length: 98.80 +/- 30.47
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 98.8         |
|    mean_reward          | 48.8         |
| time/                   |              |
|    total_timesteps      | 190000       |
| train/                  |              |
|    approx_kl            | 0.0021594823 |
|    clip_fraction        | 0.0234       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.292       |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 128          |
|    n_updates            | 920          |
|    policy_gradient_loss | 0.000294     |
|    value_loss           | 395          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 135      |
|    ep_rew_mean     | 79.3     |
| time/              |          |
|    fps             | 1444     |
|    iterations      | 93       |
|    time_elapsed    | 131      |
|    total_timesteps | 190464   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 135          |
|    ep_rew_mean          | 80.4         |
| time/                   |              |
|    fps                  | 1445         |
|    iterations           | 94           |
|    time_elapsed         | 133          |
|    total_timesteps      | 192512       |
| train/                  |              |
|    approx_kl            | 0.0012831988 |
|    clip_fraction        | 0.00459      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.306       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 178          |
|    n_updates            | 930          |
|    policy_gradient_loss | 0.00018      |
|    value_loss           | 250          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 138          |
|    ep_rew_mean          | 84           |
| time/                   |              |
|    fps                  | 1445         |
|    iterations           | 95           |
|    time_elapsed         | 134          |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 0.0018071663 |
|    clip_fraction        | 0.0125       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.292       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 153          |
|    n_updates            | 940          |
|    policy_gradient_loss | -0.000588    |
|    value_loss           | 300          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 135          |
|    ep_rew_mean          | 81.1         |
| time/                   |              |
|    fps                  | 1446         |
|    iterations           | 96           |
|    time_elapsed         | 135          |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0012468284 |
|    clip_fraction        | 0.0106       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.277       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 120          |
|    n_updates            | 950          |
|    policy_gradient_loss | 0.000137     |
|    value_loss           | 231          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 140         |
|    ep_rew_mean          | 86.4        |
| time/                   |             |
|    fps                  | 1446        |
|    iterations           | 97          |
|    time_elapsed         | 137         |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.001538946 |
|    clip_fraction        | 0.0246      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.296      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 117         |
|    n_updates            | 960         |
|    policy_gradient_loss | -4.19e-05   |
|    value_loss           | 300         |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=49.40 +/- 29.10
Episode length: 99.40 +/- 29.10
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 99.4         |
|    mean_reward          | 49.4         |
| time/                   |              |
|    total_timesteps      | 200000       |
| train/                  |              |
|    approx_kl            | 0.0018417478 |
|    clip_fraction        | 0.0144       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.33        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 112          |
|    n_updates            | 970          |
|    policy_gradient_loss | -0.000671    |
|    value_loss           | 233          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 140      |
|    ep_rew_mean     | 86.1     |
| time/              |          |
|    fps             | 1445     |
|    iterations      | 98       |
|    time_elapsed    | 138      |
|    total_timesteps | 200704   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 148          |
|    ep_rew_mean          | 93.9         |
| time/                   |              |
|    fps                  | 1446         |
|    iterations           | 99           |
|    time_elapsed         | 140          |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 0.0015458891 |
|    clip_fraction        | 0.0109       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.361       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 109          |
|    n_updates            | 980          |
|    policy_gradient_loss | -6.14e-05    |
|    value_loss           | 165          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 148         |
|    ep_rew_mean          | 95.5        |
| time/                   |             |
|    fps                  | 1446        |
|    iterations           | 100         |
|    time_elapsed         | 141         |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.005105174 |
|    clip_fraction        | 0.0358      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.325      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 69.7        |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.00265    |
|    value_loss           | 253         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 150          |
|    ep_rew_mean          | 97.5         |
| time/                   |              |
|    fps                  | 1446         |
|    iterations           | 101          |
|    time_elapsed         | 142          |
|    total_timesteps      | 206848       |
| train/                  |              |
|    approx_kl            | 0.0010636033 |
|    clip_fraction        | 0.0124       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.318       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 115          |
|    n_updates            | 1000         |
|    policy_gradient_loss | -0.0011      |
|    value_loss           | 229          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 146          |
|    ep_rew_mean          | 91.9         |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 102          |
|    time_elapsed         | 144          |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 0.0013347727 |
|    clip_fraction        | 0.022        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.35        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 289          |
|    n_updates            | 1010         |
|    policy_gradient_loss | -0.000741    |
|    value_loss           | 306          |
------------------------------------------
Eval num_timesteps=210000, episode_reward=48.60 +/- 31.06
Episode length: 98.60 +/- 31.06
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 98.6         |
|    mean_reward          | 48.6         |
| time/                   |              |
|    total_timesteps      | 210000       |
| train/                  |              |
|    approx_kl            | 0.0012247147 |
|    clip_fraction        | 0.0323       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.403       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 146          |
|    n_updates            | 1020         |
|    policy_gradient_loss | -0.00058     |
|    value_loss           | 313          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | 94.2     |
| time/              |          |
|    fps             | 1446     |
|    iterations      | 103      |
|    time_elapsed    | 145      |
|    total_timesteps | 210944   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 151          |
|    ep_rew_mean          | 96.4         |
| time/                   |              |
|    fps                  | 1446         |
|    iterations           | 104          |
|    time_elapsed         | 147          |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 0.0023138463 |
|    clip_fraction        | 0.0406       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.443       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 86.7         |
|    n_updates            | 1030         |
|    policy_gradient_loss | -0.000751    |
|    value_loss           | 215          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 150          |
|    ep_rew_mean          | 93.6         |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 105          |
|    time_elapsed         | 148          |
|    total_timesteps      | 215040       |
| train/                  |              |
|    approx_kl            | 0.0005109311 |
|    clip_fraction        | 0.0108       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.444       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 59.4         |
|    n_updates            | 1040         |
|    policy_gradient_loss | -2.87e-05    |
|    value_loss           | 263          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 154          |
|    ep_rew_mean          | 97.1         |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 106          |
|    time_elapsed         | 149          |
|    total_timesteps      | 217088       |
| train/                  |              |
|    approx_kl            | 0.0014289102 |
|    clip_fraction        | 0.0179       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.451       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 165          |
|    n_updates            | 1050         |
|    policy_gradient_loss | -0.00194     |
|    value_loss           | 228          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 150         |
|    ep_rew_mean          | 91.8        |
| time/                   |             |
|    fps                  | 1447        |
|    iterations           | 107         |
|    time_elapsed         | 151         |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.006994142 |
|    clip_fraction        | 0.0479      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.424      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 29.1        |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.00406    |
|    value_loss           | 65.3        |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=49.80 +/- 29.66
Episode length: 99.80 +/- 29.66
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 99.8         |
|    mean_reward          | 49.8         |
| time/                   |              |
|    total_timesteps      | 220000       |
| train/                  |              |
|    approx_kl            | 0.0025612637 |
|    clip_fraction        | 0.0146       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.431       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 307          |
|    n_updates            | 1070         |
|    policy_gradient_loss | -0.000323    |
|    value_loss           | 348          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 151      |
|    ep_rew_mean     | 90.6     |
| time/              |          |
|    fps             | 1447     |
|    iterations      | 108      |
|    time_elapsed    | 152      |
|    total_timesteps | 221184   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 153          |
|    ep_rew_mean          | 92.5         |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 109          |
|    time_elapsed         | 154          |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 0.0020223171 |
|    clip_fraction        | 0.0228       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.481       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 114          |
|    n_updates            | 1080         |
|    policy_gradient_loss | 8.46e-05     |
|    value_loss           | 260          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 156          |
|    ep_rew_mean          | 94.8         |
| time/                   |              |
|    fps                  | 1448         |
|    iterations           | 110          |
|    time_elapsed         | 155          |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 0.0020716533 |
|    clip_fraction        | 0.0245       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.508       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 185          |
|    n_updates            | 1090         |
|    policy_gradient_loss | -0.00145     |
|    value_loss           | 212          |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 158        |
|    ep_rew_mean          | 96.9       |
| time/                   |            |
|    fps                  | 1448       |
|    iterations           | 111        |
|    time_elapsed         | 156        |
|    total_timesteps      | 227328     |
| train/                  |            |
|    approx_kl            | 0.00325737 |
|    clip_fraction        | 0.0364     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.537     |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 99.1       |
|    n_updates            | 1100       |
|    policy_gradient_loss | -0.00254   |
|    value_loss           | 193        |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 161          |
|    ep_rew_mean          | 99.8         |
| time/                   |              |
|    fps                  | 1448         |
|    iterations           | 112          |
|    time_elapsed         | 158          |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 0.0021649147 |
|    clip_fraction        | 0.0401       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.555       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 150          |
|    n_updates            | 1110         |
|    policy_gradient_loss | -0.000499    |
|    value_loss           | 241          |
------------------------------------------
Eval num_timesteps=230000, episode_reward=71.40 +/- 25.30
Episode length: 121.40 +/- 25.30
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 121          |
|    mean_reward          | 71.4         |
| time/                   |              |
|    total_timesteps      | 230000       |
| train/                  |              |
|    approx_kl            | 0.0018262217 |
|    clip_fraction        | 0.0342       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.539       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 106          |
|    n_updates            | 1120         |
|    policy_gradient_loss | -0.002       |
|    value_loss           | 137          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 151      |
|    ep_rew_mean     | 88.6     |
| time/              |          |
|    fps             | 1447     |
|    iterations      | 113      |
|    time_elapsed    | 159      |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 148         |
|    ep_rew_mean          | 85.1        |
| time/                   |             |
|    fps                  | 1448        |
|    iterations           | 114         |
|    time_elapsed         | 161         |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.002064965 |
|    clip_fraction        | 0.0161      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.57       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 128         |
|    n_updates            | 1130        |
|    policy_gradient_loss | 0.000149    |
|    value_loss           | 356         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 154          |
|    ep_rew_mean          | 90.4         |
| time/                   |              |
|    fps                  | 1448         |
|    iterations           | 115          |
|    time_elapsed         | 162          |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 0.0031523854 |
|    clip_fraction        | 0.0348       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.585       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 156          |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.000706    |
|    value_loss           | 271          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 161         |
|    ep_rew_mean          | 98.5        |
| time/                   |             |
|    fps                  | 1448        |
|    iterations           | 116         |
|    time_elapsed         | 163         |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.004601525 |
|    clip_fraction        | 0.0102      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.58       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 36          |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.000926   |
|    value_loss           | 101         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 155        |
|    ep_rew_mean          | 90.8       |
| time/                   |            |
|    fps                  | 1449       |
|    iterations           | 117        |
|    time_elapsed         | 165        |
|    total_timesteps      | 239616     |
| train/                  |            |
|    approx_kl            | 0.00569958 |
|    clip_fraction        | 0.0522     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.539     |
|    explained_variance   | 5.96e-08   |
|    learning_rate        | 0.0003     |
|    loss                 | 71.9       |
|    n_updates            | 1160       |
|    policy_gradient_loss | -0.00229   |
|    value_loss           | 113        |
----------------------------------------
Eval num_timesteps=240000, episode_reward=59.20 +/- 27.97
Episode length: 109.20 +/- 27.97
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 109          |
|    mean_reward          | 59.2         |
| time/                   |              |
|    total_timesteps      | 240000       |
| train/                  |              |
|    approx_kl            | 0.0013406947 |
|    clip_fraction        | 0.0211       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.51        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 227          |
|    n_updates            | 1170         |
|    policy_gradient_loss | -0.000483    |
|    value_loss           | 359          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 157      |
|    ep_rew_mean     | 92.3     |
| time/              |          |
|    fps             | 1448     |
|    iterations      | 118      |
|    time_elapsed    | 166      |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 153         |
|    ep_rew_mean          | 88.6        |
| time/                   |             |
|    fps                  | 1448        |
|    iterations           | 119         |
|    time_elapsed         | 168         |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.004436652 |
|    clip_fraction        | 0.0249      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.545      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 66.4        |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.00118    |
|    value_loss           | 159         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 158          |
|    ep_rew_mean          | 94.1         |
| time/                   |              |
|    fps                  | 1449         |
|    iterations           | 120          |
|    time_elapsed         | 169          |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 0.0019941872 |
|    clip_fraction        | 0.00576      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.55        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 114          |
|    n_updates            | 1190         |
|    policy_gradient_loss | -0.0001      |
|    value_loss           | 257          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 166         |
|    ep_rew_mean          | 103         |
| time/                   |             |
|    fps                  | 1449        |
|    iterations           | 121         |
|    time_elapsed         | 170         |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.005295077 |
|    clip_fraction        | 0.0541      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.594      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 41.5        |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.00231    |
|    value_loss           | 134         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 168          |
|    ep_rew_mean          | 105          |
| time/                   |              |
|    fps                  | 1449         |
|    iterations           | 122          |
|    time_elapsed         | 172          |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 0.0061285566 |
|    clip_fraction        | 0.0669       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.62        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 23.6         |
|    n_updates            | 1210         |
|    policy_gradient_loss | -0.00108     |
|    value_loss           | 88.1         |
------------------------------------------
Eval num_timesteps=250000, episode_reward=25.68 +/- 2.44
Episode length: 77.00 +/- 1.41
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 77          |
|    mean_reward          | 25.7        |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.001225207 |
|    clip_fraction        | 0.0185      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.597      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 192         |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.000719   |
|    value_loss           | 204         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 167      |
|    ep_rew_mean     | 104      |
| time/              |          |
|    fps             | 1449     |
|    iterations      | 123      |
|    time_elapsed    | 173      |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 167         |
|    ep_rew_mean          | 103         |
| time/                   |             |
|    fps                  | 1449        |
|    iterations           | 124         |
|    time_elapsed         | 175         |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.003012821 |
|    clip_fraction        | 0.0041      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.605      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 84.9        |
|    n_updates            | 1230        |
|    policy_gradient_loss | 2.41e-05    |
|    value_loss           | 175         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 168          |
|    ep_rew_mean          | 105          |
| time/                   |              |
|    fps                  | 1449         |
|    iterations           | 125          |
|    time_elapsed         | 176          |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 0.0039072554 |
|    clip_fraction        | 0.0201       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.599       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 54.2         |
|    n_updates            | 1240         |
|    policy_gradient_loss | -0.00184     |
|    value_loss           | 92.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 169          |
|    ep_rew_mean          | 106          |
| time/                   |              |
|    fps                  | 1450         |
|    iterations           | 126          |
|    time_elapsed         | 177          |
|    total_timesteps      | 258048       |
| train/                  |              |
|    approx_kl            | 0.0024979245 |
|    clip_fraction        | 0.0442       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.593       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 75.8         |
|    n_updates            | 1250         |
|    policy_gradient_loss | -0.00155     |
|    value_loss           | 261          |
------------------------------------------
Eval num_timesteps=260000, episode_reward=47.00 +/- 28.65
Episode length: 97.00 +/- 28.65
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 97           |
|    mean_reward          | 47           |
| time/                   |              |
|    total_timesteps      | 260000       |
| train/                  |              |
|    approx_kl            | 0.0025610481 |
|    clip_fraction        | 0.0265       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.612       |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 135          |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.00145     |
|    value_loss           | 224          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 176      |
|    ep_rew_mean     | 113      |
| time/              |          |
|    fps             | 1449     |
|    iterations      | 127      |
|    time_elapsed    | 179      |
|    total_timesteps | 260096   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 177          |
|    ep_rew_mean          | 114          |
| time/                   |              |
|    fps                  | 1449         |
|    iterations           | 128          |
|    time_elapsed         | 180          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0035432985 |
|    clip_fraction        | 0.0205       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.614       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 38.7         |
|    n_updates            | 1270         |
|    policy_gradient_loss | -0.000378    |
|    value_loss           | 62.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 174          |
|    ep_rew_mean          | 110          |
| time/                   |              |
|    fps                  | 1450         |
|    iterations           | 129          |
|    time_elapsed         | 182          |
|    total_timesteps      | 264192       |
| train/                  |              |
|    approx_kl            | 0.0031637917 |
|    clip_fraction        | 0.0151       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.594       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 112          |
|    n_updates            | 1280         |
|    policy_gradient_loss | 0.000104     |
|    value_loss           | 183          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 172         |
|    ep_rew_mean          | 107         |
| time/                   |             |
|    fps                  | 1450        |
|    iterations           | 130         |
|    time_elapsed         | 183         |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.002043887 |
|    clip_fraction        | 0.04        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.621      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 183         |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.000307   |
|    value_loss           | 232         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 172          |
|    ep_rew_mean          | 107          |
| time/                   |              |
|    fps                  | 1450         |
|    iterations           | 131          |
|    time_elapsed         | 184          |
|    total_timesteps      | 268288       |
| train/                  |              |
|    approx_kl            | 0.0054091327 |
|    clip_fraction        | 0.0761       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.632       |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 111          |
|    n_updates            | 1300         |
|    policy_gradient_loss | -0.00576     |
|    value_loss           | 222          |
------------------------------------------
Eval num_timesteps=270000, episode_reward=49.80 +/- 30.54
Episode length: 99.80 +/- 30.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 99.8        |
|    mean_reward          | 49.8        |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.009393942 |
|    clip_fraction        | 0.0179      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.608      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 62          |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.0018     |
|    value_loss           | 196         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 175      |
|    ep_rew_mean     | 110      |
| time/              |          |
|    fps             | 1450     |
|    iterations      | 132      |
|    time_elapsed    | 186      |
|    total_timesteps | 270336   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 174         |
|    ep_rew_mean          | 109         |
| time/                   |             |
|    fps                  | 1450        |
|    iterations           | 133         |
|    time_elapsed         | 187         |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.005528057 |
|    clip_fraction        | 0.069       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.6        |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 16.9        |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.00257    |
|    value_loss           | 62.8        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 177          |
|    ep_rew_mean          | 113          |
| time/                   |              |
|    fps                  | 1450         |
|    iterations           | 134          |
|    time_elapsed         | 189          |
|    total_timesteps      | 274432       |
| train/                  |              |
|    approx_kl            | 0.0012631076 |
|    clip_fraction        | 0.0301       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.571       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 97.6         |
|    n_updates            | 1330         |
|    policy_gradient_loss | -0.00137     |
|    value_loss           | 211          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 179          |
|    ep_rew_mean          | 114          |
| time/                   |              |
|    fps                  | 1451         |
|    iterations           | 135          |
|    time_elapsed         | 190          |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 0.0037663253 |
|    clip_fraction        | 0.0191       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.561       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 36.9         |
|    n_updates            | 1340         |
|    policy_gradient_loss | -0.00387     |
|    value_loss           | 182          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 176         |
|    ep_rew_mean          | 112         |
| time/                   |             |
|    fps                  | 1451        |
|    iterations           | 136         |
|    time_elapsed         | 191         |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.002425821 |
|    clip_fraction        | 0.0257      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.575      |
|    explained_variance   | 1.19e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 59.8        |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.00132    |
|    value_loss           | 153         |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=62.40 +/- 29.37
Episode length: 112.40 +/- 29.37
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 112          |
|    mean_reward          | 62.4         |
| time/                   |              |
|    total_timesteps      | 280000       |
| train/                  |              |
|    approx_kl            | 0.0014862398 |
|    clip_fraction        | 0.0134       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.583       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 73.4         |
|    n_updates            | 1360         |
|    policy_gradient_loss | -0.00101     |
|    value_loss           | 155          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 178      |
|    ep_rew_mean     | 114      |
| time/              |          |
|    fps             | 1450     |
|    iterations      | 137      |
|    time_elapsed    | 193      |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 177         |
|    ep_rew_mean          | 113         |
| time/                   |             |
|    fps                  | 1450        |
|    iterations           | 138         |
|    time_elapsed         | 194         |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.004151718 |
|    clip_fraction        | 0.0101      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.573      |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 103         |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.00179    |
|    value_loss           | 218         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 180         |
|    ep_rew_mean          | 116         |
| time/                   |             |
|    fps                  | 1451        |
|    iterations           | 139         |
|    time_elapsed         | 196         |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.002746949 |
|    clip_fraction        | 0.00742     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.571      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 78.2        |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.000549   |
|    value_loss           | 204         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 177          |
|    ep_rew_mean          | 114          |
| time/                   |              |
|    fps                  | 1451         |
|    iterations           | 140          |
|    time_elapsed         | 197          |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 0.0039455825 |
|    clip_fraction        | 0.0251       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.508       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 116          |
|    n_updates            | 1390         |
|    policy_gradient_loss | -0.00401     |
|    value_loss           | 207          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 176          |
|    ep_rew_mean          | 114          |
| time/                   |              |
|    fps                  | 1451         |
|    iterations           | 141          |
|    time_elapsed         | 198          |
|    total_timesteps      | 288768       |
| train/                  |              |
|    approx_kl            | 0.0015141866 |
|    clip_fraction        | 0.00635      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.487       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 71.6         |
|    n_updates            | 1400         |
|    policy_gradient_loss | 0.000203     |
|    value_loss           | 210          |
------------------------------------------
Eval num_timesteps=290000, episode_reward=59.00 +/- 29.07
Episode length: 109.00 +/- 29.07
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 109           |
|    mean_reward          | 59            |
| time/                   |               |
|    total_timesteps      | 290000        |
| train/                  |               |
|    approx_kl            | 0.00018834439 |
|    clip_fraction        | 9.77e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.499        |
|    explained_variance   | 0             |
|    learning_rate        | 0.0003        |
|    loss                 | 138           |
|    n_updates            | 1410          |
|    policy_gradient_loss | 5.6e-05       |
|    value_loss           | 182           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 175      |
|    ep_rew_mean     | 113      |
| time/              |          |
|    fps             | 1450     |
|    iterations      | 142      |
|    time_elapsed    | 200      |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 171         |
|    ep_rew_mean          | 109         |
| time/                   |             |
|    fps                  | 1451        |
|    iterations           | 143         |
|    time_elapsed         | 201         |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.003953784 |
|    clip_fraction        | 0.0279      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.522      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 96.4        |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.000946   |
|    value_loss           | 179         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 168        |
|    ep_rew_mean          | 106        |
| time/                   |            |
|    fps                  | 1451       |
|    iterations           | 144        |
|    time_elapsed         | 203        |
|    total_timesteps      | 294912     |
| train/                  |            |
|    approx_kl            | 0.01723193 |
|    clip_fraction        | 0.0612     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.559     |
|    explained_variance   | 1.19e-07   |
|    learning_rate        | 0.0003     |
|    loss                 | 98.7       |
|    n_updates            | 1430       |
|    policy_gradient_loss | -0.00195   |
|    value_loss           | 265        |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 169          |
|    ep_rew_mean          | 106          |
| time/                   |              |
|    fps                  | 1451         |
|    iterations           | 145          |
|    time_elapsed         | 204          |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 0.0022435514 |
|    clip_fraction        | 0.0204       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.611       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 107          |
|    n_updates            | 1440         |
|    policy_gradient_loss | -0.00239     |
|    value_loss           | 224          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 165         |
|    ep_rew_mean          | 102         |
| time/                   |             |
|    fps                  | 1452        |
|    iterations           | 146         |
|    time_elapsed         | 205         |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.004353604 |
|    clip_fraction        | 0.0559      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.635      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 46.6        |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.0021     |
|    value_loss           | 168         |
-----------------------------------------
Eval num_timesteps=300000, episode_reward=47.00 +/- 29.52
Episode length: 97.00 +/- 29.52
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 97          |
|    mean_reward          | 47          |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.003981878 |
|    clip_fraction        | 0.0225      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.571      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 96.7        |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.00108    |
|    value_loss           | 275         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 167      |
|    ep_rew_mean     | 104      |
| time/              |          |
|    fps             | 1451     |
|    iterations      | 147      |
|    time_elapsed    | 207      |
|    total_timesteps | 301056   |
---------------------------------

Training complete!
Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-07_23-38-32

