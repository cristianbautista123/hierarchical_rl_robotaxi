Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-08_23-03-35

Map saved at: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-08_23-03-35/map_visualization.png

Using cpu device
Wrapping the env in a DummyVecEnv.
Logging to /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-08_23-03-35/tensorboard/PPO_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 236      |
|    ep_rew_mean     | -252     |
| time/              |          |
|    fps             | 2629     |
|    iterations      | 1        |
|    time_elapsed    | 0        |
|    total_timesteps | 2048     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 224         |
|    ep_rew_mean          | -186        |
| time/                   |             |
|    fps                  | 1857        |
|    iterations           | 2           |
|    time_elapsed         | 2           |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.027883891 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | 0.0284      |
|    learning_rate        | 0.0003      |
|    loss                 | 46.4        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0404     |
|    value_loss           | 159         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 204         |
|    ep_rew_mean          | -130        |
| time/                   |             |
|    fps                  | 1698        |
|    iterations           | 3           |
|    time_elapsed         | 3           |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.037345976 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | 0.00209     |
|    learning_rate        | 0.0003      |
|    loss                 | 31.8        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0311     |
|    value_loss           | 91.9        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 200         |
|    ep_rew_mean          | -96.5       |
| time/                   |             |
|    fps                  | 1621        |
|    iterations           | 4           |
|    time_elapsed         | 5           |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.015725251 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.941      |
|    explained_variance   | 0.135       |
|    learning_rate        | 0.0003      |
|    loss                 | 27.8        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0181     |
|    value_loss           | 67.3        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=50.80 +/- 17.05
Episode length: 100.80 +/- 17.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 101         |
|    mean_reward          | 50.8        |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.006554142 |
|    clip_fraction        | 0.0801      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.891      |
|    explained_variance   | 0.473       |
|    learning_rate        | 0.0003      |
|    loss                 | 16.5        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0124     |
|    value_loss           | 45.4        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 196      |
|    ep_rew_mean     | -68.7    |
| time/              |          |
|    fps             | 1520     |
|    iterations      | 5        |
|    time_elapsed    | 6        |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 192         |
|    ep_rew_mean          | -46.4       |
| time/                   |             |
|    fps                  | 1509        |
|    iterations           | 6           |
|    time_elapsed         | 8           |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.012580151 |
|    clip_fraction        | 0.0871      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.822      |
|    explained_variance   | 0.542       |
|    learning_rate        | 0.0003      |
|    loss                 | 25.4        |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0101     |
|    value_loss           | 52.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 190         |
|    ep_rew_mean          | -29.1       |
| time/                   |             |
|    fps                  | 1501        |
|    iterations           | 7           |
|    time_elapsed         | 9           |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.004273556 |
|    clip_fraction        | 0.0471      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.781      |
|    explained_variance   | 0.437       |
|    learning_rate        | 0.0003      |
|    loss                 | 25.2        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00785    |
|    value_loss           | 69.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 187         |
|    ep_rew_mean          | -15.5       |
| time/                   |             |
|    fps                  | 1494        |
|    iterations           | 8           |
|    time_elapsed         | 10          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.007079587 |
|    clip_fraction        | 0.0493      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.713      |
|    explained_variance   | 0.343       |
|    learning_rate        | 0.0003      |
|    loss                 | 20.9        |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00821    |
|    value_loss           | 59.2        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 190          |
|    ep_rew_mean          | -1.95        |
| time/                   |              |
|    fps                  | 1486         |
|    iterations           | 9            |
|    time_elapsed         | 12           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0077576116 |
|    clip_fraction        | 0.0514       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.691       |
|    explained_variance   | 0.27         |
|    learning_rate        | 0.0003       |
|    loss                 | 50.3         |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00779     |
|    value_loss           | 93.1         |
------------------------------------------
Eval num_timesteps=20000, episode_reward=39.20 +/- 15.10
Episode length: 89.20 +/- 15.10
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 89.2       |
|    mean_reward          | 39.2       |
| time/                   |            |
|    total_timesteps      | 20000      |
| train/                  |            |
|    approx_kl            | 0.01052929 |
|    clip_fraction        | 0.0403     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.617     |
|    explained_variance   | 0.215      |
|    learning_rate        | 0.0003     |
|    loss                 | 17.6       |
|    n_updates            | 90         |
|    policy_gradient_loss | -0.00676   |
|    value_loss           | 65.9       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 182      |
|    ep_rew_mean     | 31.9     |
| time/              |          |
|    fps             | 1466     |
|    iterations      | 10       |
|    time_elapsed    | 13       |
|    total_timesteps | 20480    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 176         |
|    ep_rew_mean          | 53.9        |
| time/                   |             |
|    fps                  | 1464        |
|    iterations           | 11          |
|    time_elapsed         | 15          |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.003892299 |
|    clip_fraction        | 0.0224      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.592      |
|    explained_variance   | 0.223       |
|    learning_rate        | 0.0003      |
|    loss                 | 83.4        |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00513    |
|    value_loss           | 136         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 178          |
|    ep_rew_mean          | 70.6         |
| time/                   |              |
|    fps                  | 1461         |
|    iterations           | 12           |
|    time_elapsed         | 16           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0059536044 |
|    clip_fraction        | 0.0452       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.546       |
|    explained_variance   | 0.3          |
|    learning_rate        | 0.0003       |
|    loss                 | 72           |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00554     |
|    value_loss           | 129          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 181         |
|    ep_rew_mean          | 83.3        |
| time/                   |             |
|    fps                  | 1460        |
|    iterations           | 13          |
|    time_elapsed         | 18          |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.002933247 |
|    clip_fraction        | 0.0276      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.539      |
|    explained_variance   | 0.245       |
|    learning_rate        | 0.0003      |
|    loss                 | 37.4        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00202    |
|    value_loss           | 59.8        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 182         |
|    ep_rew_mean          | 94.4        |
| time/                   |             |
|    fps                  | 1458        |
|    iterations           | 14          |
|    time_elapsed         | 19          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.004907754 |
|    clip_fraction        | 0.0356      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.498      |
|    explained_variance   | 0.263       |
|    learning_rate        | 0.0003      |
|    loss                 | 19.2        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00427    |
|    value_loss           | 97          |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=96.43 +/- 0.39
Episode length: 150.40 +/- 1.36
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 150          |
|    mean_reward          | 96.4         |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0034199674 |
|    clip_fraction        | 0.024        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.464       |
|    explained_variance   | 0.292        |
|    learning_rate        | 0.0003       |
|    loss                 | 16.6         |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00285     |
|    value_loss           | 69           |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 184      |
|    ep_rew_mean     | 102      |
| time/              |          |
|    fps             | 1362     |
|    iterations      | 15       |
|    time_elapsed    | 22       |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 184          |
|    ep_rew_mean          | 109          |
| time/                   |              |
|    fps                  | 1368         |
|    iterations           | 16           |
|    time_elapsed         | 23           |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0024057426 |
|    clip_fraction        | 0.0218       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.394       |
|    explained_variance   | 0.31         |
|    learning_rate        | 0.0003       |
|    loss                 | 59.5         |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00274     |
|    value_loss           | 101          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 188          |
|    ep_rew_mean          | 118          |
| time/                   |              |
|    fps                  | 1372         |
|    iterations           | 17           |
|    time_elapsed         | 25           |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0022820001 |
|    clip_fraction        | 0.0141       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.362       |
|    explained_variance   | 0.292        |
|    learning_rate        | 0.0003       |
|    loss                 | 96.1         |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00268     |
|    value_loss           | 147          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 189         |
|    ep_rew_mean          | 124         |
| time/                   |             |
|    fps                  | 1376        |
|    iterations           | 18          |
|    time_elapsed         | 26          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.003431262 |
|    clip_fraction        | 0.0282      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.31       |
|    explained_variance   | 0.379       |
|    learning_rate        | 0.0003      |
|    loss                 | 82.6        |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0023     |
|    value_loss           | 105         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 191          |
|    ep_rew_mean          | 129          |
| time/                   |              |
|    fps                  | 1379         |
|    iterations           | 19           |
|    time_elapsed         | 28           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 0.0013357957 |
|    clip_fraction        | 0.0151       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.275       |
|    explained_variance   | 0.571        |
|    learning_rate        | 0.0003       |
|    loss                 | 20.6         |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.00263     |
|    value_loss           | 58.5         |
------------------------------------------
Eval num_timesteps=40000, episode_reward=72.34 +/- 31.48
Episode length: 125.60 +/- 32.85
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 126         |
|    mean_reward          | 72.3        |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.002576592 |
|    clip_fraction        | 0.021       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.247      |
|    explained_variance   | 0.317       |
|    learning_rate        | 0.0003      |
|    loss                 | 85.8        |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.00545    |
|    value_loss           | 188         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 195      |
|    ep_rew_mean     | 138      |
| time/              |          |
|    fps             | 1348     |
|    iterations      | 20       |
|    time_elapsed    | 30       |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 194          |
|    ep_rew_mean          | 140          |
| time/                   |              |
|    fps                  | 1352         |
|    iterations           | 21           |
|    time_elapsed         | 31           |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0011335302 |
|    clip_fraction        | 0.00659      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.234       |
|    explained_variance   | 0.552        |
|    learning_rate        | 0.0003       |
|    loss                 | 19.9         |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00205     |
|    value_loss           | 82.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 195          |
|    ep_rew_mean          | 146          |
| time/                   |              |
|    fps                  | 1353         |
|    iterations           | 22           |
|    time_elapsed         | 33           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0011948477 |
|    clip_fraction        | 0.0182       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.192       |
|    explained_variance   | 0.38         |
|    learning_rate        | 0.0003       |
|    loss                 | 75.3         |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.00408     |
|    value_loss           | 175          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 199          |
|    ep_rew_mean          | 154          |
| time/                   |              |
|    fps                  | 1356         |
|    iterations           | 23           |
|    time_elapsed         | 34           |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 0.0016964434 |
|    clip_fraction        | 0.0164       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.199       |
|    explained_variance   | 0.816        |
|    learning_rate        | 0.0003       |
|    loss                 | 9.81         |
|    n_updates            | 220          |
|    policy_gradient_loss | -0.00192     |
|    value_loss           | 23           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 200          |
|    ep_rew_mean          | 157          |
| time/                   |              |
|    fps                  | 1358         |
|    iterations           | 24           |
|    time_elapsed         | 36           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0012735607 |
|    clip_fraction        | 0.0235       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.176       |
|    explained_variance   | 0.891        |
|    learning_rate        | 0.0003       |
|    loss                 | 8.28         |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.00289     |
|    value_loss           | 19.5         |
------------------------------------------
Eval num_timesteps=50000, episode_reward=33.00 +/- 3.69
Episode length: 83.00 +/- 3.69
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 83           |
|    mean_reward          | 33           |
| time/                   |              |
|    total_timesteps      | 50000        |
| train/                  |              |
|    approx_kl            | 0.0010103404 |
|    clip_fraction        | 0.0116       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.147       |
|    explained_variance   | 0.758        |
|    learning_rate        | 0.0003       |
|    loss                 | 12.7         |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.00236     |
|    value_loss           | 62.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 199      |
|    ep_rew_mean     | 159      |
| time/              |          |
|    fps             | 1357     |
|    iterations      | 25       |
|    time_elapsed    | 37       |
|    total_timesteps | 51200    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 200          |
|    ep_rew_mean          | 163          |
| time/                   |              |
|    fps                  | 1361         |
|    iterations           | 26           |
|    time_elapsed         | 39           |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0017498918 |
|    clip_fraction        | 0.0192       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.163       |
|    explained_variance   | 0.543        |
|    learning_rate        | 0.0003       |
|    loss                 | 202          |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.00459     |
|    value_loss           | 167          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 201          |
|    ep_rew_mean          | 168          |
| time/                   |              |
|    fps                  | 1364         |
|    iterations           | 27           |
|    time_elapsed         | 40           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 0.0006118682 |
|    clip_fraction        | 0.00635      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.134       |
|    explained_variance   | 0.617        |
|    learning_rate        | 0.0003       |
|    loss                 | 21.4         |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.00173     |
|    value_loss           | 129          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 202          |
|    ep_rew_mean          | 171          |
| time/                   |              |
|    fps                  | 1362         |
|    iterations           | 28           |
|    time_elapsed         | 42           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0019811222 |
|    clip_fraction        | 0.0143       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.144       |
|    explained_variance   | 0.907        |
|    learning_rate        | 0.0003       |
|    loss                 | 5.59         |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.00176     |
|    value_loss           | 17           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 207          |
|    ep_rew_mean          | 179          |
| time/                   |              |
|    fps                  | 1365         |
|    iterations           | 29           |
|    time_elapsed         | 43           |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 0.0010365522 |
|    clip_fraction        | 0.0157       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.141       |
|    explained_variance   | 0.936        |
|    learning_rate        | 0.0003       |
|    loss                 | 4.88         |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.00229     |
|    value_loss           | 16.9         |
------------------------------------------
Eval num_timesteps=60000, episode_reward=95.77 +/- 1.63
Episode length: 150.40 +/- 2.87
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 150           |
|    mean_reward          | 95.8          |
| time/                   |               |
|    total_timesteps      | 60000         |
| train/                  |               |
|    approx_kl            | 0.00093059265 |
|    clip_fraction        | 0.0189        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.122        |
|    explained_variance   | 0.951         |
|    learning_rate        | 0.0003        |
|    loss                 | 5.16          |
|    n_updates            | 290           |
|    policy_gradient_loss | -0.00286      |
|    value_loss           | 15.2          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 207      |
|    ep_rew_mean     | 181      |
| time/              |          |
|    fps             | 1352     |
|    iterations      | 30       |
|    time_elapsed    | 45       |
|    total_timesteps | 61440    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 209        |
|    ep_rew_mean          | 185        |
| time/                   |            |
|    fps                  | 1354       |
|    iterations           | 31         |
|    time_elapsed         | 46         |
|    total_timesteps      | 63488      |
| train/                  |            |
|    approx_kl            | 0.01402314 |
|    clip_fraction        | 0.0445     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.177     |
|    explained_variance   | 0.808      |
|    learning_rate        | 0.0003     |
|    loss                 | 30.4       |
|    n_updates            | 300        |
|    policy_gradient_loss | -0.0094    |
|    value_loss           | 69.9       |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 210          |
|    ep_rew_mean          | 188          |
| time/                   |              |
|    fps                  | 1354         |
|    iterations           | 32           |
|    time_elapsed         | 48           |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0013856143 |
|    clip_fraction        | 0.0164       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.138       |
|    explained_variance   | 0.781        |
|    learning_rate        | 0.0003       |
|    loss                 | 51.5         |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.00179     |
|    value_loss           | 93.3         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 210         |
|    ep_rew_mean          | 189         |
| time/                   |             |
|    fps                  | 1356        |
|    iterations           | 33          |
|    time_elapsed         | 49          |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.003149664 |
|    clip_fraction        | 0.0214      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.12       |
|    explained_variance   | 0.964       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.05        |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.00233    |
|    value_loss           | 12.1        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 211          |
|    ep_rew_mean          | 191          |
| time/                   |              |
|    fps                  | 1359         |
|    iterations           | 34           |
|    time_elapsed         | 51           |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 0.0014550213 |
|    clip_fraction        | 0.0101       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.146       |
|    explained_variance   | 0.97         |
|    learning_rate        | 0.0003       |
|    loss                 | 2.89         |
|    n_updates            | 330          |
|    policy_gradient_loss | -0.000842    |
|    value_loss           | 11           |
------------------------------------------
Eval num_timesteps=70000, episode_reward=210.73 +/- 5.33
Episode length: 222.60 +/- 3.83
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 223          |
|    mean_reward          | 211          |
| time/                   |              |
|    total_timesteps      | 70000        |
| train/                  |              |
|    approx_kl            | 0.0016108946 |
|    clip_fraction        | 0.0179       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.133       |
|    explained_variance   | 0.973        |
|    learning_rate        | 0.0003       |
|    loss                 | 2.27         |
|    n_updates            | 340          |
|    policy_gradient_loss | -0.00276     |
|    value_loss           | 11.1         |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 213      |
|    ep_rew_mean     | 194      |
| time/              |          |
|    fps             | 1320     |
|    iterations      | 35       |
|    time_elapsed    | 54       |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 214         |
|    ep_rew_mean          | 196         |
| time/                   |             |
|    fps                  | 1323        |
|    iterations           | 36          |
|    time_elapsed         | 55          |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.000987082 |
|    clip_fraction        | 0.0182      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0955     |
|    explained_variance   | 0.795       |
|    learning_rate        | 0.0003      |
|    loss                 | 29.1        |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00416    |
|    value_loss           | 95.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 216         |
|    ep_rew_mean          | 198         |
| time/                   |             |
|    fps                  | 1326        |
|    iterations           | 37          |
|    time_elapsed         | 57          |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.013886499 |
|    clip_fraction        | 0.0311      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.181      |
|    explained_variance   | 0.958       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.79        |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.00307    |
|    value_loss           | 9.71        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 216          |
|    ep_rew_mean          | 198          |
| time/                   |              |
|    fps                  | 1329         |
|    iterations           | 38           |
|    time_elapsed         | 58           |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 0.0008130997 |
|    clip_fraction        | 0.0126       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.123       |
|    explained_variance   | 0.866        |
|    learning_rate        | 0.0003       |
|    loss                 | 4.69         |
|    n_updates            | 370          |
|    policy_gradient_loss | -0.00136     |
|    value_loss           | 55.5         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 216           |
|    ep_rew_mean          | 199           |
| time/                   |               |
|    fps                  | 1330          |
|    iterations           | 39            |
|    time_elapsed         | 60            |
|    total_timesteps      | 79872         |
| train/                  |               |
|    approx_kl            | 0.00067073386 |
|    clip_fraction        | 0.0104        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.125        |
|    explained_variance   | 0.977         |
|    learning_rate        | 0.0003        |
|    loss                 | 3.46          |
|    n_updates            | 380           |
|    policy_gradient_loss | -0.000916     |
|    value_loss           | 6.83          |
-------------------------------------------
Eval num_timesteps=80000, episode_reward=213.63 +/- 2.09
Episode length: 224.60 +/- 1.96
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 225          |
|    mean_reward          | 214          |
| time/                   |              |
|    total_timesteps      | 80000        |
| train/                  |              |
|    approx_kl            | 0.0016911104 |
|    clip_fraction        | 0.0212       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.146       |
|    explained_variance   | 0.98         |
|    learning_rate        | 0.0003       |
|    loss                 | 3.47         |
|    n_updates            | 390          |
|    policy_gradient_loss | -0.00266     |
|    value_loss           | 6.37         |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 216      |
|    ep_rew_mean     | 199      |
| time/              |          |
|    fps             | 1315     |
|    iterations      | 40       |
|    time_elapsed    | 62       |
|    total_timesteps | 81920    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 217          |
|    ep_rew_mean          | 202          |
| time/                   |              |
|    fps                  | 1317         |
|    iterations           | 41           |
|    time_elapsed         | 63           |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 0.0017682136 |
|    clip_fraction        | 0.0107       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.143       |
|    explained_variance   | 0.986        |
|    learning_rate        | 0.0003       |
|    loss                 | 2.14         |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00088     |
|    value_loss           | 5.42         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 218         |
|    ep_rew_mean          | 204         |
| time/                   |             |
|    fps                  | 1319        |
|    iterations           | 42          |
|    time_elapsed         | 65          |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.000645507 |
|    clip_fraction        | 0.013       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.121      |
|    explained_variance   | 0.988       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.67        |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.000876   |
|    value_loss           | 5.54        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 204          |
| time/                   |              |
|    fps                  | 1321         |
|    iterations           | 43           |
|    time_elapsed         | 66           |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 0.0009856733 |
|    clip_fraction        | 0.00918      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.117       |
|    explained_variance   | 0.991        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.96         |
|    n_updates            | 420          |
|    policy_gradient_loss | -3.84e-05    |
|    value_loss           | 4.02         |
------------------------------------------
Eval num_timesteps=90000, episode_reward=210.15 +/- 3.78
Episode length: 222.60 +/- 3.26
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 223          |
|    mean_reward          | 210          |
| time/                   |              |
|    total_timesteps      | 90000        |
| train/                  |              |
|    approx_kl            | 0.0022378392 |
|    clip_fraction        | 0.0299       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.115       |
|    explained_variance   | 0.993        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.36         |
|    n_updates            | 430          |
|    policy_gradient_loss | -0.00138     |
|    value_loss           | 3.31         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 219      |
|    ep_rew_mean     | 204      |
| time/              |          |
|    fps             | 1283     |
|    iterations      | 44       |
|    time_elapsed    | 70       |
|    total_timesteps | 90112    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 204          |
| time/                   |              |
|    fps                  | 1287         |
|    iterations           | 45           |
|    time_elapsed         | 71           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0020876948 |
|    clip_fraction        | 0.038        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0975      |
|    explained_variance   | 0.994        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.39         |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00294     |
|    value_loss           | 2.99         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 207          |
| time/                   |              |
|    fps                  | 1290         |
|    iterations           | 46           |
|    time_elapsed         | 72           |
|    total_timesteps      | 94208        |
| train/                  |              |
|    approx_kl            | 0.0019301415 |
|    clip_fraction        | 0.0186       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.134       |
|    explained_variance   | 0.991        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.69         |
|    n_updates            | 450          |
|    policy_gradient_loss | -0.00284     |
|    value_loss           | 4.02         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 208         |
| time/                   |             |
|    fps                  | 1293        |
|    iterations           | 47          |
|    time_elapsed         | 74          |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.003604687 |
|    clip_fraction        | 0.0359      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.122      |
|    explained_variance   | 0.995       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.13        |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00145    |
|    value_loss           | 2.98        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1296         |
|    iterations           | 48           |
|    time_elapsed         | 75           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 0.0035219952 |
|    clip_fraction        | 0.0354       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.127       |
|    explained_variance   | 0.994        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.849        |
|    n_updates            | 470          |
|    policy_gradient_loss | -0.00572     |
|    value_loss           | 2.72         |
------------------------------------------
Eval num_timesteps=100000, episode_reward=206.39 +/- 2.55
Episode length: 218.20 +/- 2.32
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 218           |
|    mean_reward          | 206           |
| time/                   |               |
|    total_timesteps      | 100000        |
| train/                  |               |
|    approx_kl            | 0.00083732605 |
|    clip_fraction        | 0.0206        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.138        |
|    explained_variance   | 0.995         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.796         |
|    n_updates            | 480           |
|    policy_gradient_loss | -0.000595     |
|    value_loss           | 2.35          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 208      |
| time/              |          |
|    fps             | 1293     |
|    iterations      | 49       |
|    time_elapsed    | 77       |
|    total_timesteps | 100352   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1297         |
|    iterations           | 50           |
|    time_elapsed         | 78           |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 0.0022753319 |
|    clip_fraction        | 0.0235       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.108       |
|    explained_variance   | 0.996        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.46         |
|    n_updates            | 490          |
|    policy_gradient_loss | -0.00264     |
|    value_loss           | 1.82         |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 221        |
|    ep_rew_mean          | 209        |
| time/                   |            |
|    fps                  | 1299       |
|    iterations           | 51         |
|    time_elapsed         | 80         |
|    total_timesteps      | 104448     |
| train/                  |            |
|    approx_kl            | 0.00366264 |
|    clip_fraction        | 0.0157     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.14      |
|    explained_variance   | 0.996      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.846      |
|    n_updates            | 500        |
|    policy_gradient_loss | 0.000319   |
|    value_loss           | 1.87       |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1302         |
|    iterations           | 52           |
|    time_elapsed         | 81           |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 0.0018798717 |
|    clip_fraction        | 0.0211       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.123       |
|    explained_variance   | 0.997        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.779        |
|    n_updates            | 510          |
|    policy_gradient_loss | -0.00118     |
|    value_loss           | 1.63         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 220           |
|    ep_rew_mean          | 207           |
| time/                   |               |
|    fps                  | 1305          |
|    iterations           | 53            |
|    time_elapsed         | 83            |
|    total_timesteps      | 108544        |
| train/                  |               |
|    approx_kl            | 0.00091861404 |
|    clip_fraction        | 0.0133        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.105        |
|    explained_variance   | 0.997         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.54          |
|    n_updates            | 520           |
|    policy_gradient_loss | -0.000114     |
|    value_loss           | 1.64          |
-------------------------------------------
Eval num_timesteps=110000, episode_reward=210.03 +/- 4.88
Episode length: 221.20 +/- 4.12
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 221          |
|    mean_reward          | 210          |
| time/                   |              |
|    total_timesteps      | 110000       |
| train/                  |              |
|    approx_kl            | 0.0020095827 |
|    clip_fraction        | 0.0196       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.133       |
|    explained_variance   | 0.904        |
|    learning_rate        | 0.0003       |
|    loss                 | 2.49         |
|    n_updates            | 530          |
|    policy_gradient_loss | -0.00277     |
|    value_loss           | 50.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 220      |
|    ep_rew_mean     | 207      |
| time/              |          |
|    fps             | 1302     |
|    iterations      | 54       |
|    time_elapsed    | 84       |
|    total_timesteps | 110592   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 220          |
|    ep_rew_mean          | 207          |
| time/                   |              |
|    fps                  | 1305         |
|    iterations           | 55           |
|    time_elapsed         | 86           |
|    total_timesteps      | 112640       |
| train/                  |              |
|    approx_kl            | 0.0021933562 |
|    clip_fraction        | 0.0325       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.123       |
|    explained_variance   | 0.991        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.399        |
|    n_updates            | 540          |
|    policy_gradient_loss | -0.00149     |
|    value_loss           | 1.39         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 220         |
|    ep_rew_mean          | 207         |
| time/                   |             |
|    fps                  | 1308        |
|    iterations           | 56          |
|    time_elapsed         | 87          |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.005452264 |
|    clip_fraction        | 0.0309      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.12       |
|    explained_variance   | 0.997       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.534       |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.00014    |
|    value_loss           | 1.18        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 220         |
|    ep_rew_mean          | 207         |
| time/                   |             |
|    fps                  | 1310        |
|    iterations           | 57          |
|    time_elapsed         | 89          |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.002150359 |
|    clip_fraction        | 0.0293      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.111      |
|    explained_variance   | 0.997       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.429       |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.00078    |
|    value_loss           | 1.22        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 220          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1312         |
|    iterations           | 58           |
|    time_elapsed         | 90           |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 0.0031122873 |
|    clip_fraction        | 0.0244       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.143       |
|    explained_variance   | 0.997        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.917        |
|    n_updates            | 570          |
|    policy_gradient_loss | -0.00079     |
|    value_loss           | 1.32         |
------------------------------------------
Eval num_timesteps=120000, episode_reward=205.56 +/- 2.70
Episode length: 218.60 +/- 2.87
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 219          |
|    mean_reward          | 206          |
| time/                   |              |
|    total_timesteps      | 120000       |
| train/                  |              |
|    approx_kl            | 0.0014699372 |
|    clip_fraction        | 0.0179       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.12        |
|    explained_variance   | 0.998        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.447        |
|    n_updates            | 580          |
|    policy_gradient_loss | 0.00169      |
|    value_loss           | 1.18         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 220      |
|    ep_rew_mean     | 207      |
| time/              |          |
|    fps             | 1310     |
|    iterations      | 59       |
|    time_elapsed    | 92       |
|    total_timesteps | 120832   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 220          |
|    ep_rew_mean          | 207          |
| time/                   |              |
|    fps                  | 1312         |
|    iterations           | 60           |
|    time_elapsed         | 93           |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 0.0006523739 |
|    clip_fraction        | 0.015        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.128       |
|    explained_variance   | 0.998        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.702        |
|    n_updates            | 590          |
|    policy_gradient_loss | 5.42e-05     |
|    value_loss           | 1.08         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 220          |
|    ep_rew_mean          | 207          |
| time/                   |              |
|    fps                  | 1314         |
|    iterations           | 61           |
|    time_elapsed         | 95           |
|    total_timesteps      | 124928       |
| train/                  |              |
|    approx_kl            | 0.0007892826 |
|    clip_fraction        | 0.0183       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.117       |
|    explained_variance   | 0.998        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.495        |
|    n_updates            | 600          |
|    policy_gradient_loss | -0.000481    |
|    value_loss           | 1.08         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 220         |
|    ep_rew_mean          | 208         |
| time/                   |             |
|    fps                  | 1316        |
|    iterations           | 62          |
|    time_elapsed         | 96          |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.002546696 |
|    clip_fraction        | 0.03        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.121      |
|    explained_variance   | 0.998       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.542       |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.00216    |
|    value_loss           | 0.797       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 220          |
|    ep_rew_mean          | 207          |
| time/                   |              |
|    fps                  | 1318         |
|    iterations           | 63           |
|    time_elapsed         | 97           |
|    total_timesteps      | 129024       |
| train/                  |              |
|    approx_kl            | 0.0007228711 |
|    clip_fraction        | 0.0269       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.117       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.458        |
|    n_updates            | 620          |
|    policy_gradient_loss | 0.00283      |
|    value_loss           | 0.628        |
------------------------------------------
Eval num_timesteps=130000, episode_reward=211.88 +/- 2.77
Episode length: 223.40 +/- 1.96
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 223          |
|    mean_reward          | 212          |
| time/                   |              |
|    total_timesteps      | 130000       |
| train/                  |              |
|    approx_kl            | 0.0031962954 |
|    clip_fraction        | 0.0257       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.148       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.233        |
|    n_updates            | 630          |
|    policy_gradient_loss | -0.00546     |
|    value_loss           | 0.719        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 1315     |
|    iterations      | 64       |
|    time_elapsed    | 99       |
|    total_timesteps | 131072   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1317         |
|    iterations           | 65           |
|    time_elapsed         | 101          |
|    total_timesteps      | 133120       |
| train/                  |              |
|    approx_kl            | 0.0005023086 |
|    clip_fraction        | 0.0142       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.126       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.159        |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.000385    |
|    value_loss           | 0.601        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1319         |
|    iterations           | 66           |
|    time_elapsed         | 102          |
|    total_timesteps      | 135168       |
| train/                  |              |
|    approx_kl            | 0.0006876139 |
|    clip_fraction        | 0.0284       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.135       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.244        |
|    n_updates            | 650          |
|    policy_gradient_loss | -0.000246    |
|    value_loss           | 0.694        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1321         |
|    iterations           | 67           |
|    time_elapsed         | 103          |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 0.0015643863 |
|    clip_fraction        | 0.0163       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.124       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.252        |
|    n_updates            | 660          |
|    policy_gradient_loss | -0.000709    |
|    value_loss           | 0.628        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 209         |
| time/                   |             |
|    fps                  | 1323        |
|    iterations           | 68          |
|    time_elapsed         | 105         |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.003956832 |
|    clip_fraction        | 0.0117      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.122      |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.142       |
|    n_updates            | 670         |
|    policy_gradient_loss | 0.000446    |
|    value_loss           | 0.46        |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=209.80 +/- 4.29
Episode length: 223.00 +/- 3.35
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 223          |
|    mean_reward          | 210          |
| time/                   |              |
|    total_timesteps      | 140000       |
| train/                  |              |
|    approx_kl            | 0.0036827477 |
|    clip_fraction        | 0.0248       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.116       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.376        |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.00436     |
|    value_loss           | 0.577        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 1321     |
|    iterations      | 69       |
|    time_elapsed    | 106      |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 209         |
| time/                   |             |
|    fps                  | 1323        |
|    iterations           | 70          |
|    time_elapsed         | 108         |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.003195781 |
|    clip_fraction        | 0.0141      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.119      |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.725       |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.00113    |
|    value_loss           | 0.512       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1324         |
|    iterations           | 71           |
|    time_elapsed         | 109          |
|    total_timesteps      | 145408       |
| train/                  |              |
|    approx_kl            | 0.0023075826 |
|    clip_fraction        | 0.0284       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.126       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.117        |
|    n_updates            | 700          |
|    policy_gradient_loss | -0.00335     |
|    value_loss           | 0.656        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 1326         |
|    iterations           | 72           |
|    time_elapsed         | 111          |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 0.0032152382 |
|    clip_fraction        | 0.0258       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0982      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.123        |
|    n_updates            | 710          |
|    policy_gradient_loss | -0.00141     |
|    value_loss           | 0.623        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 1328         |
|    iterations           | 73           |
|    time_elapsed         | 112          |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 0.0047994666 |
|    clip_fraction        | 0.0226       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.108       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.226        |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.00145     |
|    value_loss           | 0.574        |
------------------------------------------
Eval num_timesteps=150000, episode_reward=211.56 +/- 3.63
Episode length: 221.80 +/- 3.76
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 222          |
|    mean_reward          | 212          |
| time/                   |              |
|    total_timesteps      | 150000       |
| train/                  |              |
|    approx_kl            | 0.0049866047 |
|    clip_fraction        | 0.0158       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.119       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.368        |
|    n_updates            | 730          |
|    policy_gradient_loss | -0.000424    |
|    value_loss           | 0.529        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 210      |
| time/              |          |
|    fps             | 1326     |
|    iterations      | 74       |
|    time_elapsed    | 114      |
|    total_timesteps | 151552   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 1327         |
|    iterations           | 75           |
|    time_elapsed         | 115          |
|    total_timesteps      | 153600       |
| train/                  |              |
|    approx_kl            | 0.0015891606 |
|    clip_fraction        | 0.0211       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.112       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.139        |
|    n_updates            | 740          |
|    policy_gradient_loss | 0.000718     |
|    value_loss           | 0.517        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 210         |
| time/                   |             |
|    fps                  | 1329        |
|    iterations           | 76          |
|    time_elapsed         | 117         |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.004566543 |
|    clip_fraction        | 0.0367      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.107      |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.145       |
|    n_updates            | 750         |
|    policy_gradient_loss | 0.0015      |
|    value_loss           | 0.551       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 1330         |
|    iterations           | 77           |
|    time_elapsed         | 118          |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 0.0004111823 |
|    clip_fraction        | 0.0162       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.121       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.139        |
|    n_updates            | 760          |
|    policy_gradient_loss | 0.00154      |
|    value_loss           | 0.44         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 1330         |
|    iterations           | 78           |
|    time_elapsed         | 120          |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 0.0026651544 |
|    clip_fraction        | 0.0258       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.113       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.2          |
|    n_updates            | 770          |
|    policy_gradient_loss | -0.000427    |
|    value_loss           | 0.643        |
------------------------------------------
Eval num_timesteps=160000, episode_reward=209.44 +/- 4.90
Episode length: 220.80 +/- 4.26
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 221         |
|    mean_reward          | 209         |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.002821958 |
|    clip_fraction        | 0.0268      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.105      |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.184       |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.000498   |
|    value_loss           | 0.751       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 210      |
| time/              |          |
|    fps             | 1326     |
|    iterations      | 79       |
|    time_elapsed    | 122      |
|    total_timesteps | 161792   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 1327         |
|    iterations           | 80           |
|    time_elapsed         | 123          |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 0.0017024449 |
|    clip_fraction        | 0.0134       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.105       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.264        |
|    n_updates            | 790          |
|    policy_gradient_loss | 0.000971     |
|    value_loss           | 0.519        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 1328         |
|    iterations           | 81           |
|    time_elapsed         | 124          |
|    total_timesteps      | 165888       |
| train/                  |              |
|    approx_kl            | 0.0017899775 |
|    clip_fraction        | 0.0147       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.108       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.313        |
|    n_updates            | 800          |
|    policy_gradient_loss | 0.00176      |
|    value_loss           | 0.503        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 1330         |
|    iterations           | 82           |
|    time_elapsed         | 126          |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 0.0010290922 |
|    clip_fraction        | 0.0085       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.111       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.248        |
|    n_updates            | 810          |
|    policy_gradient_loss | -0.000875    |
|    value_loss           | 0.77         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 210           |
| time/                   |               |
|    fps                  | 1331          |
|    iterations           | 83            |
|    time_elapsed         | 127           |
|    total_timesteps      | 169984        |
| train/                  |               |
|    approx_kl            | 0.00092279236 |
|    clip_fraction        | 0.0187        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.118        |
|    explained_variance   | 0.999         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.191         |
|    n_updates            | 820           |
|    policy_gradient_loss | 0.000263      |
|    value_loss           | 0.542         |
-------------------------------------------
Eval num_timesteps=170000, episode_reward=210.68 +/- 2.31
Episode length: 222.60 +/- 2.06
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 223          |
|    mean_reward          | 211          |
| time/                   |              |
|    total_timesteps      | 170000       |
| train/                  |              |
|    approx_kl            | 0.0022196968 |
|    clip_fraction        | 0.0202       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.108       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0772       |
|    n_updates            | 830          |
|    policy_gradient_loss | -0.0026      |
|    value_loss           | 0.397        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 210      |
| time/              |          |
|    fps             | 1329     |
|    iterations      | 84       |
|    time_elapsed    | 129      |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 209         |
| time/                   |             |
|    fps                  | 1330        |
|    iterations           | 85          |
|    time_elapsed         | 130         |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.006294899 |
|    clip_fraction        | 0.0474      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.121      |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0785      |
|    n_updates            | 840         |
|    policy_gradient_loss | 0.00227     |
|    value_loss           | 0.422       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1331         |
|    iterations           | 86           |
|    time_elapsed         | 132          |
|    total_timesteps      | 176128       |
| train/                  |              |
|    approx_kl            | 0.0013001494 |
|    clip_fraction        | 0.0233       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.121       |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0709       |
|    n_updates            | 850          |
|    policy_gradient_loss | 0.000328     |
|    value_loss           | 0.37         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1333         |
|    iterations           | 87           |
|    time_elapsed         | 133          |
|    total_timesteps      | 178176       |
| train/                  |              |
|    approx_kl            | 0.0029759335 |
|    clip_fraction        | 0.0314       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.119       |
|    explained_variance   | 0.931        |
|    learning_rate        | 0.0003       |
|    loss                 | 25.5         |
|    n_updates            | 860          |
|    policy_gradient_loss | -0.00619     |
|    value_loss           | 32.7         |
------------------------------------------
Eval num_timesteps=180000, episode_reward=205.65 +/- 2.32
Episode length: 218.20 +/- 2.04
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 218          |
|    mean_reward          | 206          |
| time/                   |              |
|    total_timesteps      | 180000       |
| train/                  |              |
|    approx_kl            | 0.0026873718 |
|    clip_fraction        | 0.0252       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.107       |
|    explained_variance   | 0.995        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.22         |
|    n_updates            | 870          |
|    policy_gradient_loss | 0.000861     |
|    value_loss           | 0.645        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 1328     |
|    iterations      | 88       |
|    time_elapsed    | 135      |
|    total_timesteps | 180224   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1330         |
|    iterations           | 89           |
|    time_elapsed         | 137          |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 0.0015108307 |
|    clip_fraction        | 0.0123       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.101       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0811       |
|    n_updates            | 880          |
|    policy_gradient_loss | 0.00174      |
|    value_loss           | 0.431        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 220          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1331         |
|    iterations           | 90           |
|    time_elapsed         | 138          |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 0.0023619158 |
|    clip_fraction        | 0.0254       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.125       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.235        |
|    n_updates            | 890          |
|    policy_gradient_loss | -0.00116     |
|    value_loss           | 0.456        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1332         |
|    iterations           | 91           |
|    time_elapsed         | 139          |
|    total_timesteps      | 186368       |
| train/                  |              |
|    approx_kl            | 0.0022341304 |
|    clip_fraction        | 0.0261       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.105       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.122        |
|    n_updates            | 900          |
|    policy_gradient_loss | 0.000643     |
|    value_loss           | 0.453        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1333         |
|    iterations           | 92           |
|    time_elapsed         | 141          |
|    total_timesteps      | 188416       |
| train/                  |              |
|    approx_kl            | 0.0014476788 |
|    clip_fraction        | 0.0135       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0958      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.205        |
|    n_updates            | 910          |
|    policy_gradient_loss | -0.00155     |
|    value_loss           | 0.392        |
------------------------------------------
Eval num_timesteps=190000, episode_reward=208.66 +/- 4.53
Episode length: 220.40 +/- 3.07
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 220          |
|    mean_reward          | 209          |
| time/                   |              |
|    total_timesteps      | 190000       |
| train/                  |              |
|    approx_kl            | 0.0005234811 |
|    clip_fraction        | 0.0194       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.104       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.354        |
|    n_updates            | 920          |
|    policy_gradient_loss | 0.00138      |
|    value_loss           | 0.367        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 208      |
| time/              |          |
|    fps             | 1331     |
|    iterations      | 93       |
|    time_elapsed    | 143      |
|    total_timesteps | 190464   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1332         |
|    iterations           | 94           |
|    time_elapsed         | 144          |
|    total_timesteps      | 192512       |
| train/                  |              |
|    approx_kl            | 0.0026620915 |
|    clip_fraction        | 0.0431       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0985      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.361        |
|    n_updates            | 930          |
|    policy_gradient_loss | 0.00213      |
|    value_loss           | 0.582        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1333         |
|    iterations           | 95           |
|    time_elapsed         | 145          |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 0.0017437659 |
|    clip_fraction        | 0.018        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0886      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.228        |
|    n_updates            | 940          |
|    policy_gradient_loss | -0.000631    |
|    value_loss           | 0.466        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1334         |
|    iterations           | 96           |
|    time_elapsed         | 147          |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0029593832 |
|    clip_fraction        | 0.0307       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0882      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.617        |
|    n_updates            | 950          |
|    policy_gradient_loss | 0.00181      |
|    value_loss           | 0.385        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 210         |
| time/                   |             |
|    fps                  | 1335        |
|    iterations           | 97          |
|    time_elapsed         | 148         |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.003570761 |
|    clip_fraction        | 0.0163      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0688     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0956      |
|    n_updates            | 960         |
|    policy_gradient_loss | 0.000502    |
|    value_loss           | 0.425       |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=211.20 +/- 3.66
Episode length: 222.40 +/- 2.87
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 222         |
|    mean_reward          | 211         |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.004898686 |
|    clip_fraction        | 0.0212      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0812     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.162       |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.00245    |
|    value_loss           | 0.345       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 1333     |
|    iterations      | 98       |
|    time_elapsed    | 150      |
|    total_timesteps | 200704   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1334         |
|    iterations           | 99           |
|    time_elapsed         | 151          |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 0.0018100449 |
|    clip_fraction        | 0.031        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0925      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.125        |
|    n_updates            | 980          |
|    policy_gradient_loss | 7.45e-05     |
|    value_loss           | 0.324        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1335         |
|    iterations           | 100          |
|    time_elapsed         | 153          |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 0.0009957508 |
|    clip_fraction        | 0.0164       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0966      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0866       |
|    n_updates            | 990          |
|    policy_gradient_loss | -0.000153    |
|    value_loss           | 0.315        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1336         |
|    iterations           | 101          |
|    time_elapsed         | 154          |
|    total_timesteps      | 206848       |
| train/                  |              |
|    approx_kl            | 0.0013841416 |
|    clip_fraction        | 0.0211       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0852      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0592       |
|    n_updates            | 1000         |
|    policy_gradient_loss | -0.0027      |
|    value_loss           | 0.399        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1337         |
|    iterations           | 102          |
|    time_elapsed         | 156          |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 0.0038158544 |
|    clip_fraction        | 0.0358       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0991      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0886       |
|    n_updates            | 1010         |
|    policy_gradient_loss | 0.00394      |
|    value_loss           | 0.368        |
------------------------------------------
Eval num_timesteps=210000, episode_reward=206.32 +/- 2.16
Episode length: 219.20 +/- 2.71
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 219          |
|    mean_reward          | 206          |
| time/                   |              |
|    total_timesteps      | 210000       |
| train/                  |              |
|    approx_kl            | 0.0011090415 |
|    clip_fraction        | 0.0224       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0963      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.534        |
|    n_updates            | 1020         |
|    policy_gradient_loss | 0.000767     |
|    value_loss           | 0.398        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 1330     |
|    iterations      | 103      |
|    time_elapsed    | 158      |
|    total_timesteps | 210944   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1331         |
|    iterations           | 104          |
|    time_elapsed         | 159          |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 0.0015584622 |
|    clip_fraction        | 0.0192       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0897      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.101        |
|    n_updates            | 1030         |
|    policy_gradient_loss | -0.00105     |
|    value_loss           | 0.472        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1332         |
|    iterations           | 105          |
|    time_elapsed         | 161          |
|    total_timesteps      | 215040       |
| train/                  |              |
|    approx_kl            | 0.0018936179 |
|    clip_fraction        | 0.027        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0936      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.142        |
|    n_updates            | 1040         |
|    policy_gradient_loss | -0.00217     |
|    value_loss           | 0.461        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 209         |
| time/                   |             |
|    fps                  | 1332        |
|    iterations           | 106         |
|    time_elapsed         | 162         |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.002306046 |
|    clip_fraction        | 0.0261      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.091      |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.204       |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.00282    |
|    value_loss           | 0.526       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 209         |
| time/                   |             |
|    fps                  | 1333        |
|    iterations           | 107         |
|    time_elapsed         | 164         |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.002328407 |
|    clip_fraction        | 0.0223      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0905     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.225       |
|    n_updates            | 1060        |
|    policy_gradient_loss | 0.000896    |
|    value_loss           | 0.254       |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=208.54 +/- 3.11
Episode length: 220.20 +/- 1.83
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 220         |
|    mean_reward          | 209         |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.005139972 |
|    clip_fraction        | 0.0209      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0732     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.217       |
|    n_updates            | 1070        |
|    policy_gradient_loss | 0.000871    |
|    value_loss           | 0.25        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 1332     |
|    iterations      | 108      |
|    time_elapsed    | 166      |
|    total_timesteps | 221184   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1333         |
|    iterations           | 109          |
|    time_elapsed         | 167          |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 0.0027922438 |
|    clip_fraction        | 0.0219       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0807      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.196        |
|    n_updates            | 1080         |
|    policy_gradient_loss | -0.00159     |
|    value_loss           | 0.252        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1334         |
|    iterations           | 110          |
|    time_elapsed         | 168          |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 0.0020774282 |
|    clip_fraction        | 0.019        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0626      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.471        |
|    n_updates            | 1090         |
|    policy_gradient_loss | -0.000116    |
|    value_loss           | 0.287        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 209         |
| time/                   |             |
|    fps                  | 1335        |
|    iterations           | 111         |
|    time_elapsed         | 170         |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.002297186 |
|    clip_fraction        | 0.0167      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0671     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0857      |
|    n_updates            | 1100        |
|    policy_gradient_loss | -1.97e-05   |
|    value_loss           | 0.31        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1336         |
|    iterations           | 112          |
|    time_elapsed         | 171          |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 0.0013235812 |
|    clip_fraction        | 0.0232       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0787      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.152        |
|    n_updates            | 1110         |
|    policy_gradient_loss | 0.00255      |
|    value_loss           | 0.358        |
------------------------------------------
Eval num_timesteps=230000, episode_reward=209.46 +/- 4.03
Episode length: 221.80 +/- 3.66
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 222          |
|    mean_reward          | 209          |
| time/                   |              |
|    total_timesteps      | 230000       |
| train/                  |              |
|    approx_kl            | 0.0045726257 |
|    clip_fraction        | 0.0388       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0783      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0464       |
|    n_updates            | 1120         |
|    policy_gradient_loss | 0.0177       |
|    value_loss           | 0.329        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 1334     |
|    iterations      | 113      |
|    time_elapsed    | 173      |
|    total_timesteps | 231424   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1335         |
|    iterations           | 114          |
|    time_elapsed         | 174          |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 0.0043915547 |
|    clip_fraction        | 0.0165       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0766      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0752       |
|    n_updates            | 1130         |
|    policy_gradient_loss | -0.000273    |
|    value_loss           | 0.309        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 1336         |
|    iterations           | 115          |
|    time_elapsed         | 176          |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 0.0002836494 |
|    clip_fraction        | 0.01         |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0692      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.108        |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.00034     |
|    value_loss           | 0.329        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 210         |
| time/                   |             |
|    fps                  | 1336        |
|    iterations           | 116         |
|    time_elapsed         | 177         |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.003115693 |
|    clip_fraction        | 0.0191      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0644     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.167       |
|    n_updates            | 1150        |
|    policy_gradient_loss | 0.00122     |
|    value_loss           | 0.376       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 1337         |
|    iterations           | 117          |
|    time_elapsed         | 179          |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 0.0008692926 |
|    clip_fraction        | 0.00947      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0643      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.181        |
|    n_updates            | 1160         |
|    policy_gradient_loss | -0.00135     |
|    value_loss           | 0.527        |
------------------------------------------
Eval num_timesteps=240000, episode_reward=210.15 +/- 4.57
Episode length: 222.00 +/- 3.03
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 222          |
|    mean_reward          | 210          |
| time/                   |              |
|    total_timesteps      | 240000       |
| train/                  |              |
|    approx_kl            | 0.0033408406 |
|    clip_fraction        | 0.0223       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0693      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.122        |
|    n_updates            | 1170         |
|    policy_gradient_loss | -0.00315     |
|    value_loss           | 0.238        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 210      |
| time/              |          |
|    fps             | 1336     |
|    iterations      | 118      |
|    time_elapsed    | 180      |
|    total_timesteps | 241664   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 1337         |
|    iterations           | 119          |
|    time_elapsed         | 182          |
|    total_timesteps      | 243712       |
| train/                  |              |
|    approx_kl            | 0.0011026477 |
|    clip_fraction        | 0.0139       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0864      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.198        |
|    n_updates            | 1180         |
|    policy_gradient_loss | -7.81e-05    |
|    value_loss           | 0.342        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 1338         |
|    iterations           | 120          |
|    time_elapsed         | 183          |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 0.0025243848 |
|    clip_fraction        | 0.0169       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0842      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.843        |
|    n_updates            | 1190         |
|    policy_gradient_loss | 0.00131      |
|    value_loss           | 0.498        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 210           |
| time/                   |               |
|    fps                  | 1338          |
|    iterations           | 121           |
|    time_elapsed         | 185           |
|    total_timesteps      | 247808        |
| train/                  |               |
|    approx_kl            | 0.00054574467 |
|    clip_fraction        | 0.00942       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0712       |
|    explained_variance   | 0.998         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.122         |
|    n_updates            | 1200          |
|    policy_gradient_loss | -0.000276     |
|    value_loss           | 0.332         |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 210         |
| time/                   |             |
|    fps                  | 1339        |
|    iterations           | 122         |
|    time_elapsed         | 186         |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.001196545 |
|    clip_fraction        | 0.0225      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0701     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.124       |
|    n_updates            | 1210        |
|    policy_gradient_loss | -7.78e-05   |
|    value_loss           | 0.432       |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=212.47 +/- 1.45
Episode length: 225.00 +/- 1.10
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 225         |
|    mean_reward          | 212         |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.002436277 |
|    clip_fraction        | 0.0336      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.077      |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0546      |
|    n_updates            | 1220        |
|    policy_gradient_loss | 0.00258     |
|    value_loss           | 0.295       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 210      |
| time/              |          |
|    fps             | 1337     |
|    iterations      | 123      |
|    time_elapsed    | 188      |
|    total_timesteps | 251904   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 210           |
| time/                   |               |
|    fps                  | 1338          |
|    iterations           | 124           |
|    time_elapsed         | 189           |
|    total_timesteps      | 253952        |
| train/                  |               |
|    approx_kl            | 0.00069613074 |
|    clip_fraction        | 0.0159        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0977       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.411         |
|    n_updates            | 1230          |
|    policy_gradient_loss | 0.000535      |
|    value_loss           | 0.474         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1339         |
|    iterations           | 125          |
|    time_elapsed         | 191          |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 0.0015370636 |
|    clip_fraction        | 0.0202       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0975      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.139        |
|    n_updates            | 1240         |
|    policy_gradient_loss | -0.000975    |
|    value_loss           | 0.3          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1340         |
|    iterations           | 126          |
|    time_elapsed         | 192          |
|    total_timesteps      | 258048       |
| train/                  |              |
|    approx_kl            | 0.0043113884 |
|    clip_fraction        | 0.0344       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0867      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0972       |
|    n_updates            | 1250         |
|    policy_gradient_loss | 0.00102      |
|    value_loss           | 0.354        |
------------------------------------------
Eval num_timesteps=260000, episode_reward=210.67 +/- 2.65
Episode length: 223.00 +/- 3.63
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 223           |
|    mean_reward          | 211           |
| time/                   |               |
|    total_timesteps      | 260000        |
| train/                  |               |
|    approx_kl            | 0.00059725554 |
|    clip_fraction        | 0.0171        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0976       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.495         |
|    n_updates            | 1260          |
|    policy_gradient_loss | -2.33e-05     |
|    value_loss           | 0.265         |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 1338     |
|    iterations      | 127      |
|    time_elapsed    | 194      |
|    total_timesteps | 260096   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 221        |
|    ep_rew_mean          | 209        |
| time/                   |            |
|    fps                  | 1339       |
|    iterations           | 128        |
|    time_elapsed         | 195        |
|    total_timesteps      | 262144     |
| train/                  |            |
|    approx_kl            | 0.00693684 |
|    clip_fraction        | 0.0219     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.086     |
|    explained_variance   | 0.999      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.245      |
|    n_updates            | 1270       |
|    policy_gradient_loss | -0.000386  |
|    value_loss           | 0.374      |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1340         |
|    iterations           | 129          |
|    time_elapsed         | 197          |
|    total_timesteps      | 264192       |
| train/                  |              |
|    approx_kl            | 0.0010898225 |
|    clip_fraction        | 0.0298       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0892      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.149        |
|    n_updates            | 1280         |
|    policy_gradient_loss | 0.00106      |
|    value_loss           | 0.39         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1341         |
|    iterations           | 130          |
|    time_elapsed         | 198          |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 0.0019881255 |
|    clip_fraction        | 0.0206       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0852      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.184        |
|    n_updates            | 1290         |
|    policy_gradient_loss | -0.00203     |
|    value_loss           | 0.467        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1341         |
|    iterations           | 131          |
|    time_elapsed         | 199          |
|    total_timesteps      | 268288       |
| train/                  |              |
|    approx_kl            | 0.0023218514 |
|    clip_fraction        | 0.0214       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0947      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0764       |
|    n_updates            | 1300         |
|    policy_gradient_loss | 0.000807     |
|    value_loss           | 0.251        |
------------------------------------------
Eval num_timesteps=270000, episode_reward=207.24 +/- 3.71
Episode length: 219.60 +/- 3.38
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 220          |
|    mean_reward          | 207          |
| time/                   |              |
|    total_timesteps      | 270000       |
| train/                  |              |
|    approx_kl            | 0.0022981262 |
|    clip_fraction        | 0.0244       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0802      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0914       |
|    n_updates            | 1310         |
|    policy_gradient_loss | 0.00104      |
|    value_loss           | 0.263        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 1340     |
|    iterations      | 132      |
|    time_elapsed    | 201      |
|    total_timesteps | 270336   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1341         |
|    iterations           | 133          |
|    time_elapsed         | 203          |
|    total_timesteps      | 272384       |
| train/                  |              |
|    approx_kl            | 0.0014496542 |
|    clip_fraction        | 0.013        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0824      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.168        |
|    n_updates            | 1320         |
|    policy_gradient_loss | -0.000486    |
|    value_loss           | 0.4          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 209         |
| time/                   |             |
|    fps                  | 1342        |
|    iterations           | 134         |
|    time_elapsed         | 204         |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.002149636 |
|    clip_fraction        | 0.0146      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0835     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0422      |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.000232   |
|    value_loss           | 0.27        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1342         |
|    iterations           | 135          |
|    time_elapsed         | 205          |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 0.0010946363 |
|    clip_fraction        | 0.0191       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0863      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0313       |
|    n_updates            | 1340         |
|    policy_gradient_loss | 0.000708     |
|    value_loss           | 0.27         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 1342         |
|    iterations           | 136          |
|    time_elapsed         | 207          |
|    total_timesteps      | 278528       |
| train/                  |              |
|    approx_kl            | 0.0033056578 |
|    clip_fraction        | 0.0193       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0977      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0483       |
|    n_updates            | 1350         |
|    policy_gradient_loss | -0.000514    |
|    value_loss           | 0.301        |
------------------------------------------
Eval num_timesteps=280000, episode_reward=209.52 +/- 3.27
Episode length: 221.20 +/- 1.94
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 221          |
|    mean_reward          | 210          |
| time/                   |              |
|    total_timesteps      | 280000       |
| train/                  |              |
|    approx_kl            | 0.0017267178 |
|    clip_fraction        | 0.0338       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.106       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.083        |
|    n_updates            | 1360         |
|    policy_gradient_loss | -0.0016      |
|    value_loss           | 0.342        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 208      |
| time/              |          |
|    fps             | 1340     |
|    iterations      | 137      |
|    time_elapsed    | 209      |
|    total_timesteps | 280576   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1341         |
|    iterations           | 138          |
|    time_elapsed         | 210          |
|    total_timesteps      | 282624       |
| train/                  |              |
|    approx_kl            | 0.0026197475 |
|    clip_fraction        | 0.0225       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0925      |
|    explained_variance   | 0.93         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.993        |
|    n_updates            | 1370         |
|    policy_gradient_loss | -0.00348     |
|    value_loss           | 35           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1341         |
|    iterations           | 139          |
|    time_elapsed         | 212          |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 0.0048629236 |
|    clip_fraction        | 0.0303       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0906      |
|    explained_variance   | 0.998        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.114        |
|    n_updates            | 1380         |
|    policy_gradient_loss | 0.000156     |
|    value_loss           | 0.612        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1342         |
|    iterations           | 140          |
|    time_elapsed         | 213          |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 0.0017015837 |
|    clip_fraction        | 0.0277       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0876      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0358       |
|    n_updates            | 1390         |
|    policy_gradient_loss | -0.00153     |
|    value_loss           | 0.357        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1343         |
|    iterations           | 141          |
|    time_elapsed         | 215          |
|    total_timesteps      | 288768       |
| train/                  |              |
|    approx_kl            | 0.0024024367 |
|    clip_fraction        | 0.0151       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0749      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.18         |
|    n_updates            | 1400         |
|    policy_gradient_loss | -0.000405    |
|    value_loss           | 0.277        |
------------------------------------------
Eval num_timesteps=290000, episode_reward=210.90 +/- 2.09
Episode length: 222.60 +/- 1.50
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 223          |
|    mean_reward          | 211          |
| time/                   |              |
|    total_timesteps      | 290000       |
| train/                  |              |
|    approx_kl            | 0.0047446815 |
|    clip_fraction        | 0.0215       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0585      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.112        |
|    n_updates            | 1410         |
|    policy_gradient_loss | -0.00173     |
|    value_loss           | 0.3          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 208      |
| time/              |          |
|    fps             | 1341     |
|    iterations      | 142      |
|    time_elapsed    | 216      |
|    total_timesteps | 290816   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 208           |
| time/                   |               |
|    fps                  | 1342          |
|    iterations           | 143           |
|    time_elapsed         | 218           |
|    total_timesteps      | 292864        |
| train/                  |               |
|    approx_kl            | 0.00080304197 |
|    clip_fraction        | 0.00654       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0522       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.255         |
|    n_updates            | 1420          |
|    policy_gradient_loss | 0.000405      |
|    value_loss           | 0.214         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1342         |
|    iterations           | 144          |
|    time_elapsed         | 219          |
|    total_timesteps      | 294912       |
| train/                  |              |
|    approx_kl            | 0.0014315573 |
|    clip_fraction        | 0.014        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0536      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.173        |
|    n_updates            | 1430         |
|    policy_gradient_loss | 4.49e-05     |
|    value_loss           | 0.196        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1342         |
|    iterations           | 145          |
|    time_elapsed         | 221          |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 0.0010483579 |
|    clip_fraction        | 0.011        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0566      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0317       |
|    n_updates            | 1440         |
|    policy_gradient_loss | 0.00028      |
|    value_loss           | 0.372        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 1343         |
|    iterations           | 146          |
|    time_elapsed         | 222          |
|    total_timesteps      | 299008       |
| train/                  |              |
|    approx_kl            | 0.0028664223 |
|    clip_fraction        | 0.0232       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0565      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.141        |
|    n_updates            | 1450         |
|    policy_gradient_loss | 0.00132      |
|    value_loss           | 0.26         |
------------------------------------------
Eval num_timesteps=300000, episode_reward=209.38 +/- 2.94
Episode length: 220.40 +/- 3.44
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 220          |
|    mean_reward          | 209          |
| time/                   |              |
|    total_timesteps      | 300000       |
| train/                  |              |
|    approx_kl            | 0.0023727717 |
|    clip_fraction        | 0.0215       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0644      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.103        |
|    n_updates            | 1460         |
|    policy_gradient_loss | -0.000902    |
|    value_loss           | 0.193        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 1341     |
|    iterations      | 147      |
|    time_elapsed    | 224      |
|    total_timesteps | 301056   |
---------------------------------

Training complete!
Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-08_23-03-35

