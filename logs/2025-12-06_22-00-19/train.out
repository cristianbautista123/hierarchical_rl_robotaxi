Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-06_22-00-19

Map saved at: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-06_22-00-19/map_visualization.png

Using cpu device
Wrapping the env in a DummyVecEnv.
Logging to /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-06_22-00-19/tensorboard/PPO_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 171      |
|    ep_rew_mean     | 129      |
| time/              |          |
|    fps             | 2671     |
|    iterations      | 1        |
|    time_elapsed    | 0        |
|    total_timesteps | 2048     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 167         |
|    ep_rew_mean          | 125         |
| time/                   |             |
|    fps                  | 1828        |
|    iterations           | 2           |
|    time_elapsed         | 2           |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.007963141 |
|    clip_fraction        | 0.064       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.685      |
|    explained_variance   | 0.00601     |
|    learning_rate        | 0.0003      |
|    loss                 | 30.3        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00592    |
|    value_loss           | 123         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 171         |
|    ep_rew_mean          | 127         |
| time/                   |             |
|    fps                  | 1704        |
|    iterations           | 3           |
|    time_elapsed         | 3           |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.009592845 |
|    clip_fraction        | 0.0625      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.672      |
|    explained_variance   | -0.037      |
|    learning_rate        | 0.0003      |
|    loss                 | 57          |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00281    |
|    value_loss           | 134         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 178          |
|    ep_rew_mean          | 135          |
| time/                   |              |
|    fps                  | 1649         |
|    iterations           | 4            |
|    time_elapsed         | 4            |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0015323025 |
|    clip_fraction        | 0.00913      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.673       |
|    explained_variance   | -0.00393     |
|    learning_rate        | 0.0003       |
|    loss                 | 158          |
|    n_updates            | 30           |
|    policy_gradient_loss | 0.000432     |
|    value_loss           | 126          |
------------------------------------------
Eval num_timesteps=10000, episode_reward=156.10 +/- 50.48
Episode length: 203.60 +/- 37.35
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 204           |
|    mean_reward          | 156           |
| time/                   |               |
|    total_timesteps      | 10000         |
| train/                  |               |
|    approx_kl            | 0.00093230506 |
|    clip_fraction        | 0.0103        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.652        |
|    explained_variance   | -0.00505      |
|    learning_rate        | 0.0003        |
|    loss                 | 64.2          |
|    n_updates            | 40            |
|    policy_gradient_loss | 5.63e-05      |
|    value_loss           | 103           |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 180      |
|    ep_rew_mean     | 138      |
| time/              |          |
|    fps             | 1548     |
|    iterations      | 5        |
|    time_elapsed    | 6        |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 182          |
|    ep_rew_mean          | 140          |
| time/                   |              |
|    fps                  | 1542         |
|    iterations           | 6            |
|    time_elapsed         | 7            |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0072479555 |
|    clip_fraction        | 0.0261       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.637       |
|    explained_variance   | -0.00269     |
|    learning_rate        | 0.0003       |
|    loss                 | 83.9         |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00153     |
|    value_loss           | 108          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 184         |
|    ep_rew_mean          | 142         |
| time/                   |             |
|    fps                  | 1535        |
|    iterations           | 7           |
|    time_elapsed         | 9           |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.014404683 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.673      |
|    explained_variance   | -0.00116    |
|    learning_rate        | 0.0003      |
|    loss                 | 63.9        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00478    |
|    value_loss           | 149         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 187        |
|    ep_rew_mean          | 145        |
| time/                   |            |
|    fps                  | 1531       |
|    iterations           | 8          |
|    time_elapsed         | 10         |
|    total_timesteps      | 16384      |
| train/                  |            |
|    approx_kl            | 0.00847625 |
|    clip_fraction        | 0.0641     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.684     |
|    explained_variance   | -0.000338  |
|    learning_rate        | 0.0003     |
|    loss                 | 28.9       |
|    n_updates            | 70         |
|    policy_gradient_loss | -0.00292   |
|    value_loss           | 128        |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 190          |
|    ep_rew_mean          | 149          |
| time/                   |              |
|    fps                  | 1528         |
|    iterations           | 9            |
|    time_elapsed         | 12           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0074718595 |
|    clip_fraction        | 0.0281       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.685       |
|    explained_variance   | -0.000472    |
|    learning_rate        | 0.0003       |
|    loss                 | 23.3         |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00288     |
|    value_loss           | 111          |
------------------------------------------
Eval num_timesteps=20000, episode_reward=84.95 +/- 3.52
Episode length: 136.40 +/- 3.38
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 136          |
|    mean_reward          | 85           |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0015181811 |
|    clip_fraction        | 0.00146      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.684       |
|    explained_variance   | -0.000437    |
|    learning_rate        | 0.0003       |
|    loss                 | 92.5         |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00164     |
|    value_loss           | 123          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 187      |
|    ep_rew_mean     | 145      |
| time/              |          |
|    fps             | 1504     |
|    iterations      | 10       |
|    time_elapsed    | 13       |
|    total_timesteps | 20480    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 191         |
|    ep_rew_mean          | 150         |
| time/                   |             |
|    fps                  | 1492        |
|    iterations           | 11          |
|    time_elapsed         | 15          |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.006901188 |
|    clip_fraction        | 0.00815     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.687      |
|    explained_variance   | -0.00016    |
|    learning_rate        | 0.0003      |
|    loss                 | 261         |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.000519   |
|    value_loss           | 361         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 190          |
|    ep_rew_mean          | 149          |
| time/                   |              |
|    fps                  | 1492         |
|    iterations           | 12           |
|    time_elapsed         | 16           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0053226785 |
|    clip_fraction        | 0.0135       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.675       |
|    explained_variance   | -9.33e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 170          |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00313     |
|    value_loss           | 219          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 190         |
|    ep_rew_mean          | 150         |
| time/                   |             |
|    fps                  | 1492        |
|    iterations           | 13          |
|    time_elapsed         | 17          |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.011456549 |
|    clip_fraction        | 0.0681      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.678      |
|    explained_variance   | -4.74e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 144         |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00448    |
|    value_loss           | 217         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 186         |
|    ep_rew_mean          | 145         |
| time/                   |             |
|    fps                  | 1493        |
|    iterations           | 14          |
|    time_elapsed         | 19          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.006860527 |
|    clip_fraction        | 0.0649      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.675      |
|    explained_variance   | -4.05e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 83.7        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00463    |
|    value_loss           | 225         |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=79.84 +/- 3.75
Episode length: 133.40 +/- 3.93
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 133          |
|    mean_reward          | 79.8         |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0018841026 |
|    clip_fraction        | 0.00278      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.681       |
|    explained_variance   | -2e-05       |
|    learning_rate        | 0.0003       |
|    loss                 | 174          |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.0021      |
|    value_loss           | 309          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 188      |
|    ep_rew_mean     | 148      |
| time/              |          |
|    fps             | 1480     |
|    iterations      | 15       |
|    time_elapsed    | 20       |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 185          |
|    ep_rew_mean          | 145          |
| time/                   |              |
|    fps                  | 1482         |
|    iterations           | 16           |
|    time_elapsed         | 22           |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0077054277 |
|    clip_fraction        | 0.0147       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.676       |
|    explained_variance   | -3.83e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 74           |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00278     |
|    value_loss           | 159          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 182         |
|    ep_rew_mean          | 140         |
| time/                   |             |
|    fps                  | 1483        |
|    iterations           | 17          |
|    time_elapsed         | 23          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.012841291 |
|    clip_fraction        | 0.0496      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.677      |
|    explained_variance   | -1.45e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 77.2        |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.00495    |
|    value_loss           | 315         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 180         |
|    ep_rew_mean          | 138         |
| time/                   |             |
|    fps                  | 1484        |
|    iterations           | 18          |
|    time_elapsed         | 24          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.001236977 |
|    clip_fraction        | 0.00244     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.655      |
|    explained_variance   | -1.18e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 226         |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0002     |
|    value_loss           | 251         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 187          |
|    ep_rew_mean          | 146          |
| time/                   |              |
|    fps                  | 1484         |
|    iterations           | 19           |
|    time_elapsed         | 26           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 0.0026935292 |
|    clip_fraction        | 0.00273      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.623       |
|    explained_variance   | -1.14e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 61.4         |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.00198     |
|    value_loss           | 157          |
------------------------------------------
Eval num_timesteps=40000, episode_reward=180.72 +/- 1.16
Episode length: 221.60 +/- 1.20
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 222          |
|    mean_reward          | 181          |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0013812877 |
|    clip_fraction        | 0.0022       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.637       |
|    explained_variance   | -1.53e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 36.8         |
|    n_updates            | 190          |
|    policy_gradient_loss | 9.12e-05     |
|    value_loss           | 134          |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 189      |
|    ep_rew_mean     | 148      |
| time/              |          |
|    fps             | 1469     |
|    iterations      | 20       |
|    time_elapsed    | 27       |
|    total_timesteps | 40960    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 190           |
|    ep_rew_mean          | 149           |
| time/                   |               |
|    fps                  | 1470          |
|    iterations           | 21            |
|    time_elapsed         | 29            |
|    total_timesteps      | 43008         |
| train/                  |               |
|    approx_kl            | 0.00031608087 |
|    clip_fraction        | 9.77e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.637        |
|    explained_variance   | -7.87e-06     |
|    learning_rate        | 0.0003        |
|    loss                 | 32.8          |
|    n_updates            | 200           |
|    policy_gradient_loss | -7.48e-05     |
|    value_loss           | 172           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 189          |
|    ep_rew_mean          | 147          |
| time/                   |              |
|    fps                  | 1471         |
|    iterations           | 22           |
|    time_elapsed         | 30           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0058237347 |
|    clip_fraction        | 0.0763       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.666       |
|    explained_variance   | -9.3e-06     |
|    learning_rate        | 0.0003       |
|    loss                 | 63.8         |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.00295     |
|    value_loss           | 206          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 187          |
|    ep_rew_mean          | 145          |
| time/                   |              |
|    fps                  | 1472         |
|    iterations           | 23           |
|    time_elapsed         | 31           |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 0.0015800043 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.672       |
|    explained_variance   | -4.89e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 87.7         |
|    n_updates            | 220          |
|    policy_gradient_loss | 0.000345     |
|    value_loss           | 272          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 188          |
|    ep_rew_mean          | 145          |
| time/                   |              |
|    fps                  | 1473         |
|    iterations           | 24           |
|    time_elapsed         | 33           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0025622535 |
|    clip_fraction        | 0.00615      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.683       |
|    explained_variance   | -6.08e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 106          |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.00164     |
|    value_loss           | 257          |
------------------------------------------
Eval num_timesteps=50000, episode_reward=84.68 +/- 2.79
Episode length: 135.40 +/- 2.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 135         |
|    mean_reward          | 84.7        |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.010755828 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.69       |
|    explained_variance   | -2.38e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 48          |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.00425    |
|    value_loss           | 194         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 191      |
|    ep_rew_mean     | 149      |
| time/              |          |
|    fps             | 1466     |
|    iterations      | 25       |
|    time_elapsed    | 34       |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 193         |
|    ep_rew_mean          | 151         |
| time/                   |             |
|    fps                  | 1467        |
|    iterations           | 26          |
|    time_elapsed         | 36          |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.003481675 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.687      |
|    explained_variance   | -3.34e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 48.8        |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00224    |
|    value_loss           | 174         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 193         |
|    ep_rew_mean          | 152         |
| time/                   |             |
|    fps                  | 1468        |
|    iterations           | 27          |
|    time_elapsed         | 37          |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.006242583 |
|    clip_fraction        | 0.0475      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.669      |
|    explained_variance   | -3.7e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 63          |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.00218    |
|    value_loss           | 170         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 192         |
|    ep_rew_mean          | 151         |
| time/                   |             |
|    fps                  | 1469        |
|    iterations           | 28          |
|    time_elapsed         | 39          |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.003101418 |
|    clip_fraction        | 0.00894     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.677      |
|    explained_variance   | -2.62e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 103         |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.000629   |
|    value_loss           | 208         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 189          |
|    ep_rew_mean          | 148          |
| time/                   |              |
|    fps                  | 1470         |
|    iterations           | 29           |
|    time_elapsed         | 40           |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 0.0041650347 |
|    clip_fraction        | 0.0063       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.672       |
|    explained_variance   | -3.34e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 78.9         |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.000899    |
|    value_loss           | 211          |
------------------------------------------
Eval num_timesteps=60000, episode_reward=113.48 +/- 84.33
Episode length: 163.80 +/- 73.42
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 164          |
|    mean_reward          | 113          |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0020226033 |
|    clip_fraction        | 0.00601      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.685       |
|    explained_variance   | -1.07e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 37.8         |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.000398    |
|    value_loss           | 206          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 190      |
|    ep_rew_mean     | 148      |
| time/              |          |
|    fps             | 1463     |
|    iterations      | 30       |
|    time_elapsed    | 41       |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 191         |
|    ep_rew_mean          | 150         |
| time/                   |             |
|    fps                  | 1464        |
|    iterations           | 31          |
|    time_elapsed         | 43          |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.006689075 |
|    clip_fraction        | 0.00781     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.683      |
|    explained_variance   | -1.43e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 148         |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00116    |
|    value_loss           | 197         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 191         |
|    ep_rew_mean          | 150         |
| time/                   |             |
|    fps                  | 1465        |
|    iterations           | 32          |
|    time_elapsed         | 44          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.005996081 |
|    clip_fraction        | 0.0334      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.647      |
|    explained_variance   | -8.34e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 40.7        |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.00341    |
|    value_loss           | 136         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 192          |
|    ep_rew_mean          | 150          |
| time/                   |              |
|    fps                  | 1466         |
|    iterations           | 33           |
|    time_elapsed         | 46           |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 0.0043418184 |
|    clip_fraction        | 0.0444       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.672       |
|    explained_variance   | -2.38e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 27           |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00136     |
|    value_loss           | 272          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 193         |
|    ep_rew_mean          | 152         |
| time/                   |             |
|    fps                  | 1467        |
|    iterations           | 34          |
|    time_elapsed         | 47          |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.008448151 |
|    clip_fraction        | 0.089       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.687      |
|    explained_variance   | -8.34e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 184         |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.00503    |
|    value_loss           | 164         |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=187.30 +/- 2.33
Episode length: 220.60 +/- 1.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 221         |
|    mean_reward          | 187         |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.009768358 |
|    clip_fraction        | 0.0568      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.681      |
|    explained_variance   | -8.34e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 162         |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.00628    |
|    value_loss           | 173         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 192      |
|    ep_rew_mean     | 151      |
| time/              |          |
|    fps             | 1459     |
|    iterations      | 35       |
|    time_elapsed    | 49       |
|    total_timesteps | 71680    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 194          |
|    ep_rew_mean          | 153          |
| time/                   |              |
|    fps                  | 1460         |
|    iterations           | 36           |
|    time_elapsed         | 50           |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 0.0019253525 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.686       |
|    explained_variance   | -5.96e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 110          |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.00136     |
|    value_loss           | 197          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 194         |
|    ep_rew_mean          | 152         |
| time/                   |             |
|    fps                  | 1461        |
|    iterations           | 37          |
|    time_elapsed         | 51          |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.006213353 |
|    clip_fraction        | 0.0228      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.671      |
|    explained_variance   | -5.96e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 25.3        |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0022     |
|    value_loss           | 140         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 192         |
|    ep_rew_mean          | 151         |
| time/                   |             |
|    fps                  | 1462        |
|    iterations           | 38          |
|    time_elapsed         | 53          |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.008568486 |
|    clip_fraction        | 0.0361      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.676      |
|    explained_variance   | -3.58e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 138         |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0004     |
|    value_loss           | 171         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 194         |
|    ep_rew_mean          | 153         |
| time/                   |             |
|    fps                  | 1462        |
|    iterations           | 39          |
|    time_elapsed         | 54          |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.004655673 |
|    clip_fraction        | 0.0236      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.69       |
|    explained_variance   | -2.38e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 123         |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.00262    |
|    value_loss           | 283         |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=180.90 +/- 2.12
Episode length: 222.00 +/- 2.28
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 222         |
|    mean_reward          | 181         |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.009662208 |
|    clip_fraction        | 0.00869     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.68       |
|    explained_variance   | -2.38e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 55          |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.00246    |
|    value_loss           | 139         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 191      |
|    ep_rew_mean     | 150      |
| time/              |          |
|    fps             | 1456     |
|    iterations      | 40       |
|    time_elapsed    | 56       |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 193         |
|    ep_rew_mean          | 153         |
| time/                   |             |
|    fps                  | 1457        |
|    iterations           | 41          |
|    time_elapsed         | 57          |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.014635436 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.687      |
|    explained_variance   | -7.15e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 154         |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.00836    |
|    value_loss           | 243         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 190         |
|    ep_rew_mean          | 150         |
| time/                   |             |
|    fps                  | 1458        |
|    iterations           | 42          |
|    time_elapsed         | 58          |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.008391496 |
|    clip_fraction        | 0.0305      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.691      |
|    explained_variance   | -7.15e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 97.7        |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.00399    |
|    value_loss           | 201         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 191         |
|    ep_rew_mean          | 152         |
| time/                   |             |
|    fps                  | 1458        |
|    iterations           | 43          |
|    time_elapsed         | 60          |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.008570742 |
|    clip_fraction        | 0.0666      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.691      |
|    explained_variance   | -5.96e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 67.4        |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.00595    |
|    value_loss           | 245         |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=147.74 +/- 54.94
Episode length: 186.20 +/- 45.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 186         |
|    mean_reward          | 148         |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.002676194 |
|    clip_fraction        | 0.000195    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.691      |
|    explained_variance   | -5.96e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 119         |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.000365   |
|    value_loss           | 140         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 191      |
|    ep_rew_mean     | 152      |
| time/              |          |
|    fps             | 1453     |
|    iterations      | 44       |
|    time_elapsed    | 61       |
|    total_timesteps | 90112    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 187          |
|    ep_rew_mean          | 148          |
| time/                   |              |
|    fps                  | 1454         |
|    iterations           | 45           |
|    time_elapsed         | 63           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0017812927 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.689       |
|    explained_variance   | -2.38e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 86.6         |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.000746    |
|    value_loss           | 183          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 185          |
|    ep_rew_mean          | 145          |
| time/                   |              |
|    fps                  | 1456         |
|    iterations           | 46           |
|    time_elapsed         | 64           |
|    total_timesteps      | 94208        |
| train/                  |              |
|    approx_kl            | 0.0017088787 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.69        |
|    explained_variance   | -2.38e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 243          |
|    n_updates            | 450          |
|    policy_gradient_loss | -0.000138    |
|    value_loss           | 309          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 185          |
|    ep_rew_mean          | 145          |
| time/                   |              |
|    fps                  | 1457         |
|    iterations           | 47           |
|    time_elapsed         | 66           |
|    total_timesteps      | 96256        |
| train/                  |              |
|    approx_kl            | 0.0038739976 |
|    clip_fraction        | 0.0167       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 107          |
|    n_updates            | 460          |
|    policy_gradient_loss | -0.00275     |
|    value_loss           | 262          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 182          |
|    ep_rew_mean          | 141          |
| time/                   |              |
|    fps                  | 1457         |
|    iterations           | 48           |
|    time_elapsed         | 67           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 0.0030518572 |
|    clip_fraction        | 0.0129       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | -2.38e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 227          |
|    n_updates            | 470          |
|    policy_gradient_loss | -0.00173     |
|    value_loss           | 266          |
------------------------------------------
Eval num_timesteps=100000, episode_reward=180.11 +/- 3.31
Episode length: 220.60 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 221         |
|    mean_reward          | 180         |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.005141381 |
|    clip_fraction        | 0.00674     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.686      |
|    explained_variance   | -2.38e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 203         |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.000806   |
|    value_loss           | 235         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 184      |
|    ep_rew_mean     | 145      |
| time/              |          |
|    fps             | 1452     |
|    iterations      | 49       |
|    time_elapsed    | 69       |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 184         |
|    ep_rew_mean          | 145         |
| time/                   |             |
|    fps                  | 1453        |
|    iterations           | 50          |
|    time_elapsed         | 70          |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.012647367 |
|    clip_fraction        | 0.0782      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.688      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 21          |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.00586    |
|    value_loss           | 128         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 187         |
|    ep_rew_mean          | 148         |
| time/                   |             |
|    fps                  | 1454        |
|    iterations           | 51          |
|    time_elapsed         | 71          |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.011127306 |
|    clip_fraction        | 0.0229      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.688      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 54.7        |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.00148    |
|    value_loss           | 208         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 188          |
|    ep_rew_mean          | 149          |
| time/                   |              |
|    fps                  | 1455         |
|    iterations           | 52           |
|    time_elapsed         | 73           |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 0.0056388946 |
|    clip_fraction        | 0.0127       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.674       |
|    explained_variance   | -2.38e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 132          |
|    n_updates            | 510          |
|    policy_gradient_loss | 0.000351     |
|    value_loss           | 142          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 187         |
|    ep_rew_mean          | 147         |
| time/                   |             |
|    fps                  | 1456        |
|    iterations           | 53          |
|    time_elapsed         | 74          |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.010211437 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.681      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 174         |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.00423    |
|    value_loss           | 144         |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=25.06 +/- 3.55
Episode length: 77.20 +/- 3.76
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 77.2        |
|    mean_reward          | 25.1        |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.018200552 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.672      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 19.7        |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.00508    |
|    value_loss           | 138         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | 148      |
| time/              |          |
|    fps             | 1454     |
|    iterations      | 54       |
|    time_elapsed    | 76       |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 190         |
|    ep_rew_mean          | 153         |
| time/                   |             |
|    fps                  | 1455        |
|    iterations           | 55          |
|    time_elapsed         | 77          |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.009404985 |
|    clip_fraction        | 0.00796     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.685      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 255         |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.000265   |
|    value_loss           | 325         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 195        |
|    ep_rew_mean          | 159        |
| time/                   |            |
|    fps                  | 1456       |
|    iterations           | 56         |
|    time_elapsed         | 78         |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.00917615 |
|    clip_fraction        | 0.0132     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.684     |
|    explained_variance   | -2.38e-07  |
|    learning_rate        | 0.0003     |
|    loss                 | 55.5       |
|    n_updates            | 550        |
|    policy_gradient_loss | -0.000508  |
|    value_loss           | 115        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 194         |
|    ep_rew_mean          | 159         |
| time/                   |             |
|    fps                  | 1457        |
|    iterations           | 57          |
|    time_elapsed         | 80          |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.010172643 |
|    clip_fraction        | 0.0293      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.67       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 55.5        |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.00316    |
|    value_loss           | 139         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 201         |
|    ep_rew_mean          | 166         |
| time/                   |             |
|    fps                  | 1457        |
|    iterations           | 58          |
|    time_elapsed         | 81          |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.011354644 |
|    clip_fraction        | 0.0648      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.676      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 46          |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.0055     |
|    value_loss           | 194         |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=154.55 +/- 49.19
Episode length: 201.40 +/- 35.71
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 201          |
|    mean_reward          | 155          |
| time/                   |              |
|    total_timesteps      | 120000       |
| train/                  |              |
|    approx_kl            | 0.0059806914 |
|    clip_fraction        | 0.0347       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.668       |
|    explained_variance   | -2.38e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 31.4         |
|    n_updates            | 580          |
|    policy_gradient_loss | -0.00381     |
|    value_loss           | 110          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 199      |
|    ep_rew_mean     | 163      |
| time/              |          |
|    fps             | 1453     |
|    iterations      | 59       |
|    time_elapsed    | 83       |
|    total_timesteps | 120832   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 203         |
|    ep_rew_mean          | 168         |
| time/                   |             |
|    fps                  | 1454        |
|    iterations           | 60          |
|    time_elapsed         | 84          |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.008185307 |
|    clip_fraction        | 0.0774      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.686      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 99.2        |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.00573    |
|    value_loss           | 186         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 199         |
|    ep_rew_mean          | 164         |
| time/                   |             |
|    fps                  | 1455        |
|    iterations           | 61          |
|    time_elapsed         | 85          |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.004592727 |
|    clip_fraction        | 0.00508     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.687      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 46.6        |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.00168    |
|    value_loss           | 121         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 198         |
|    ep_rew_mean          | 163         |
| time/                   |             |
|    fps                  | 1456        |
|    iterations           | 62          |
|    time_elapsed         | 87          |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.008568129 |
|    clip_fraction        | 0.0297      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.683      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 178         |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0021     |
|    value_loss           | 296         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 199         |
|    ep_rew_mean          | 164         |
| time/                   |             |
|    fps                  | 1451        |
|    iterations           | 63          |
|    time_elapsed         | 88          |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.009344926 |
|    clip_fraction        | 0.0179      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.682      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 115         |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.000573   |
|    value_loss           | 151         |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=192.19 +/- 5.32
Episode length: 224.60 +/- 2.50
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 225          |
|    mean_reward          | 192          |
| time/                   |              |
|    total_timesteps      | 130000       |
| train/                  |              |
|    approx_kl            | 0.0008965065 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.691       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 57.1         |
|    n_updates            | 630          |
|    policy_gradient_loss | -0.00134     |
|    value_loss           | 184          |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 169      |
| time/              |          |
|    fps             | 1447     |
|    iterations      | 64       |
|    time_elapsed    | 90       |
|    total_timesteps | 131072   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 201         |
|    ep_rew_mean          | 166         |
| time/                   |             |
|    fps                  | 1448        |
|    iterations           | 65          |
|    time_elapsed         | 91          |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.010525136 |
|    clip_fraction        | 0.0733      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.686      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 156         |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.00523    |
|    value_loss           | 155         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 197         |
|    ep_rew_mean          | 162         |
| time/                   |             |
|    fps                  | 1449        |
|    iterations           | 66          |
|    time_elapsed         | 93          |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.003847227 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.683      |
|    explained_variance   | -2.38e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 131         |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.000472   |
|    value_loss           | 189         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 195          |
|    ep_rew_mean          | 160          |
| time/                   |              |
|    fps                  | 1450         |
|    iterations           | 67           |
|    time_elapsed         | 94           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 0.0072158286 |
|    clip_fraction        | 0.0315       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 175          |
|    n_updates            | 660          |
|    policy_gradient_loss | -0.00322     |
|    value_loss           | 334          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 186         |
|    ep_rew_mean          | 151         |
| time/                   |             |
|    fps                  | 1450        |
|    iterations           | 68          |
|    time_elapsed         | 95          |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.009532593 |
|    clip_fraction        | 0.0572      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.676      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 227         |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.00484    |
|    value_loss           | 214         |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=62.69 +/- 77.96
Episode length: 104.20 +/- 60.99
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 104         |
|    mean_reward          | 62.7        |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.008560037 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.688      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 287         |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.00325    |
|    value_loss           | 393         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 183      |
|    ep_rew_mean     | 148      |
| time/              |          |
|    fps             | 1449     |
|    iterations      | 69       |
|    time_elapsed    | 97       |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 186         |
|    ep_rew_mean          | 152         |
| time/                   |             |
|    fps                  | 1450        |
|    iterations           | 70          |
|    time_elapsed         | 98          |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.011439072 |
|    clip_fraction        | 0.0352      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.688      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 54.6        |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.00402    |
|    value_loss           | 170         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 186          |
|    ep_rew_mean          | 152          |
| time/                   |              |
|    fps                  | 1451         |
|    iterations           | 71           |
|    time_elapsed         | 100          |
|    total_timesteps      | 145408       |
| train/                  |              |
|    approx_kl            | 0.0059511103 |
|    clip_fraction        | 0.0332       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.69        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 191          |
|    n_updates            | 700          |
|    policy_gradient_loss | -0.00174     |
|    value_loss           | 187          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 184          |
|    ep_rew_mean          | 148          |
| time/                   |              |
|    fps                  | 1451         |
|    iterations           | 72           |
|    time_elapsed         | 101          |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 0.0046860646 |
|    clip_fraction        | 0.000586     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.688       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 93.9         |
|    n_updates            | 710          |
|    policy_gradient_loss | -0.000493    |
|    value_loss           | 177          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 181          |
|    ep_rew_mean          | 146          |
| time/                   |              |
|    fps                  | 1452         |
|    iterations           | 73           |
|    time_elapsed         | 102          |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 0.0060771112 |
|    clip_fraction        | 0.00547      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.686       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 302          |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.00242     |
|    value_loss           | 270          |
------------------------------------------
Eval num_timesteps=150000, episode_reward=184.79 +/- 4.79
Episode length: 221.60 +/- 3.44
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 222          |
|    mean_reward          | 185          |
| time/                   |              |
|    total_timesteps      | 150000       |
| train/                  |              |
|    approx_kl            | 0.0042608324 |
|    clip_fraction        | 0.0241       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.682       |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 17           |
|    n_updates            | 730          |
|    policy_gradient_loss | -0.00106     |
|    value_loss           | 182          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 180      |
|    ep_rew_mean     | 143      |
| time/              |          |
|    fps             | 1449     |
|    iterations      | 74       |
|    time_elapsed    | 104      |
|    total_timesteps | 151552   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 183          |
|    ep_rew_mean          | 146          |
| time/                   |              |
|    fps                  | 1449         |
|    iterations           | 75           |
|    time_elapsed         | 105          |
|    total_timesteps      | 153600       |
| train/                  |              |
|    approx_kl            | 0.0081501845 |
|    clip_fraction        | 0.0236       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.689       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 69.1         |
|    n_updates            | 740          |
|    policy_gradient_loss | -0.00319     |
|    value_loss           | 212          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 182         |
|    ep_rew_mean          | 145         |
| time/                   |             |
|    fps                  | 1450        |
|    iterations           | 76          |
|    time_elapsed         | 107         |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.010507813 |
|    clip_fraction        | 0.0234      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.682      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 72.7        |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.00414    |
|    value_loss           | 240         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 184          |
|    ep_rew_mean          | 147          |
| time/                   |              |
|    fps                  | 1450         |
|    iterations           | 77           |
|    time_elapsed         | 108          |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 0.0056954874 |
|    clip_fraction        | 0.0116       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.685       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 63.6         |
|    n_updates            | 760          |
|    policy_gradient_loss | -0.00064     |
|    value_loss           | 245          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 186         |
|    ep_rew_mean          | 149         |
| time/                   |             |
|    fps                  | 1451        |
|    iterations           | 78          |
|    time_elapsed         | 110         |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.007016927 |
|    clip_fraction        | 0.0148      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.688      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 67.1        |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.00425    |
|    value_loss           | 305         |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=194.53 +/- 4.77
Episode length: 221.60 +/- 4.27
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 222           |
|    mean_reward          | 195           |
| time/                   |               |
|    total_timesteps      | 160000        |
| train/                  |               |
|    approx_kl            | 0.00085491507 |
|    clip_fraction        | 0.021         |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.677        |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.0003        |
|    loss                 | 52.4          |
|    n_updates            | 780           |
|    policy_gradient_loss | -0.00186      |
|    value_loss           | 136           |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 187      |
|    ep_rew_mean     | 150      |
| time/              |          |
|    fps             | 1448     |
|    iterations      | 79       |
|    time_elapsed    | 111      |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 180         |
|    ep_rew_mean          | 143         |
| time/                   |             |
|    fps                  | 1448        |
|    iterations           | 80          |
|    time_elapsed         | 113         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.009341368 |
|    clip_fraction        | 0.0715      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.68       |
|    explained_variance   | 1.19e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 99.8        |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.00771    |
|    value_loss           | 144         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 182         |
|    ep_rew_mean          | 145         |
| time/                   |             |
|    fps                  | 1449        |
|    iterations           | 81          |
|    time_elapsed         | 114         |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.010085518 |
|    clip_fraction        | 0.0282      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.686      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 54.8        |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.00201    |
|    value_loss           | 317         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 182          |
|    ep_rew_mean          | 146          |
| time/                   |              |
|    fps                  | 1450         |
|    iterations           | 82           |
|    time_elapsed         | 115          |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 0.0039074766 |
|    clip_fraction        | 0.0442       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.678       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 72.4         |
|    n_updates            | 810          |
|    policy_gradient_loss | -0.00177     |
|    value_loss           | 206          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 183         |
|    ep_rew_mean          | 146         |
| time/                   |             |
|    fps                  | 1450        |
|    iterations           | 83          |
|    time_elapsed         | 117         |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.005562572 |
|    clip_fraction        | 0.0527      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.674      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 82.9        |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.00444    |
|    value_loss           | 204         |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=193.93 +/- 4.74
Episode length: 221.00 +/- 2.45
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 221         |
|    mean_reward          | 194         |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.009133024 |
|    clip_fraction        | 0.0556      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.682      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 54.6        |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.00327    |
|    value_loss           | 168         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 184      |
|    ep_rew_mean     | 148      |
| time/              |          |
|    fps             | 1447     |
|    iterations      | 84       |
|    time_elapsed    | 118      |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 185         |
|    ep_rew_mean          | 150         |
| time/                   |             |
|    fps                  | 1448        |
|    iterations           | 85          |
|    time_elapsed         | 120         |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.010266049 |
|    clip_fraction        | 0.0435      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.68       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 268         |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.00181    |
|    value_loss           | 183         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 190          |
|    ep_rew_mean          | 155          |
| time/                   |              |
|    fps                  | 1449         |
|    iterations           | 86           |
|    time_elapsed         | 121          |
|    total_timesteps      | 176128       |
| train/                  |              |
|    approx_kl            | 0.0065964423 |
|    clip_fraction        | 0.00552      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 62.2         |
|    n_updates            | 850          |
|    policy_gradient_loss | -0.00207     |
|    value_loss           | 210          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 190          |
|    ep_rew_mean          | 154          |
| time/                   |              |
|    fps                  | 1450         |
|    iterations           | 87           |
|    time_elapsed         | 122          |
|    total_timesteps      | 178176       |
| train/                  |              |
|    approx_kl            | 0.0054101027 |
|    clip_fraction        | 0.0227       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.679       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 78.3         |
|    n_updates            | 860          |
|    policy_gradient_loss | -0.00166     |
|    value_loss           | 114          |
------------------------------------------
Eval num_timesteps=180000, episode_reward=194.19 +/- 6.83
Episode length: 221.60 +/- 3.50
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 222          |
|    mean_reward          | 194          |
| time/                   |              |
|    total_timesteps      | 180000       |
| train/                  |              |
|    approx_kl            | 0.0059064394 |
|    clip_fraction        | 0.0563       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.677       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 124          |
|    n_updates            | 870          |
|    policy_gradient_loss | -0.00558     |
|    value_loss           | 213          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 191      |
|    ep_rew_mean     | 156      |
| time/              |          |
|    fps             | 1446     |
|    iterations      | 88       |
|    time_elapsed    | 124      |
|    total_timesteps | 180224   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 191          |
|    ep_rew_mean          | 156          |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 89           |
|    time_elapsed         | 125          |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 0.0066024233 |
|    clip_fraction        | 0.0264       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.659       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 7.42         |
|    n_updates            | 880          |
|    policy_gradient_loss | -0.00207     |
|    value_loss           | 107          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 197         |
|    ep_rew_mean          | 164         |
| time/                   |             |
|    fps                  | 1448        |
|    iterations           | 90          |
|    time_elapsed         | 127         |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.009573346 |
|    clip_fraction        | 0.0492      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.658      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 63.3        |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.00248    |
|    value_loss           | 149         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 198          |
|    ep_rew_mean          | 166          |
| time/                   |              |
|    fps                  | 1448         |
|    iterations           | 91           |
|    time_elapsed         | 128          |
|    total_timesteps      | 186368       |
| train/                  |              |
|    approx_kl            | 0.0070117516 |
|    clip_fraction        | 0.0255       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.667       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 141          |
|    n_updates            | 900          |
|    policy_gradient_loss | -0.00203     |
|    value_loss           | 161          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 199         |
|    ep_rew_mean          | 168         |
| time/                   |             |
|    fps                  | 1449        |
|    iterations           | 92          |
|    time_elapsed         | 130         |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.005430529 |
|    clip_fraction        | 0.0163      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.667      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 87.9        |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.00148    |
|    value_loss           | 195         |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=192.69 +/- 3.01
Episode length: 222.20 +/- 3.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 222         |
|    mean_reward          | 193         |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.009812163 |
|    clip_fraction        | 0.0588      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.659      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 117         |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.00177    |
|    value_loss           | 247         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 199      |
|    ep_rew_mean     | 168      |
| time/              |          |
|    fps             | 1446     |
|    iterations      | 93       |
|    time_elapsed    | 131      |
|    total_timesteps | 190464   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 201          |
|    ep_rew_mean          | 169          |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 94           |
|    time_elapsed         | 133          |
|    total_timesteps      | 192512       |
| train/                  |              |
|    approx_kl            | 0.0075521385 |
|    clip_fraction        | 0.0225       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.662       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 138          |
|    n_updates            | 930          |
|    policy_gradient_loss | -0.000558    |
|    value_loss           | 156          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 202         |
|    ep_rew_mean          | 171         |
| time/                   |             |
|    fps                  | 1447        |
|    iterations           | 95          |
|    time_elapsed         | 134         |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.005352851 |
|    clip_fraction        | 0.0063      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.664      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 81.3        |
|    n_updates            | 940         |
|    policy_gradient_loss | 0.000681    |
|    value_loss           | 188         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 200          |
|    ep_rew_mean          | 169          |
| time/                   |              |
|    fps                  | 1448         |
|    iterations           | 96           |
|    time_elapsed         | 135          |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0029951208 |
|    clip_fraction        | 0.0112       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.666       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 78.8         |
|    n_updates            | 950          |
|    policy_gradient_loss | -0.000933    |
|    value_loss           | 199          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 196         |
|    ep_rew_mean          | 164         |
| time/                   |             |
|    fps                  | 1449        |
|    iterations           | 97          |
|    time_elapsed         | 137         |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.008068482 |
|    clip_fraction        | 0.0197      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.667      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 136         |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.000802   |
|    value_loss           | 186         |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=192.62 +/- 9.60
Episode length: 224.80 +/- 2.14
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 225          |
|    mean_reward          | 193          |
| time/                   |              |
|    total_timesteps      | 200000       |
| train/                  |              |
|    approx_kl            | 0.0074185207 |
|    clip_fraction        | 0.0355       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.673       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 131          |
|    n_updates            | 970          |
|    policy_gradient_loss | -0.00347     |
|    value_loss           | 268          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 195      |
|    ep_rew_mean     | 163      |
| time/              |          |
|    fps             | 1446     |
|    iterations      | 98       |
|    time_elapsed    | 138      |
|    total_timesteps | 200704   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 195          |
|    ep_rew_mean          | 162          |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 99           |
|    time_elapsed         | 140          |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 0.0046874247 |
|    clip_fraction        | 0.0283       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.672       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 56.2         |
|    n_updates            | 980          |
|    policy_gradient_loss | -0.00287     |
|    value_loss           | 149          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 197         |
|    ep_rew_mean          | 164         |
| time/                   |             |
|    fps                  | 1446        |
|    iterations           | 100         |
|    time_elapsed         | 141         |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.009100361 |
|    clip_fraction        | 0.0601      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.671      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 40.9        |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.00511    |
|    value_loss           | 157         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 189          |
|    ep_rew_mean          | 153          |
| time/                   |              |
|    fps                  | 1446         |
|    iterations           | 101          |
|    time_elapsed         | 142          |
|    total_timesteps      | 206848       |
| train/                  |              |
|    approx_kl            | 0.0066335737 |
|    clip_fraction        | 0.0654       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.673       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 36.7         |
|    n_updates            | 1000         |
|    policy_gradient_loss | -0.0036      |
|    value_loss           | 189          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 188          |
|    ep_rew_mean          | 153          |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 102          |
|    time_elapsed         | 144          |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 0.0025103977 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.664       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 364          |
|    n_updates            | 1010         |
|    policy_gradient_loss | -0.000174    |
|    value_loss           | 418          |
------------------------------------------
Eval num_timesteps=210000, episode_reward=128.76 +/- 83.96
Episode length: 161.80 +/- 70.13
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 162          |
|    mean_reward          | 129          |
| time/                   |              |
|    total_timesteps      | 210000       |
| train/                  |              |
|    approx_kl            | 0.0083915405 |
|    clip_fraction        | 0.0311       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.67        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 74.3         |
|    n_updates            | 1020         |
|    policy_gradient_loss | -0.00463     |
|    value_loss           | 218          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | 150      |
| time/              |          |
|    fps             | 1445     |
|    iterations      | 103      |
|    time_elapsed    | 145      |
|    total_timesteps | 210944   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 187          |
|    ep_rew_mean          | 153          |
| time/                   |              |
|    fps                  | 1446         |
|    iterations           | 104          |
|    time_elapsed         | 147          |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 0.0072230725 |
|    clip_fraction        | 0.053        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.668       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 194          |
|    n_updates            | 1030         |
|    policy_gradient_loss | -0.0042      |
|    value_loss           | 245          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 186         |
|    ep_rew_mean          | 151         |
| time/                   |             |
|    fps                  | 1447        |
|    iterations           | 105         |
|    time_elapsed         | 148         |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.008791319 |
|    clip_fraction        | 0.0291      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.667      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 126         |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.00173    |
|    value_loss           | 178         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 179          |
|    ep_rew_mean          | 144          |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 106          |
|    time_elapsed         | 149          |
|    total_timesteps      | 217088       |
| train/                  |              |
|    approx_kl            | 0.0066955774 |
|    clip_fraction        | 0.103        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.674       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 84.2         |
|    n_updates            | 1050         |
|    policy_gradient_loss | -0.00533     |
|    value_loss           | 229          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 179         |
|    ep_rew_mean          | 144         |
| time/                   |             |
|    fps                  | 1447        |
|    iterations           | 107         |
|    time_elapsed         | 151         |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.008042768 |
|    clip_fraction        | 0.0281      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.673      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 179         |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.00237    |
|    value_loss           | 416         |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=192.49 +/- 3.56
Episode length: 221.40 +/- 2.87
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 221          |
|    mean_reward          | 192          |
| time/                   |              |
|    total_timesteps      | 220000       |
| train/                  |              |
|    approx_kl            | 0.0045453166 |
|    clip_fraction        | 0.0195       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.67        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 68.8         |
|    n_updates            | 1070         |
|    policy_gradient_loss | -0.0011      |
|    value_loss           | 132          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 181      |
|    ep_rew_mean     | 146      |
| time/              |          |
|    fps             | 1445     |
|    iterations      | 108      |
|    time_elapsed    | 152      |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 178         |
|    ep_rew_mean          | 143         |
| time/                   |             |
|    fps                  | 1446        |
|    iterations           | 109         |
|    time_elapsed         | 154         |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.009853319 |
|    clip_fraction        | 0.0362      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.679      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 50.4        |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.00244    |
|    value_loss           | 107         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 179         |
|    ep_rew_mean          | 145         |
| time/                   |             |
|    fps                  | 1446        |
|    iterations           | 110         |
|    time_elapsed         | 155         |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.005000597 |
|    clip_fraction        | 0.0172      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.667      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 113         |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.000182   |
|    value_loss           | 327         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 181          |
|    ep_rew_mean          | 148          |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 111          |
|    time_elapsed         | 157          |
|    total_timesteps      | 227328       |
| train/                  |              |
|    approx_kl            | 0.0052462285 |
|    clip_fraction        | 0.00713      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.674       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 175          |
|    n_updates            | 1100         |
|    policy_gradient_loss | -0.00111     |
|    value_loss           | 252          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 182         |
|    ep_rew_mean          | 149         |
| time/                   |             |
|    fps                  | 1447        |
|    iterations           | 112         |
|    time_elapsed         | 158         |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.004917071 |
|    clip_fraction        | 0.0461      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.66       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 95          |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.00423    |
|    value_loss           | 186         |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=126.13 +/- 81.40
Episode length: 164.80 +/- 72.15
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 165          |
|    mean_reward          | 126          |
| time/                   |              |
|    total_timesteps      | 230000       |
| train/                  |              |
|    approx_kl            | 0.0048107356 |
|    clip_fraction        | 0.00586      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.655       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 222          |
|    n_updates            | 1120         |
|    policy_gradient_loss | -0.00151     |
|    value_loss           | 216          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 182      |
|    ep_rew_mean     | 148      |
| time/              |          |
|    fps             | 1446     |
|    iterations      | 113      |
|    time_elapsed    | 160      |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 182         |
|    ep_rew_mean          | 147         |
| time/                   |             |
|    fps                  | 1446        |
|    iterations           | 114         |
|    time_elapsed         | 161         |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.009145727 |
|    clip_fraction        | 0.0551      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.658      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 35.9        |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.00277    |
|    value_loss           | 138         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 190          |
|    ep_rew_mean          | 157          |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 115          |
|    time_elapsed         | 162          |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 0.0018033194 |
|    clip_fraction        | 0.0471       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.662       |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 85.5         |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.00114     |
|    value_loss           | 228          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 192         |
|    ep_rew_mean          | 159         |
| time/                   |             |
|    fps                  | 1447        |
|    iterations           | 116         |
|    time_elapsed         | 164         |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.009290356 |
|    clip_fraction        | 0.0583      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.66       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 101         |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.00349    |
|    value_loss           | 150         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 191          |
|    ep_rew_mean          | 157          |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 117          |
|    time_elapsed         | 165          |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 0.0062538697 |
|    clip_fraction        | 0.012        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.664       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 249          |
|    n_updates            | 1160         |
|    policy_gradient_loss | -0.00147     |
|    value_loss           | 183          |
------------------------------------------
Eval num_timesteps=240000, episode_reward=120.61 +/- 77.29
Episode length: 163.60 +/- 71.57
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 164         |
|    mean_reward          | 121         |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.003516722 |
|    clip_fraction        | 0.00986     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.648      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 41.3        |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.00271    |
|    value_loss           | 144         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 193      |
|    ep_rew_mean     | 159      |
| time/              |          |
|    fps             | 1446     |
|    iterations      | 118      |
|    time_elapsed    | 167      |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 197         |
|    ep_rew_mean          | 163         |
| time/                   |             |
|    fps                  | 1446        |
|    iterations           | 119         |
|    time_elapsed         | 168         |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.007600474 |
|    clip_fraction        | 0.0541      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.66       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 54.8        |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.0068     |
|    value_loss           | 149         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 200          |
|    ep_rew_mean          | 166          |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 120          |
|    time_elapsed         | 169          |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 0.0023091938 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.658       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 61.5         |
|    n_updates            | 1190         |
|    policy_gradient_loss | -6.35e-05    |
|    value_loss           | 124          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 201          |
|    ep_rew_mean          | 168          |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 121          |
|    time_elapsed         | 171          |
|    total_timesteps      | 247808       |
| train/                  |              |
|    approx_kl            | 0.0072702384 |
|    clip_fraction        | 0.0827       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.671       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 39.7         |
|    n_updates            | 1200         |
|    policy_gradient_loss | -0.00192     |
|    value_loss           | 189          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 203         |
|    ep_rew_mean          | 170         |
| time/                   |             |
|    fps                  | 1448        |
|    iterations           | 122         |
|    time_elapsed         | 172         |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.002479651 |
|    clip_fraction        | 0.0107      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.678      |
|    explained_variance   | 1.19e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 34          |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.00325    |
|    value_loss           | 156         |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=25.40 +/- 3.14
Episode length: 75.40 +/- 3.14
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 75.4         |
|    mean_reward          | 25.4         |
| time/                   |              |
|    total_timesteps      | 250000       |
| train/                  |              |
|    approx_kl            | 0.0025257675 |
|    clip_fraction        | 0.00454      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.672       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 80.8         |
|    n_updates            | 1220         |
|    policy_gradient_loss | -0.00186     |
|    value_loss           | 161          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | 166      |
| time/              |          |
|    fps             | 1447     |
|    iterations      | 123      |
|    time_elapsed    | 174      |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 205         |
|    ep_rew_mean          | 172         |
| time/                   |             |
|    fps                  | 1448        |
|    iterations           | 124         |
|    time_elapsed         | 175         |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.006403549 |
|    clip_fraction        | 0.0393      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.674      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 176         |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.00518    |
|    value_loss           | 227         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 207         |
|    ep_rew_mean          | 174         |
| time/                   |             |
|    fps                  | 1448        |
|    iterations           | 125         |
|    time_elapsed         | 176         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.013694381 |
|    clip_fraction        | 0.0319      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.676      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 54.5        |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.00521    |
|    value_loss           | 125         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 203          |
|    ep_rew_mean          | 169          |
| time/                   |              |
|    fps                  | 1448         |
|    iterations           | 126          |
|    time_elapsed         | 178          |
|    total_timesteps      | 258048       |
| train/                  |              |
|    approx_kl            | 0.0034483694 |
|    clip_fraction        | 0.011        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.669       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 40.1         |
|    n_updates            | 1250         |
|    policy_gradient_loss | -0.000967    |
|    value_loss           | 121          |
------------------------------------------
Eval num_timesteps=260000, episode_reward=212.38 +/- 6.44
Episode length: 221.40 +/- 3.44
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 221          |
|    mean_reward          | 212          |
| time/                   |              |
|    total_timesteps      | 260000       |
| train/                  |              |
|    approx_kl            | 0.0027135785 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.676       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 134          |
|    n_updates            | 1260         |
|    policy_gradient_loss | 0.000283     |
|    value_loss           | 282          |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 203      |
|    ep_rew_mean     | 170      |
| time/              |          |
|    fps             | 1446     |
|    iterations      | 127      |
|    time_elapsed    | 179      |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 201         |
|    ep_rew_mean          | 168         |
| time/                   |             |
|    fps                  | 1446        |
|    iterations           | 128         |
|    time_elapsed         | 181         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.009021292 |
|    clip_fraction        | 0.0466      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.654      |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 62.7        |
|    n_updates            | 1270        |
|    policy_gradient_loss | -0.00297    |
|    value_loss           | 151         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 203         |
|    ep_rew_mean          | 170         |
| time/                   |             |
|    fps                  | 1447        |
|    iterations           | 129         |
|    time_elapsed         | 182         |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.005777579 |
|    clip_fraction        | 0.035       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.655      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 151         |
|    n_updates            | 1280        |
|    policy_gradient_loss | -0.00552    |
|    value_loss           | 264         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 204         |
|    ep_rew_mean          | 172         |
| time/                   |             |
|    fps                  | 1447        |
|    iterations           | 130         |
|    time_elapsed         | 183         |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.008846108 |
|    clip_fraction        | 0.0422      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.664      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 43.2        |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.000488   |
|    value_loss           | 117         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 200         |
|    ep_rew_mean          | 167         |
| time/                   |             |
|    fps                  | 1448        |
|    iterations           | 131         |
|    time_elapsed         | 185         |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.009304626 |
|    clip_fraction        | 0.0393      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.653      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 55.7        |
|    n_updates            | 1300        |
|    policy_gradient_loss | -0.00311    |
|    value_loss           | 131         |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=128.42 +/- 83.65
Episode length: 162.80 +/- 70.90
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 163          |
|    mean_reward          | 128          |
| time/                   |              |
|    total_timesteps      | 270000       |
| train/                  |              |
|    approx_kl            | 0.0075466335 |
|    clip_fraction        | 0.0395       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.641       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 196          |
|    n_updates            | 1310         |
|    policy_gradient_loss | -0.00207     |
|    value_loss           | 301          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 202      |
|    ep_rew_mean     | 169      |
| time/              |          |
|    fps             | 1446     |
|    iterations      | 132      |
|    time_elapsed    | 186      |
|    total_timesteps | 270336   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 206          |
|    ep_rew_mean          | 174          |
| time/                   |              |
|    fps                  | 1446         |
|    iterations           | 133          |
|    time_elapsed         | 188          |
|    total_timesteps      | 272384       |
| train/                  |              |
|    approx_kl            | 0.0029260088 |
|    clip_fraction        | 0.00254      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.636       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 64.6         |
|    n_updates            | 1320         |
|    policy_gradient_loss | -0.00067     |
|    value_loss           | 132          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 199          |
|    ep_rew_mean          | 166          |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 134          |
|    time_elapsed         | 189          |
|    total_timesteps      | 274432       |
| train/                  |              |
|    approx_kl            | 0.0015963031 |
|    clip_fraction        | 0.0043       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.633       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 59           |
|    n_updates            | 1330         |
|    policy_gradient_loss | -0.000288    |
|    value_loss           | 122          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 200         |
|    ep_rew_mean          | 167         |
| time/                   |             |
|    fps                  | 1447        |
|    iterations           | 135         |
|    time_elapsed         | 191         |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.004285198 |
|    clip_fraction        | 0.00396     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.649      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 82.4        |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.00125    |
|    value_loss           | 305         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 205         |
|    ep_rew_mean          | 173         |
| time/                   |             |
|    fps                  | 1447        |
|    iterations           | 136         |
|    time_elapsed         | 192         |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.008569536 |
|    clip_fraction        | 0.0197      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.641      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 68.6        |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.00232    |
|    value_loss           | 128         |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=91.18 +/- 80.26
Episode length: 134.60 +/- 72.21
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 135          |
|    mean_reward          | 91.2         |
| time/                   |              |
|    total_timesteps      | 280000       |
| train/                  |              |
|    approx_kl            | 0.0037909765 |
|    clip_fraction        | 0.0147       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.641       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 51.2         |
|    n_updates            | 1360         |
|    policy_gradient_loss | -0.00217     |
|    value_loss           | 118          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 202      |
|    ep_rew_mean     | 170      |
| time/              |          |
|    fps             | 1446     |
|    iterations      | 137      |
|    time_elapsed    | 193      |
|    total_timesteps | 280576   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 204          |
|    ep_rew_mean          | 172          |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 138          |
|    time_elapsed         | 195          |
|    total_timesteps      | 282624       |
| train/                  |              |
|    approx_kl            | 0.0048864475 |
|    clip_fraction        | 0.0255       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.649       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 175          |
|    n_updates            | 1370         |
|    policy_gradient_loss | -0.000469    |
|    value_loss           | 195          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 202          |
|    ep_rew_mean          | 169          |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 139          |
|    time_elapsed         | 196          |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 0.0011656075 |
|    clip_fraction        | 4.88e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.655       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 91.7         |
|    n_updates            | 1380         |
|    policy_gradient_loss | -0.000249    |
|    value_loss           | 159          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 202         |
|    ep_rew_mean          | 169         |
| time/                   |             |
|    fps                  | 1447        |
|    iterations           | 140         |
|    time_elapsed         | 198         |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.006844838 |
|    clip_fraction        | 0.0441      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.654      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 26.6        |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.00637    |
|    value_loss           | 200         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 206         |
|    ep_rew_mean          | 174         |
| time/                   |             |
|    fps                  | 1448        |
|    iterations           | 141         |
|    time_elapsed         | 199         |
|    total_timesteps      | 288768      |
| train/                  |             |
|    approx_kl            | 0.005758042 |
|    clip_fraction        | 0.0142      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.662      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 67.8        |
|    n_updates            | 1400        |
|    policy_gradient_loss | -0.00191    |
|    value_loss           | 117         |
-----------------------------------------
Eval num_timesteps=290000, episode_reward=185.94 +/- 3.66
Episode length: 222.40 +/- 3.61
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 222         |
|    mean_reward          | 186         |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.008869547 |
|    clip_fraction        | 0.0422      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.646      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 79.3        |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.000939   |
|    value_loss           | 163         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 206      |
|    ep_rew_mean     | 173      |
| time/              |          |
|    fps             | 1446     |
|    iterations      | 142      |
|    time_elapsed    | 201      |
|    total_timesteps | 290816   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 206          |
|    ep_rew_mean          | 173          |
| time/                   |              |
|    fps                  | 1446         |
|    iterations           | 143          |
|    time_elapsed         | 202          |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 0.0019050413 |
|    clip_fraction        | 0.00483      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.646       |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 72.5         |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.000762    |
|    value_loss           | 119          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 210          |
|    ep_rew_mean          | 177          |
| time/                   |              |
|    fps                  | 1447         |
|    iterations           | 144          |
|    time_elapsed         | 203          |
|    total_timesteps      | 294912       |
| train/                  |              |
|    approx_kl            | 0.0037412872 |
|    clip_fraction        | 0.023        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.641       |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 67           |
|    n_updates            | 1430         |
|    policy_gradient_loss | -0.00207     |
|    value_loss           | 121          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 213         |
|    ep_rew_mean          | 180         |
| time/                   |             |
|    fps                  | 1447        |
|    iterations           | 145         |
|    time_elapsed         | 205         |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.008937329 |
|    clip_fraction        | 0.0398      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.65       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 61.4        |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.00489    |
|    value_loss           | 134         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 212         |
|    ep_rew_mean          | 179         |
| time/                   |             |
|    fps                  | 1447        |
|    iterations           | 146         |
|    time_elapsed         | 206         |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.011920314 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.674      |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 76.4        |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.00547    |
|    value_loss           | 119         |
-----------------------------------------
Eval num_timesteps=300000, episode_reward=194.20 +/- 3.93
Episode length: 222.60 +/- 3.83
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 223          |
|    mean_reward          | 194          |
| time/                   |              |
|    total_timesteps      | 300000       |
| train/                  |              |
|    approx_kl            | 0.0028265174 |
|    clip_fraction        | 0.0332       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.673       |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 75.2         |
|    n_updates            | 1460         |
|    policy_gradient_loss | -0.00236     |
|    value_loss           | 157          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 211      |
|    ep_rew_mean     | 177      |
| time/              |          |
|    fps             | 1446     |
|    iterations      | 147      |
|    time_elapsed    | 208      |
|    total_timesteps | 301056   |
---------------------------------

Training complete!
Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-06_22-00-19

