Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-08_23-58-40

Map saved at: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-08_23-58-40/map_visualization.png

Using cpu device
Wrapping the env in a DummyVecEnv.
Logging to /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-08_23-58-40/tensorboard/PPO_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 332      |
|    ep_rew_mean     | -332     |
| time/              |          |
|    fps             | 2755     |
|    iterations      | 1        |
|    time_elapsed    | 0        |
|    total_timesteps | 2048     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 307         |
|    ep_rew_mean          | -230        |
| time/                   |             |
|    fps                  | 1853        |
|    iterations           | 2           |
|    time_elapsed         | 2           |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.038377568 |
|    clip_fraction        | 0.367       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | -0.0131     |
|    learning_rate        | 0.0003      |
|    loss                 | 49.6        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0413     |
|    value_loss           | 150         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 283        |
|    ep_rew_mean          | -125       |
| time/                   |            |
|    fps                  | 1672       |
|    iterations           | 3          |
|    time_elapsed         | 3          |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.05951217 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.972     |
|    explained_variance   | -0.000932  |
|    learning_rate        | 0.0003     |
|    loss                 | 29.3       |
|    n_updates            | 20         |
|    policy_gradient_loss | -0.034     |
|    value_loss           | 64.8       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 269        |
|    ep_rew_mean          | -64.3      |
| time/                   |            |
|    fps                  | 1606       |
|    iterations           | 4          |
|    time_elapsed         | 5          |
|    total_timesteps      | 8192       |
| train/                  |            |
|    approx_kl            | 0.01969086 |
|    clip_fraction        | 0.0546     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.888     |
|    explained_variance   | 0.0822     |
|    learning_rate        | 0.0003     |
|    loss                 | 14         |
|    n_updates            | 30         |
|    policy_gradient_loss | -0.0104    |
|    value_loss           | 48.7       |
----------------------------------------
Eval num_timesteps=10000, episode_reward=194.96 +/- 24.08
Episode length: 224.40 +/- 1.20
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 224          |
|    mean_reward          | 195          |
| time/                   |              |
|    total_timesteps      | 10000        |
| train/                  |              |
|    approx_kl            | 0.0123867355 |
|    clip_fraction        | 0.0675       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.849       |
|    explained_variance   | 0.502        |
|    learning_rate        | 0.0003       |
|    loss                 | 9.31         |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.013       |
|    value_loss           | 29           |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 261      |
|    ep_rew_mean     | -30.7    |
| time/              |          |
|    fps             | 1488     |
|    iterations      | 5        |
|    time_elapsed    | 6        |
|    total_timesteps | 10240    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 255        |
|    ep_rew_mean          | -5.78      |
| time/                   |            |
|    fps                  | 1477       |
|    iterations           | 6          |
|    time_elapsed         | 8          |
|    total_timesteps      | 12288      |
| train/                  |            |
|    approx_kl            | 0.01353622 |
|    clip_fraction        | 0.0418     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.822     |
|    explained_variance   | 0.63       |
|    learning_rate        | 0.0003     |
|    loss                 | 14.5       |
|    n_updates            | 50         |
|    policy_gradient_loss | -0.0108    |
|    value_loss           | 35.1       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 12.9        |
| time/                   |             |
|    fps                  | 1472        |
|    iterations           | 7           |
|    time_elapsed         | 9           |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.010021703 |
|    clip_fraction        | 0.0273      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.774      |
|    explained_variance   | 0.706       |
|    learning_rate        | 0.0003      |
|    loss                 | 13.6        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00712    |
|    value_loss           | 32.9        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 247        |
|    ep_rew_mean          | 25.6       |
| time/                   |            |
|    fps                  | 1467       |
|    iterations           | 8          |
|    time_elapsed         | 11         |
|    total_timesteps      | 16384      |
| train/                  |            |
|    approx_kl            | 0.01294722 |
|    clip_fraction        | 0.0292     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.708     |
|    explained_variance   | 0.474      |
|    learning_rate        | 0.0003     |
|    loss                 | 9.84       |
|    n_updates            | 70         |
|    policy_gradient_loss | -0.00711   |
|    value_loss           | 44.2       |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 245          |
|    ep_rew_mean          | 37.5         |
| time/                   |              |
|    fps                  | 1463         |
|    iterations           | 9            |
|    time_elapsed         | 12           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0071455697 |
|    clip_fraction        | 0.0298       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.702       |
|    explained_variance   | 0.536        |
|    learning_rate        | 0.0003       |
|    loss                 | 18.7         |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00231     |
|    value_loss           | 42.3         |
------------------------------------------
Eval num_timesteps=20000, episode_reward=126.09 +/- 24.03
Episode length: 220.60 +/- 3.61
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 221         |
|    mean_reward          | 126         |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.010697201 |
|    clip_fraction        | 0.0537      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.717      |
|    explained_variance   | 0.345       |
|    learning_rate        | 0.0003      |
|    loss                 | 25.8        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00561    |
|    value_loss           | 44.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 242      |
|    ep_rew_mean     | 45.2     |
| time/              |          |
|    fps             | 1434     |
|    iterations      | 10       |
|    time_elapsed    | 14       |
|    total_timesteps | 20480    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 240         |
|    ep_rew_mean          | 53.7        |
| time/                   |             |
|    fps                  | 1436        |
|    iterations           | 11          |
|    time_elapsed         | 15          |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.008380076 |
|    clip_fraction        | 0.0419      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.72       |
|    explained_variance   | 0.407       |
|    learning_rate        | 0.0003      |
|    loss                 | 20          |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00381    |
|    value_loss           | 53.4        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 237         |
|    ep_rew_mean          | 69.4        |
| time/                   |             |
|    fps                  | 1439        |
|    iterations           | 12          |
|    time_elapsed         | 17          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.014914302 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.726      |
|    explained_variance   | 0.183       |
|    learning_rate        | 0.0003      |
|    loss                 | 26.6        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00607    |
|    value_loss           | 53.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 229         |
|    ep_rew_mean          | 102         |
| time/                   |             |
|    fps                  | 1440        |
|    iterations           | 13          |
|    time_elapsed         | 18          |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.014992548 |
|    clip_fraction        | 0.0628      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.715      |
|    explained_variance   | 0.205       |
|    learning_rate        | 0.0003      |
|    loss                 | 23.4        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00438    |
|    value_loss           | 59.2        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 226         |
|    ep_rew_mean          | 111         |
| time/                   |             |
|    fps                  | 1440        |
|    iterations           | 14          |
|    time_elapsed         | 19          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.013836592 |
|    clip_fraction        | 0.0258      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.717      |
|    explained_variance   | 0.258       |
|    learning_rate        | 0.0003      |
|    loss                 | 30.5        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00229    |
|    value_loss           | 67.7        |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=190.95 +/- 20.93
Episode length: 219.40 +/- 3.50
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 219          |
|    mean_reward          | 191          |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0071039805 |
|    clip_fraction        | 0.000537     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.709       |
|    explained_variance   | 0.343        |
|    learning_rate        | 0.0003       |
|    loss                 | 24.8         |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00149     |
|    value_loss           | 67.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 225      |
|    ep_rew_mean     | 116      |
| time/              |          |
|    fps             | 1353     |
|    iterations      | 15       |
|    time_elapsed    | 22       |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 224          |
|    ep_rew_mean          | 120          |
| time/                   |              |
|    fps                  | 1360         |
|    iterations           | 16           |
|    time_elapsed         | 24           |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0007640443 |
|    clip_fraction        | 0.0624       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.677       |
|    explained_variance   | -0.00958     |
|    learning_rate        | 0.0003       |
|    loss                 | 15.1         |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00301     |
|    value_loss           | 66.9         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 223         |
|    ep_rew_mean          | 124         |
| time/                   |             |
|    fps                  | 1365        |
|    iterations           | 17          |
|    time_elapsed         | 25          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.008720284 |
|    clip_fraction        | 0.017       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.658      |
|    explained_variance   | 0.248       |
|    learning_rate        | 0.0003      |
|    loss                 | 59.6        |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.00214    |
|    value_loss           | 68.5        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 127         |
| time/                   |             |
|    fps                  | 1370        |
|    iterations           | 18          |
|    time_elapsed         | 26          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.010212709 |
|    clip_fraction        | 0.0464      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.608      |
|    explained_variance   | 0.189       |
|    learning_rate        | 0.0003      |
|    loss                 | 24          |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0044     |
|    value_loss           | 83          |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 129         |
| time/                   |             |
|    fps                  | 1374        |
|    iterations           | 19          |
|    time_elapsed         | 28          |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.004765309 |
|    clip_fraction        | 0.0288      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.629      |
|    explained_variance   | 0.18        |
|    learning_rate        | 0.0003      |
|    loss                 | 41.9        |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00117    |
|    value_loss           | 77.4        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=192.35 +/- 19.74
Episode length: 221.80 +/- 2.14
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 222         |
|    mean_reward          | 192         |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.009818138 |
|    clip_fraction        | 0.0845      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.585      |
|    explained_variance   | 0.248       |
|    learning_rate        | 0.0003      |
|    loss                 | 37.2        |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.00859    |
|    value_loss           | 83.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 131      |
| time/              |          |
|    fps             | 1364     |
|    iterations      | 20       |
|    time_elapsed    | 30       |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 134          |
| time/                   |              |
|    fps                  | 1369         |
|    iterations           | 21           |
|    time_elapsed         | 31           |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0018641949 |
|    clip_fraction        | 0.0209       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.611       |
|    explained_variance   | 0.163        |
|    learning_rate        | 0.0003       |
|    loss                 | 37.6         |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00146     |
|    value_loss           | 82.5         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 134         |
| time/                   |             |
|    fps                  | 1372        |
|    iterations           | 22          |
|    time_elapsed         | 32          |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.006187903 |
|    clip_fraction        | 0.0498      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.659      |
|    explained_variance   | 0.18        |
|    learning_rate        | 0.0003      |
|    loss                 | 57          |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.00254    |
|    value_loss           | 82.1        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 222        |
|    ep_rew_mean          | 135        |
| time/                   |            |
|    fps                  | 1376       |
|    iterations           | 23         |
|    time_elapsed         | 34         |
|    total_timesteps      | 47104      |
| train/                  |            |
|    approx_kl            | 0.00903005 |
|    clip_fraction        | 0.038      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.615     |
|    explained_variance   | 0.166      |
|    learning_rate        | 0.0003     |
|    loss                 | 41.5       |
|    n_updates            | 220        |
|    policy_gradient_loss | -0.00288   |
|    value_loss           | 87.2       |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 136          |
| time/                   |              |
|    fps                  | 1379         |
|    iterations           | 24           |
|    time_elapsed         | 35           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0068749115 |
|    clip_fraction        | 0.0132       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.633       |
|    explained_variance   | 0.195        |
|    learning_rate        | 0.0003       |
|    loss                 | 62.7         |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.000836    |
|    value_loss           | 84.3         |
------------------------------------------
Eval num_timesteps=50000, episode_reward=214.10 +/- 21.86
Episode length: 224.80 +/- 2.04
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 225         |
|    mean_reward          | 214         |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.007445704 |
|    clip_fraction        | 0.0371      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.678      |
|    explained_variance   | 0.234       |
|    learning_rate        | 0.0003      |
|    loss                 | 35          |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.00313    |
|    value_loss           | 81.9        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 138      |
| time/              |          |
|    fps             | 1369     |
|    iterations      | 25       |
|    time_elapsed    | 37       |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 137         |
| time/                   |             |
|    fps                  | 1373        |
|    iterations           | 26          |
|    time_elapsed         | 38          |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.006902561 |
|    clip_fraction        | 0.00508     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.659      |
|    explained_variance   | 0.132       |
|    learning_rate        | 0.0003      |
|    loss                 | 32.2        |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.0012     |
|    value_loss           | 82.3        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 138          |
| time/                   |              |
|    fps                  | 1376         |
|    iterations           | 27           |
|    time_elapsed         | 40           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 0.0081181135 |
|    clip_fraction        | 0.0225       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.624       |
|    explained_variance   | 0.24         |
|    learning_rate        | 0.0003       |
|    loss                 | 28.5         |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.00152     |
|    value_loss           | 85.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 139          |
| time/                   |              |
|    fps                  | 1378         |
|    iterations           | 28           |
|    time_elapsed         | 41           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0009394896 |
|    clip_fraction        | 0.00137      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.607       |
|    explained_variance   | 0.326        |
|    learning_rate        | 0.0003       |
|    loss                 | 35.9         |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.000419    |
|    value_loss           | 76.8         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 140         |
| time/                   |             |
|    fps                  | 1381        |
|    iterations           | 29          |
|    time_elapsed         | 42          |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.008400936 |
|    clip_fraction        | 0.0764      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.531      |
|    explained_variance   | 0.242       |
|    learning_rate        | 0.0003      |
|    loss                 | 40.1        |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00601    |
|    value_loss           | 79.4        |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=191.63 +/- 20.61
Episode length: 221.20 +/- 3.71
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 221          |
|    mean_reward          | 192          |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0011904164 |
|    clip_fraction        | 0.0244       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.481       |
|    explained_variance   | 0.268        |
|    learning_rate        | 0.0003       |
|    loss                 | 39.9         |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.00214     |
|    value_loss           | 76.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 140      |
| time/              |          |
|    fps             | 1374     |
|    iterations      | 30       |
|    time_elapsed    | 44       |
|    total_timesteps | 61440    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 141          |
| time/                   |              |
|    fps                  | 1377         |
|    iterations           | 31           |
|    time_elapsed         | 46           |
|    total_timesteps      | 63488        |
| train/                  |              |
|    approx_kl            | 0.0053629875 |
|    clip_fraction        | 0.0159       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.466       |
|    explained_variance   | 0.403        |
|    learning_rate        | 0.0003       |
|    loss                 | 45.8         |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.00203     |
|    value_loss           | 73.2         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 142          |
| time/                   |              |
|    fps                  | 1379         |
|    iterations           | 32           |
|    time_elapsed         | 47           |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0001751442 |
|    clip_fraction        | 0.000684     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.45        |
|    explained_variance   | 0.311        |
|    learning_rate        | 0.0003       |
|    loss                 | 28.7         |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.000426    |
|    value_loss           | 75.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 143          |
| time/                   |              |
|    fps                  | 1381         |
|    iterations           | 33           |
|    time_elapsed         | 48           |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 0.0012949668 |
|    clip_fraction        | 0.0063       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.414       |
|    explained_variance   | 0.394        |
|    learning_rate        | 0.0003       |
|    loss                 | 35.4         |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00141     |
|    value_loss           | 76.1         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 145           |
| time/                   |               |
|    fps                  | 1383          |
|    iterations           | 34            |
|    time_elapsed         | 50            |
|    total_timesteps      | 69632         |
| train/                  |               |
|    approx_kl            | 0.00040122078 |
|    clip_fraction        | 0.000195      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.405        |
|    explained_variance   | 0.434         |
|    learning_rate        | 0.0003        |
|    loss                 | 40.5          |
|    n_updates            | 330           |
|    policy_gradient_loss | -0.000333     |
|    value_loss           | 75.7          |
-------------------------------------------
Eval num_timesteps=70000, episode_reward=196.77 +/- 23.85
Episode length: 221.40 +/- 4.22
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 221           |
|    mean_reward          | 197           |
| time/                   |               |
|    total_timesteps      | 70000         |
| train/                  |               |
|    approx_kl            | 0.00092981115 |
|    clip_fraction        | 0.000537      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.407        |
|    explained_variance   | 0.448         |
|    learning_rate        | 0.0003        |
|    loss                 | 42.1          |
|    n_updates            | 340           |
|    policy_gradient_loss | -0.000516     |
|    value_loss           | 72.2          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 147      |
| time/              |          |
|    fps             | 1377     |
|    iterations      | 35       |
|    time_elapsed    | 52       |
|    total_timesteps | 71680    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 150          |
| time/                   |              |
|    fps                  | 1379         |
|    iterations           | 36           |
|    time_elapsed         | 53           |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 0.0032427078 |
|    clip_fraction        | 0.0409       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.344       |
|    explained_variance   | 0.534        |
|    learning_rate        | 0.0003       |
|    loss                 | 34.7         |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.00273     |
|    value_loss           | 66.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 152          |
| time/                   |              |
|    fps                  | 1381         |
|    iterations           | 37           |
|    time_elapsed         | 54           |
|    total_timesteps      | 75776        |
| train/                  |              |
|    approx_kl            | 0.0017032555 |
|    clip_fraction        | 0.00937      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.31        |
|    explained_variance   | 0.599        |
|    learning_rate        | 0.0003       |
|    loss                 | 19           |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.00119     |
|    value_loss           | 58.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 155          |
| time/                   |              |
|    fps                  | 1383         |
|    iterations           | 38           |
|    time_elapsed         | 56           |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 0.0031056125 |
|    clip_fraction        | 0.0347       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.26        |
|    explained_variance   | 0.602        |
|    learning_rate        | 0.0003       |
|    loss                 | 48.5         |
|    n_updates            | 370          |
|    policy_gradient_loss | -0.00288     |
|    value_loss           | 64.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 158          |
| time/                   |              |
|    fps                  | 1385         |
|    iterations           | 39           |
|    time_elapsed         | 57           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 0.0018240386 |
|    clip_fraction        | 0.0338       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.222       |
|    explained_variance   | 0.676        |
|    learning_rate        | 0.0003       |
|    loss                 | 28.3         |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.00335     |
|    value_loss           | 59.4         |
------------------------------------------
Eval num_timesteps=80000, episode_reward=208.45 +/- 14.23
Episode length: 222.20 +/- 3.66
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 222          |
|    mean_reward          | 208          |
| time/                   |              |
|    total_timesteps      | 80000        |
| train/                  |              |
|    approx_kl            | 0.0014408008 |
|    clip_fraction        | 0.0189       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.19        |
|    explained_variance   | 0.717        |
|    learning_rate        | 0.0003       |
|    loss                 | 28.6         |
|    n_updates            | 390          |
|    policy_gradient_loss | -0.0016      |
|    value_loss           | 50.1         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 160      |
| time/              |          |
|    fps             | 1377     |
|    iterations      | 40       |
|    time_elapsed    | 59       |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 163         |
| time/                   |             |
|    fps                  | 1379        |
|    iterations           | 41          |
|    time_elapsed         | 60          |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.001195617 |
|    clip_fraction        | 0.0234      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.159      |
|    explained_variance   | 0.785       |
|    learning_rate        | 0.0003      |
|    loss                 | 17.3        |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.00195    |
|    value_loss           | 41.9        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 167          |
| time/                   |              |
|    fps                  | 1380         |
|    iterations           | 42           |
|    time_elapsed         | 62           |
|    total_timesteps      | 86016        |
| train/                  |              |
|    approx_kl            | 0.0010465141 |
|    clip_fraction        | 0.014        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.132       |
|    explained_variance   | 0.847        |
|    learning_rate        | 0.0003       |
|    loss                 | 14.4         |
|    n_updates            | 410          |
|    policy_gradient_loss | -0.00204     |
|    value_loss           | 34.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 170          |
| time/                   |              |
|    fps                  | 1382         |
|    iterations           | 43           |
|    time_elapsed         | 63           |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 0.0009793182 |
|    clip_fraction        | 0.014        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.113       |
|    explained_variance   | 0.869        |
|    learning_rate        | 0.0003       |
|    loss                 | 23.3         |
|    n_updates            | 420          |
|    policy_gradient_loss | -0.00156     |
|    value_loss           | 32.6         |
------------------------------------------
Eval num_timesteps=90000, episode_reward=191.94 +/- 19.50
Episode length: 221.40 +/- 3.32
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 221          |
|    mean_reward          | 192          |
| time/                   |              |
|    total_timesteps      | 90000        |
| train/                  |              |
|    approx_kl            | 0.0004006682 |
|    clip_fraction        | 0.00308      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0986      |
|    explained_variance   | 0.899        |
|    learning_rate        | 0.0003       |
|    loss                 | 9.69         |
|    n_updates            | 430          |
|    policy_gradient_loss | -0.000952    |
|    value_loss           | 25.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 174      |
| time/              |          |
|    fps             | 1378     |
|    iterations      | 44       |
|    time_elapsed    | 65       |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 176         |
| time/                   |             |
|    fps                  | 1379        |
|    iterations           | 45          |
|    time_elapsed         | 66          |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.001004746 |
|    clip_fraction        | 0.0125      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0782     |
|    explained_variance   | 0.905       |
|    learning_rate        | 0.0003      |
|    loss                 | 8.54        |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00139    |
|    value_loss           | 27.1        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 179           |
| time/                   |               |
|    fps                  | 1381          |
|    iterations           | 46            |
|    time_elapsed         | 68            |
|    total_timesteps      | 94208         |
| train/                  |               |
|    approx_kl            | 0.00026866162 |
|    clip_fraction        | 0.00806       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0626       |
|    explained_variance   | 0.941         |
|    learning_rate        | 0.0003        |
|    loss                 | 4.58          |
|    n_updates            | 450           |
|    policy_gradient_loss | -0.00135      |
|    value_loss           | 20            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 183           |
| time/                   |               |
|    fps                  | 1383          |
|    iterations           | 47            |
|    time_elapsed         | 69            |
|    total_timesteps      | 96256         |
| train/                  |               |
|    approx_kl            | 0.00018533686 |
|    clip_fraction        | 0.00435       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0504       |
|    explained_variance   | 0.942         |
|    learning_rate        | 0.0003        |
|    loss                 | 10.3          |
|    n_updates            | 460           |
|    policy_gradient_loss | -0.00104      |
|    value_loss           | 19.7          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 186          |
| time/                   |              |
|    fps                  | 1384         |
|    iterations           | 48           |
|    time_elapsed         | 70           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 0.0001918228 |
|    clip_fraction        | 0.000439     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0449      |
|    explained_variance   | 0.946        |
|    learning_rate        | 0.0003       |
|    loss                 | 10.8         |
|    n_updates            | 470          |
|    policy_gradient_loss | -0.000344    |
|    value_loss           | 17.2         |
------------------------------------------
Eval num_timesteps=100000, episode_reward=196.63 +/- 22.64
Episode length: 223.20 +/- 1.94
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 223           |
|    mean_reward          | 197           |
| time/                   |               |
|    total_timesteps      | 100000        |
| train/                  |               |
|    approx_kl            | 0.00018815402 |
|    clip_fraction        | 0.00313       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0367       |
|    explained_variance   | 0.957         |
|    learning_rate        | 0.0003        |
|    loss                 | 5.06          |
|    n_updates            | 480           |
|    policy_gradient_loss | -0.000952     |
|    value_loss           | 16.4          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 189      |
| time/              |          |
|    fps             | 1379     |
|    iterations      | 49       |
|    time_elapsed    | 72       |
|    total_timesteps | 100352   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 190           |
| time/                   |               |
|    fps                  | 1381          |
|    iterations           | 50            |
|    time_elapsed         | 74            |
|    total_timesteps      | 102400        |
| train/                  |               |
|    approx_kl            | 0.00022336995 |
|    clip_fraction        | 0.00601       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0296       |
|    explained_variance   | 0.956         |
|    learning_rate        | 0.0003        |
|    loss                 | 8.26          |
|    n_updates            | 490           |
|    policy_gradient_loss | -0.0016       |
|    value_loss           | 18.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 193           |
| time/                   |               |
|    fps                  | 1382          |
|    iterations           | 51            |
|    time_elapsed         | 75            |
|    total_timesteps      | 104448        |
| train/                  |               |
|    approx_kl            | 0.00014482916 |
|    clip_fraction        | 0.00166       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0252       |
|    explained_variance   | 0.959         |
|    learning_rate        | 0.0003        |
|    loss                 | 9.03          |
|    n_updates            | 500           |
|    policy_gradient_loss | -0.000651     |
|    value_loss           | 15            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 195           |
| time/                   |               |
|    fps                  | 1384          |
|    iterations           | 52            |
|    time_elapsed         | 76            |
|    total_timesteps      | 106496        |
| train/                  |               |
|    approx_kl            | 1.5339465e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0239       |
|    explained_variance   | 0.948         |
|    learning_rate        | 0.0003        |
|    loss                 | 3.66          |
|    n_updates            | 510           |
|    policy_gradient_loss | -6.48e-05     |
|    value_loss           | 15.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 195           |
| time/                   |               |
|    fps                  | 1384          |
|    iterations           | 53            |
|    time_elapsed         | 78            |
|    total_timesteps      | 108544        |
| train/                  |               |
|    approx_kl            | 2.1210668e-05 |
|    clip_fraction        | 0.000146      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0231       |
|    explained_variance   | 0.963         |
|    learning_rate        | 0.0003        |
|    loss                 | 3.75          |
|    n_updates            | 520           |
|    policy_gradient_loss | -0.000311     |
|    value_loss           | 11.7          |
-------------------------------------------
Eval num_timesteps=110000, episode_reward=194.40 +/- 21.96
Episode length: 220.00 +/- 3.79
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 220           |
|    mean_reward          | 194           |
| time/                   |               |
|    total_timesteps      | 110000        |
| train/                  |               |
|    approx_kl            | 0.00014286174 |
|    clip_fraction        | 0.00371       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0198       |
|    explained_variance   | 0.955         |
|    learning_rate        | 0.0003        |
|    loss                 | 6.77          |
|    n_updates            | 530           |
|    policy_gradient_loss | -0.000845     |
|    value_loss           | 16.8          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 195      |
| time/              |          |
|    fps             | 1378     |
|    iterations      | 54       |
|    time_elapsed    | 80       |
|    total_timesteps | 110592   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 194          |
| time/                   |              |
|    fps                  | 1379         |
|    iterations           | 55           |
|    time_elapsed         | 81           |
|    total_timesteps      | 112640       |
| train/                  |              |
|    approx_kl            | 0.0001598351 |
|    clip_fraction        | 0.000977     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0153      |
|    explained_variance   | 0.958        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.98         |
|    n_updates            | 540          |
|    policy_gradient_loss | -0.000519    |
|    value_loss           | 15.9         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 196           |
| time/                   |               |
|    fps                  | 1378          |
|    iterations           | 56            |
|    time_elapsed         | 83            |
|    total_timesteps      | 114688        |
| train/                  |               |
|    approx_kl            | 1.6136939e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.013        |
|    explained_variance   | 0.961         |
|    learning_rate        | 0.0003        |
|    loss                 | 11.3          |
|    n_updates            | 550           |
|    policy_gradient_loss | -5.45e-05     |
|    value_loss           | 14.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 198           |
| time/                   |               |
|    fps                  | 1378          |
|    iterations           | 57            |
|    time_elapsed         | 84            |
|    total_timesteps      | 116736        |
| train/                  |               |
|    approx_kl            | 2.5951711e-05 |
|    clip_fraction        | 0.000293      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0104       |
|    explained_variance   | 0.967         |
|    learning_rate        | 0.0003        |
|    loss                 | 5.6           |
|    n_updates            | 560           |
|    policy_gradient_loss | -0.000414     |
|    value_loss           | 9.56          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 198          |
| time/                   |              |
|    fps                  | 1379         |
|    iterations           | 58           |
|    time_elapsed         | 86           |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 7.317902e-05 |
|    clip_fraction        | 0.00112      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00797     |
|    explained_variance   | 0.985        |
|    learning_rate        | 0.0003       |
|    loss                 | 4.94         |
|    n_updates            | 570          |
|    policy_gradient_loss | -0.00045     |
|    value_loss           | 7.12         |
------------------------------------------
Eval num_timesteps=120000, episode_reward=216.77 +/- 11.58
Episode length: 222.20 +/- 3.31
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 222           |
|    mean_reward          | 217           |
| time/                   |               |
|    total_timesteps      | 120000        |
| train/                  |               |
|    approx_kl            | 3.1036412e-05 |
|    clip_fraction        | 0.000195      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00703      |
|    explained_variance   | 0.96          |
|    learning_rate        | 0.0003        |
|    loss                 | 3.59          |
|    n_updates            | 580           |
|    policy_gradient_loss | -0.000197     |
|    value_loss           | 14.1          |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 200      |
| time/              |          |
|    fps             | 1374     |
|    iterations      | 59       |
|    time_elapsed    | 87       |
|    total_timesteps | 120832   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 201           |
| time/                   |               |
|    fps                  | 1374          |
|    iterations           | 60            |
|    time_elapsed         | 89            |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 1.3197423e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00623      |
|    explained_variance   | 0.971         |
|    learning_rate        | 0.0003        |
|    loss                 | 5.89          |
|    n_updates            | 590           |
|    policy_gradient_loss | -1.43e-05     |
|    value_loss           | 9.22          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 202          |
| time/                   |              |
|    fps                  | 1374         |
|    iterations           | 61           |
|    time_elapsed         | 90           |
|    total_timesteps      | 124928       |
| train/                  |              |
|    approx_kl            | 2.220855e-06 |
|    clip_fraction        | 0.000293     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00585     |
|    explained_variance   | 0.98         |
|    learning_rate        | 0.0003       |
|    loss                 | 5.12         |
|    n_updates            | 600          |
|    policy_gradient_loss | -9.09e-06    |
|    value_loss           | 9.46         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 202           |
| time/                   |               |
|    fps                  | 1374          |
|    iterations           | 62            |
|    time_elapsed         | 92            |
|    total_timesteps      | 126976        |
| train/                  |               |
|    approx_kl            | 1.9819709e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00625      |
|    explained_variance   | 0.961         |
|    learning_rate        | 0.0003        |
|    loss                 | 3.14          |
|    n_updates            | 610           |
|    policy_gradient_loss | -1.15e-05     |
|    value_loss           | 10.6          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 201           |
| time/                   |               |
|    fps                  | 1374          |
|    iterations           | 63            |
|    time_elapsed         | 93            |
|    total_timesteps      | 129024        |
| train/                  |               |
|    approx_kl            | 1.4656689e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00621      |
|    explained_variance   | 0.966         |
|    learning_rate        | 0.0003        |
|    loss                 | 5.52          |
|    n_updates            | 620           |
|    policy_gradient_loss | -8.12e-06     |
|    value_loss           | 10.8          |
-------------------------------------------
Eval num_timesteps=130000, episode_reward=217.68 +/- 7.38
Episode length: 222.40 +/- 3.26
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 222           |
|    mean_reward          | 218           |
| time/                   |               |
|    total_timesteps      | 130000        |
| train/                  |               |
|    approx_kl            | 4.4154236e-05 |
|    clip_fraction        | 0.000537      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00527      |
|    explained_variance   | 0.947         |
|    learning_rate        | 0.0003        |
|    loss                 | 3.64          |
|    n_updates            | 630           |
|    policy_gradient_loss | -0.000214     |
|    value_loss           | 9.42          |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 202      |
| time/              |          |
|    fps             | 1370     |
|    iterations      | 64       |
|    time_elapsed    | 95       |
|    total_timesteps | 131072   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 203          |
| time/                   |              |
|    fps                  | 1371         |
|    iterations           | 65           |
|    time_elapsed         | 97           |
|    total_timesteps      | 133120       |
| train/                  |              |
|    approx_kl            | 8.905132e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00472     |
|    explained_variance   | 0.968        |
|    learning_rate        | 0.0003       |
|    loss                 | 14.7         |
|    n_updates            | 640          |
|    policy_gradient_loss | -2.61e-05    |
|    value_loss           | 14.1         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 205          |
| time/                   |              |
|    fps                  | 1371         |
|    iterations           | 66           |
|    time_elapsed         | 98           |
|    total_timesteps      | 135168       |
| train/                  |              |
|    approx_kl            | 1.155457e-05 |
|    clip_fraction        | 0.000439     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00505     |
|    explained_variance   | 0.973        |
|    learning_rate        | 0.0003       |
|    loss                 | 7.19         |
|    n_updates            | 650          |
|    policy_gradient_loss | -0.000282    |
|    value_loss           | 11.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 204          |
| time/                   |              |
|    fps                  | 1371         |
|    iterations           | 67           |
|    time_elapsed         | 100          |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 5.667124e-05 |
|    clip_fraction        | 0.000684     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00426     |
|    explained_variance   | 0.98         |
|    learning_rate        | 0.0003       |
|    loss                 | 1.45         |
|    n_updates            | 660          |
|    policy_gradient_loss | -0.000489    |
|    value_loss           | 9.42         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 203           |
| time/                   |               |
|    fps                  | 1371          |
|    iterations           | 68            |
|    time_elapsed         | 101           |
|    total_timesteps      | 139264        |
| train/                  |               |
|    approx_kl            | 2.6073249e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0038       |
|    explained_variance   | 0.967         |
|    learning_rate        | 0.0003        |
|    loss                 | 6.99          |
|    n_updates            | 670           |
|    policy_gradient_loss | -1.96e-05     |
|    value_loss           | 14.1          |
-------------------------------------------
Eval num_timesteps=140000, episode_reward=201.18 +/- 19.20
Episode length: 221.80 +/- 3.12
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 222          |
|    mean_reward          | 201          |
| time/                   |              |
|    total_timesteps      | 140000       |
| train/                  |              |
|    approx_kl            | 2.266781e-05 |
|    clip_fraction        | 0.000293     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00326     |
|    explained_variance   | 0.973        |
|    learning_rate        | 0.0003       |
|    loss                 | 6.35         |
|    n_updates            | 680          |
|    policy_gradient_loss | -5.44e-05    |
|    value_loss           | 12.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 203      |
| time/              |          |
|    fps             | 1367     |
|    iterations      | 69       |
|    time_elapsed    | 103      |
|    total_timesteps | 141312   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 221      |
|    ep_rew_mean          | 201      |
| time/                   |          |
|    fps                  | 1368     |
|    iterations           | 70       |
|    time_elapsed         | 104      |
|    total_timesteps      | 143360   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00315 |
|    explained_variance   | 0.967    |
|    learning_rate        | 0.0003   |
|    loss                 | 8.85     |
|    n_updates            | 690      |
|    policy_gradient_loss | -2.2e-07 |
|    value_loss           | 11.8     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 200       |
| time/                   |           |
|    fps                  | 1368      |
|    iterations           | 71        |
|    time_elapsed         | 106       |
|    total_timesteps      | 145408    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00323  |
|    explained_variance   | 0.962     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.6       |
|    n_updates            | 700       |
|    policy_gradient_loss | -1.29e-06 |
|    value_loss           | 14.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 200       |
| time/                   |           |
|    fps                  | 1368      |
|    iterations           | 72        |
|    time_elapsed         | 107       |
|    total_timesteps      | 147456    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00313  |
|    explained_variance   | 0.976     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.6       |
|    n_updates            | 710       |
|    policy_gradient_loss | -1.73e-07 |
|    value_loss           | 10.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 200       |
| time/                   |           |
|    fps                  | 1368      |
|    iterations           | 73        |
|    time_elapsed         | 109       |
|    total_timesteps      | 149504    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00317  |
|    explained_variance   | 0.97      |
|    learning_rate        | 0.0003    |
|    loss                 | 4.94      |
|    n_updates            | 720       |
|    policy_gradient_loss | -2.26e-07 |
|    value_loss           | 13.9      |
---------------------------------------
Eval num_timesteps=150000, episode_reward=185.13 +/- 17.05
Episode length: 221.60 +/- 4.67
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 222           |
|    mean_reward          | 185           |
| time/                   |               |
|    total_timesteps      | 150000        |
| train/                  |               |
|    approx_kl            | 4.0671555e-05 |
|    clip_fraction        | 0.000732      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00277      |
|    explained_variance   | 0.963         |
|    learning_rate        | 0.0003        |
|    loss                 | 9.24          |
|    n_updates            | 730           |
|    policy_gradient_loss | -0.000197     |
|    value_loss           | 13.3          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 202      |
| time/              |          |
|    fps             | 1357     |
|    iterations      | 74       |
|    time_elapsed    | 111      |
|    total_timesteps | 151552   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 201       |
| time/                   |           |
|    fps                  | 1357      |
|    iterations           | 75        |
|    time_elapsed         | 113       |
|    total_timesteps      | 153600    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00261  |
|    explained_variance   | 0.979     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.83      |
|    n_updates            | 740       |
|    policy_gradient_loss | -2.25e-07 |
|    value_loss           | 11        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 202       |
| time/                   |           |
|    fps                  | 1358      |
|    iterations           | 76        |
|    time_elapsed         | 114       |
|    total_timesteps      | 155648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00266  |
|    explained_variance   | 0.977     |
|    learning_rate        | 0.0003    |
|    loss                 | 5.32      |
|    n_updates            | 750       |
|    policy_gradient_loss | -2.41e-07 |
|    value_loss           | 10.1      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 201           |
| time/                   |               |
|    fps                  | 1358          |
|    iterations           | 77            |
|    time_elapsed         | 116           |
|    total_timesteps      | 157696        |
| train/                  |               |
|    approx_kl            | 1.6096717e-05 |
|    clip_fraction        | 0.000342      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00312      |
|    explained_variance   | 0.975         |
|    learning_rate        | 0.0003        |
|    loss                 | 3.8           |
|    n_updates            | 760           |
|    policy_gradient_loss | -0.000393     |
|    value_loss           | 10.4          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 203       |
| time/                   |           |
|    fps                  | 1358      |
|    iterations           | 78        |
|    time_elapsed         | 117       |
|    total_timesteps      | 159744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00325  |
|    explained_variance   | 0.977     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.997     |
|    n_updates            | 770       |
|    policy_gradient_loss | -3.09e-08 |
|    value_loss           | 9.18      |
---------------------------------------
Eval num_timesteps=160000, episode_reward=201.86 +/- 20.56
Episode length: 223.60 +/- 3.14
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 224           |
|    mean_reward          | 202           |
| time/                   |               |
|    total_timesteps      | 160000        |
| train/                  |               |
|    approx_kl            | 1.8315885e-05 |
|    clip_fraction        | 0.000293      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00274      |
|    explained_variance   | 0.984         |
|    learning_rate        | 0.0003        |
|    loss                 | 4.24          |
|    n_updates            | 780           |
|    policy_gradient_loss | -0.000314     |
|    value_loss           | 8.54          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 203      |
| time/              |          |
|    fps             | 1355     |
|    iterations      | 79       |
|    time_elapsed    | 119      |
|    total_timesteps | 161792   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 204          |
| time/                   |              |
|    fps                  | 1356         |
|    iterations           | 80           |
|    time_elapsed         | 120          |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 7.477938e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00254     |
|    explained_variance   | 0.973        |
|    learning_rate        | 0.0003       |
|    loss                 | 3.6          |
|    n_updates            | 790          |
|    policy_gradient_loss | -7.1e-06     |
|    value_loss           | 11.8         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 204       |
| time/                   |           |
|    fps                  | 1356      |
|    iterations           | 81        |
|    time_elapsed         | 122       |
|    total_timesteps      | 165888    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0025   |
|    explained_variance   | 0.977     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.69      |
|    n_updates            | 800       |
|    policy_gradient_loss | -1.44e-06 |
|    value_loss           | 8.86      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 205       |
| time/                   |           |
|    fps                  | 1356      |
|    iterations           | 82        |
|    time_elapsed         | 123       |
|    total_timesteps      | 167936    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00254  |
|    explained_variance   | 0.972     |
|    learning_rate        | 0.0003    |
|    loss                 | 11.4      |
|    n_updates            | 810       |
|    policy_gradient_loss | -2.04e-07 |
|    value_loss           | 12.6      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 204           |
| time/                   |               |
|    fps                  | 1357          |
|    iterations           | 83            |
|    time_elapsed         | 125           |
|    total_timesteps      | 169984        |
| train/                  |               |
|    approx_kl            | 1.6362348e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00237      |
|    explained_variance   | 0.975         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.871         |
|    n_updates            | 820           |
|    policy_gradient_loss | -9.14e-05     |
|    value_loss           | 12.4          |
-------------------------------------------
Eval num_timesteps=170000, episode_reward=218.40 +/- 5.85
Episode length: 220.80 +/- 2.79
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 221      |
|    mean_reward          | 218      |
| time/                   |          |
|    total_timesteps      | 170000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00224 |
|    explained_variance   | 0.97     |
|    learning_rate        | 0.0003   |
|    loss                 | 11.2     |
|    n_updates            | 830      |
|    policy_gradient_loss | -4.8e-07 |
|    value_loss           | 12.2     |
--------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 204      |
| time/              |          |
|    fps             | 1353     |
|    iterations      | 84       |
|    time_elapsed    | 127      |
|    total_timesteps | 172032   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 204       |
| time/                   |           |
|    fps                  | 1354      |
|    iterations           | 85        |
|    time_elapsed         | 128       |
|    total_timesteps      | 174080    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00221  |
|    explained_variance   | 0.976     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.48      |
|    n_updates            | 840       |
|    policy_gradient_loss | -3.62e-07 |
|    value_loss           | 10.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 205       |
| time/                   |           |
|    fps                  | 1354      |
|    iterations           | 86        |
|    time_elapsed         | 130       |
|    total_timesteps      | 176128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00221  |
|    explained_variance   | 0.959     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.03      |
|    n_updates            | 850       |
|    policy_gradient_loss | -6.64e-07 |
|    value_loss           | 14.1      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 205       |
| time/                   |           |
|    fps                  | 1355      |
|    iterations           | 87        |
|    time_elapsed         | 131       |
|    total_timesteps      | 178176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00225  |
|    explained_variance   | 0.976     |
|    learning_rate        | 0.0003    |
|    loss                 | 16.4      |
|    n_updates            | 860       |
|    policy_gradient_loss | -1.06e-09 |
|    value_loss           | 12.7      |
---------------------------------------
Eval num_timesteps=180000, episode_reward=217.01 +/- 10.12
Episode length: 222.60 +/- 1.96
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 223           |
|    mean_reward          | 217           |
| time/                   |               |
|    total_timesteps      | 180000        |
| train/                  |               |
|    approx_kl            | 3.0904775e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00221      |
|    explained_variance   | 0.973         |
|    learning_rate        | 0.0003        |
|    loss                 | 1.1           |
|    n_updates            | 870           |
|    policy_gradient_loss | -1.74e-05     |
|    value_loss           | 7.75          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 205      |
| time/              |          |
|    fps             | 1352     |
|    iterations      | 88       |
|    time_elapsed    | 133      |
|    total_timesteps | 180224   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 203       |
| time/                   |           |
|    fps                  | 1353      |
|    iterations           | 89        |
|    time_elapsed         | 134       |
|    total_timesteps      | 182272    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00203  |
|    explained_variance   | 0.973     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.75      |
|    n_updates            | 880       |
|    policy_gradient_loss | -1.21e-07 |
|    value_loss           | 8.99      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 203          |
| time/                   |              |
|    fps                  | 1353         |
|    iterations           | 90           |
|    time_elapsed         | 136          |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 7.174822e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00187     |
|    explained_variance   | 0.966        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.74         |
|    n_updates            | 890          |
|    policy_gradient_loss | -2.39e-05    |
|    value_loss           | 9.07         |
------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 222      |
|    ep_rew_mean          | 203      |
| time/                   |          |
|    fps                  | 1353     |
|    iterations           | 91       |
|    time_elapsed         | 137      |
|    total_timesteps      | 186368   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00177 |
|    explained_variance   | 0.973    |
|    learning_rate        | 0.0003   |
|    loss                 | 4.45     |
|    n_updates            | 900      |
|    policy_gradient_loss | -1e-07   |
|    value_loss           | 12.9     |
--------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 203           |
| time/                   |               |
|    fps                  | 1354          |
|    iterations           | 92            |
|    time_elapsed         | 139           |
|    total_timesteps      | 188416        |
| train/                  |               |
|    approx_kl            | 1.1781231e-05 |
|    clip_fraction        | 4.88e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00175      |
|    explained_variance   | 0.968         |
|    learning_rate        | 0.0003        |
|    loss                 | 5.47          |
|    n_updates            | 910           |
|    policy_gradient_loss | -4.52e-05     |
|    value_loss           | 12.4          |
-------------------------------------------
Eval num_timesteps=190000, episode_reward=191.37 +/- 19.29
Episode length: 219.80 +/- 2.32
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 220      |
|    mean_reward          | 191      |
| time/                   |          |
|    total_timesteps      | 190000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00162 |
|    explained_variance   | 0.968    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.537    |
|    n_updates            | 920      |
|    policy_gradient_loss | -3.5e-07 |
|    value_loss           | 7.18     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 204      |
| time/              |          |
|    fps             | 1351     |
|    iterations      | 93       |
|    time_elapsed    | 140      |
|    total_timesteps | 190464   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 205       |
| time/                   |           |
|    fps                  | 1351      |
|    iterations           | 94        |
|    time_elapsed         | 142       |
|    total_timesteps      | 192512    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00162  |
|    explained_variance   | 0.983     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.9       |
|    n_updates            | 930       |
|    policy_gradient_loss | -1.32e-07 |
|    value_loss           | 6.93      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 204       |
| time/                   |           |
|    fps                  | 1352      |
|    iterations           | 95        |
|    time_elapsed         | 143       |
|    total_timesteps      | 194560    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00164  |
|    explained_variance   | 0.98      |
|    learning_rate        | 0.0003    |
|    loss                 | 2.4       |
|    n_updates            | 940       |
|    policy_gradient_loss | -9.02e-08 |
|    value_loss           | 6.84      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 203       |
| time/                   |           |
|    fps                  | 1352      |
|    iterations           | 96        |
|    time_elapsed         | 145       |
|    total_timesteps      | 196608    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0017   |
|    explained_variance   | 0.957     |
|    learning_rate        | 0.0003    |
|    loss                 | 11.5      |
|    n_updates            | 950       |
|    policy_gradient_loss | -3.49e-07 |
|    value_loss           | 12        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 204       |
| time/                   |           |
|    fps                  | 1353      |
|    iterations           | 97        |
|    time_elapsed         | 146       |
|    total_timesteps      | 198656    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00168  |
|    explained_variance   | 0.976     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.27      |
|    n_updates            | 960       |
|    policy_gradient_loss | -7.94e-08 |
|    value_loss           | 10.7      |
---------------------------------------
Eval num_timesteps=200000, episode_reward=205.79 +/- 18.60
Episode length: 222.40 +/- 4.08
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 222      |
|    mean_reward          | 206      |
| time/                   |          |
|    total_timesteps      | 200000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00169 |
|    explained_variance   | 0.979    |
|    learning_rate        | 0.0003   |
|    loss                 | 6.81     |
|    n_updates            | 970      |
|    policy_gradient_loss | -1.2e-08 |
|    value_loss           | 10       |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 203      |
| time/              |          |
|    fps             | 1350     |
|    iterations      | 98       |
|    time_elapsed    | 148      |
|    total_timesteps | 200704   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 203       |
| time/                   |           |
|    fps                  | 1350      |
|    iterations           | 99        |
|    time_elapsed         | 150       |
|    total_timesteps      | 202752    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0017   |
|    explained_variance   | 0.977     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.17      |
|    n_updates            | 980       |
|    policy_gradient_loss | -2.12e-08 |
|    value_loss           | 11        |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 202           |
| time/                   |               |
|    fps                  | 1351          |
|    iterations           | 100           |
|    time_elapsed         | 151           |
|    total_timesteps      | 204800        |
| train/                  |               |
|    approx_kl            | 6.7547255e-05 |
|    clip_fraction        | 0.000391      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00154      |
|    explained_variance   | 0.978         |
|    learning_rate        | 0.0003        |
|    loss                 | 2.42          |
|    n_updates            | 990           |
|    policy_gradient_loss | -0.000151     |
|    value_loss           | 10.4          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 201       |
| time/                   |           |
|    fps                  | 1351      |
|    iterations           | 101       |
|    time_elapsed         | 153       |
|    total_timesteps      | 206848    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00155  |
|    explained_variance   | 0.968     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.82      |
|    n_updates            | 1000      |
|    policy_gradient_loss | -2.29e-07 |
|    value_loss           | 12        |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 222      |
|    ep_rew_mean          | 203      |
| time/                   |          |
|    fps                  | 1351     |
|    iterations           | 102      |
|    time_elapsed         | 154      |
|    total_timesteps      | 208896   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00153 |
|    explained_variance   | 0.96     |
|    learning_rate        | 0.0003   |
|    loss                 | 7.43     |
|    n_updates            | 1010     |
|    policy_gradient_loss | 1.77e-08 |
|    value_loss           | 13.3     |
--------------------------------------
Eval num_timesteps=210000, episode_reward=208.34 +/- 20.62
Episode length: 221.00 +/- 3.29
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 221       |
|    mean_reward          | 208       |
| time/                   |           |
|    total_timesteps      | 210000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00153  |
|    explained_variance   | 0.98      |
|    learning_rate        | 0.0003    |
|    loss                 | 5.34      |
|    n_updates            | 1020      |
|    policy_gradient_loss | -8.28e-08 |
|    value_loss           | 9.75      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 200      |
| time/              |          |
|    fps             | 1349     |
|    iterations      | 103      |
|    time_elapsed    | 156      |
|    total_timesteps | 210944   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 200           |
| time/                   |               |
|    fps                  | 1349          |
|    iterations           | 104           |
|    time_elapsed         | 157           |
|    total_timesteps      | 212992        |
| train/                  |               |
|    approx_kl            | 1.6075646e-05 |
|    clip_fraction        | 0.000293      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00131      |
|    explained_variance   | 0.971         |
|    learning_rate        | 0.0003        |
|    loss                 | 3.55          |
|    n_updates            | 1030          |
|    policy_gradient_loss | -0.000243     |
|    value_loss           | 12            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 199          |
| time/                   |              |
|    fps                  | 1350         |
|    iterations           | 105          |
|    time_elapsed         | 159          |
|    total_timesteps      | 215040       |
| train/                  |              |
|    approx_kl            | 2.924935e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00121     |
|    explained_variance   | 0.971        |
|    learning_rate        | 0.0003       |
|    loss                 | 5.63         |
|    n_updates            | 1040         |
|    policy_gradient_loss | -2e-05       |
|    value_loss           | 12.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 199           |
| time/                   |               |
|    fps                  | 1350          |
|    iterations           | 106           |
|    time_elapsed         | 160           |
|    total_timesteps      | 217088        |
| train/                  |               |
|    approx_kl            | 1.7858401e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00109      |
|    explained_variance   | 0.971         |
|    learning_rate        | 0.0003        |
|    loss                 | 7.87          |
|    n_updates            | 1050          |
|    policy_gradient_loss | -7.34e-06     |
|    value_loss           | 13.2          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 221      |
|    ep_rew_mean          | 199      |
| time/                   |          |
|    fps                  | 1350     |
|    iterations           | 107      |
|    time_elapsed         | 162      |
|    total_timesteps      | 219136   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00105 |
|    explained_variance   | 0.972    |
|    learning_rate        | 0.0003   |
|    loss                 | 8.75     |
|    n_updates            | 1060     |
|    policy_gradient_loss | -7.4e-08 |
|    value_loss           | 10.8     |
--------------------------------------
Eval num_timesteps=220000, episode_reward=213.61 +/- 19.64
Episode length: 224.20 +/- 2.32
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 224      |
|    mean_reward          | 214      |
| time/                   |          |
|    total_timesteps      | 220000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00109 |
|    explained_variance   | 0.973    |
|    learning_rate        | 0.0003   |
|    loss                 | 5.08     |
|    n_updates            | 1070     |
|    policy_gradient_loss | 7.78e-09 |
|    value_loss           | 13.9     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 199      |
| time/              |          |
|    fps             | 1348     |
|    iterations      | 108      |
|    time_elapsed    | 164      |
|    total_timesteps | 221184   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 199       |
| time/                   |           |
|    fps                  | 1349      |
|    iterations           | 109       |
|    time_elapsed         | 165       |
|    total_timesteps      | 223232    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00107  |
|    explained_variance   | 0.972     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.92      |
|    n_updates            | 1080      |
|    policy_gradient_loss | -2.35e-08 |
|    value_loss           | 12        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 200       |
| time/                   |           |
|    fps                  | 1349      |
|    iterations           | 110       |
|    time_elapsed         | 166       |
|    total_timesteps      | 225280    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00107  |
|    explained_variance   | 0.973     |
|    learning_rate        | 0.0003    |
|    loss                 | 7.44      |
|    n_updates            | 1090      |
|    policy_gradient_loss | -4.05e-09 |
|    value_loss           | 13.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 202       |
| time/                   |           |
|    fps                  | 1349      |
|    iterations           | 111       |
|    time_elapsed         | 168       |
|    total_timesteps      | 227328    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00107  |
|    explained_variance   | 0.976     |
|    learning_rate        | 0.0003    |
|    loss                 | 12.2      |
|    n_updates            | 1100      |
|    policy_gradient_loss | -3.03e-09 |
|    value_loss           | 11.9      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 202       |
| time/                   |           |
|    fps                  | 1350      |
|    iterations           | 112       |
|    time_elapsed         | 169       |
|    total_timesteps      | 229376    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00108  |
|    explained_variance   | 0.971     |
|    learning_rate        | 0.0003    |
|    loss                 | 7.92      |
|    n_updates            | 1110      |
|    policy_gradient_loss | -1.83e-08 |
|    value_loss           | 13.2      |
---------------------------------------
Eval num_timesteps=230000, episode_reward=195.58 +/- 22.02
Episode length: 220.00 +/- 3.41
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 220       |
|    mean_reward          | 196       |
| time/                   |           |
|    total_timesteps      | 230000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0011   |
|    explained_variance   | 0.977     |
|    learning_rate        | 0.0003    |
|    loss                 | 9.22      |
|    n_updates            | 1120      |
|    policy_gradient_loss | -4.78e-08 |
|    value_loss           | 10.7      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 202      |
| time/              |          |
|    fps             | 1348     |
|    iterations      | 113      |
|    time_elapsed    | 171      |
|    total_timesteps | 231424   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 202       |
| time/                   |           |
|    fps                  | 1348      |
|    iterations           | 114       |
|    time_elapsed         | 173       |
|    total_timesteps      | 233472    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00108  |
|    explained_variance   | 0.977     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.34      |
|    n_updates            | 1130      |
|    policy_gradient_loss | -4.87e-09 |
|    value_loss           | 10.3      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 221      |
|    ep_rew_mean          | 201      |
| time/                   |          |
|    fps                  | 1348     |
|    iterations           | 115      |
|    time_elapsed         | 174      |
|    total_timesteps      | 235520   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00109 |
|    explained_variance   | 0.972    |
|    learning_rate        | 0.0003   |
|    loss                 | 7.2      |
|    n_updates            | 1140     |
|    policy_gradient_loss | -5.7e-08 |
|    value_loss           | 12.3     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 202       |
| time/                   |           |
|    fps                  | 1348      |
|    iterations           | 116       |
|    time_elapsed         | 176       |
|    total_timesteps      | 237568    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0011   |
|    explained_variance   | 0.978     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.79      |
|    n_updates            | 1150      |
|    policy_gradient_loss | -2.13e-08 |
|    value_loss           | 11.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 202       |
| time/                   |           |
|    fps                  | 1349      |
|    iterations           | 117       |
|    time_elapsed         | 177       |
|    total_timesteps      | 239616    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00112  |
|    explained_variance   | 0.977     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.6       |
|    n_updates            | 1160      |
|    policy_gradient_loss | -2.94e-08 |
|    value_loss           | 9.54      |
---------------------------------------
Eval num_timesteps=240000, episode_reward=200.55 +/- 19.55
Episode length: 220.80 +/- 3.19
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 221       |
|    mean_reward          | 201       |
| time/                   |           |
|    total_timesteps      | 240000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00111  |
|    explained_variance   | 0.972     |
|    learning_rate        | 0.0003    |
|    loss                 | 5.54      |
|    n_updates            | 1170      |
|    policy_gradient_loss | -4.55e-08 |
|    value_loss           | 12.8      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 201      |
| time/              |          |
|    fps             | 1346     |
|    iterations      | 118      |
|    time_elapsed    | 179      |
|    total_timesteps | 241664   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 222      |
|    ep_rew_mean          | 201      |
| time/                   |          |
|    fps                  | 1347     |
|    iterations           | 119      |
|    time_elapsed         | 180      |
|    total_timesteps      | 243712   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00112 |
|    explained_variance   | 0.961    |
|    learning_rate        | 0.0003   |
|    loss                 | 3.56     |
|    n_updates            | 1180     |
|    policy_gradient_loss | -2.2e-07 |
|    value_loss           | 12.8     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 201       |
| time/                   |           |
|    fps                  | 1347      |
|    iterations           | 120       |
|    time_elapsed         | 182       |
|    total_timesteps      | 245760    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00114  |
|    explained_variance   | 0.972     |
|    learning_rate        | 0.0003    |
|    loss                 | 5.16      |
|    n_updates            | 1190      |
|    policy_gradient_loss | -3.83e-08 |
|    value_loss           | 10.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 200       |
| time/                   |           |
|    fps                  | 1347      |
|    iterations           | 121       |
|    time_elapsed         | 183       |
|    total_timesteps      | 247808    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00117  |
|    explained_variance   | 0.97      |
|    learning_rate        | 0.0003    |
|    loss                 | 10.9      |
|    n_updates            | 1200      |
|    policy_gradient_loss | -2.78e-08 |
|    value_loss           | 13.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 200       |
| time/                   |           |
|    fps                  | 1348      |
|    iterations           | 122       |
|    time_elapsed         | 185       |
|    total_timesteps      | 249856    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00113  |
|    explained_variance   | 0.978     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.74      |
|    n_updates            | 1210      |
|    policy_gradient_loss | -8.27e-09 |
|    value_loss           | 9.8       |
---------------------------------------
Eval num_timesteps=250000, episode_reward=199.48 +/- 19.31
Episode length: 222.00 +/- 3.69
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 222       |
|    mean_reward          | 199       |
| time/                   |           |
|    total_timesteps      | 250000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00113  |
|    explained_variance   | 0.98      |
|    learning_rate        | 0.0003    |
|    loss                 | 7.56      |
|    n_updates            | 1220      |
|    policy_gradient_loss | -5.44e-08 |
|    value_loss           | 7.68      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 199      |
| time/              |          |
|    fps             | 1341     |
|    iterations      | 123      |
|    time_elapsed    | 187      |
|    total_timesteps | 251904   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 200       |
| time/                   |           |
|    fps                  | 1342      |
|    iterations           | 124       |
|    time_elapsed         | 189       |
|    total_timesteps      | 253952    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00114  |
|    explained_variance   | 0.974     |
|    learning_rate        | 0.0003    |
|    loss                 | 5         |
|    n_updates            | 1230      |
|    policy_gradient_loss | -6.74e-08 |
|    value_loss           | 10.5      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 200         |
| time/                   |             |
|    fps                  | 1342        |
|    iterations           | 125         |
|    time_elapsed         | 190         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 9.11532e-08 |
|    clip_fraction        | 0           |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00117    |
|    explained_variance   | 0.977       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.17        |
|    n_updates            | 1240        |
|    policy_gradient_loss | -2.99e-07   |
|    value_loss           | 11.4        |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 221      |
|    ep_rew_mean          | 201      |
| time/                   |          |
|    fps                  | 1342     |
|    iterations           | 126      |
|    time_elapsed         | 192      |
|    total_timesteps      | 258048   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00117 |
|    explained_variance   | 0.972    |
|    learning_rate        | 0.0003   |
|    loss                 | 3.29     |
|    n_updates            | 1250     |
|    policy_gradient_loss | 2.89e-09 |
|    value_loss           | 14       |
--------------------------------------
Eval num_timesteps=260000, episode_reward=212.75 +/- 7.48
Episode length: 223.20 +/- 2.86
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 223       |
|    mean_reward          | 213       |
| time/                   |           |
|    total_timesteps      | 260000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00116  |
|    explained_variance   | 0.98      |
|    learning_rate        | 0.0003    |
|    loss                 | 1.26      |
|    n_updates            | 1260      |
|    policy_gradient_loss | -6.84e-08 |
|    value_loss           | 8.25      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 203      |
| time/              |          |
|    fps             | 1339     |
|    iterations      | 127      |
|    time_elapsed    | 194      |
|    total_timesteps | 260096   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 222      |
|    ep_rew_mean          | 203      |
| time/                   |          |
|    fps                  | 1339     |
|    iterations           | 128      |
|    time_elapsed         | 195      |
|    total_timesteps      | 262144   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00116 |
|    explained_variance   | 0.983    |
|    learning_rate        | 0.0003   |
|    loss                 | 1.49     |
|    n_updates            | 1270     |
|    policy_gradient_loss | 4e-09    |
|    value_loss           | 4.15     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 203       |
| time/                   |           |
|    fps                  | 1339      |
|    iterations           | 129       |
|    time_elapsed         | 197       |
|    total_timesteps      | 264192    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00121  |
|    explained_variance   | 0.968     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.13      |
|    n_updates            | 1280      |
|    policy_gradient_loss | -3.39e-07 |
|    value_loss           | 10.6      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 204           |
| time/                   |               |
|    fps                  | 1340          |
|    iterations           | 130           |
|    time_elapsed         | 198           |
|    total_timesteps      | 266240        |
| train/                  |               |
|    approx_kl            | 3.9719453e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00115      |
|    explained_variance   | 0.961         |
|    learning_rate        | 0.0003        |
|    loss                 | 3.92          |
|    n_updates            | 1290          |
|    policy_gradient_loss | -4.24e-06     |
|    value_loss           | 9.74          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 204       |
| time/                   |           |
|    fps                  | 1340      |
|    iterations           | 131       |
|    time_elapsed         | 200       |
|    total_timesteps      | 268288    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00107  |
|    explained_variance   | 0.979     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.07      |
|    n_updates            | 1300      |
|    policy_gradient_loss | -1.86e-07 |
|    value_loss           | 6.65      |
---------------------------------------
Eval num_timesteps=270000, episode_reward=187.57 +/- 20.77
Episode length: 222.00 +/- 4.05
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 222       |
|    mean_reward          | 188       |
| time/                   |           |
|    total_timesteps      | 270000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00107  |
|    explained_variance   | 0.973     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.47      |
|    n_updates            | 1310      |
|    policy_gradient_loss | -1.37e-07 |
|    value_loss           | 11.9      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 203      |
| time/              |          |
|    fps             | 1338     |
|    iterations      | 132      |
|    time_elapsed    | 201      |
|    total_timesteps | 270336   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 201       |
| time/                   |           |
|    fps                  | 1339      |
|    iterations           | 133       |
|    time_elapsed         | 203       |
|    total_timesteps      | 272384    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00112  |
|    explained_variance   | 0.968     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.15      |
|    n_updates            | 1320      |
|    policy_gradient_loss | -3.25e-07 |
|    value_loss           | 9.72      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 200       |
| time/                   |           |
|    fps                  | 1339      |
|    iterations           | 134       |
|    time_elapsed         | 204       |
|    total_timesteps      | 274432    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0011   |
|    explained_variance   | 0.967     |
|    learning_rate        | 0.0003    |
|    loss                 | 5.37      |
|    n_updates            | 1330      |
|    policy_gradient_loss | -8.64e-08 |
|    value_loss           | 10.9      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 199           |
| time/                   |               |
|    fps                  | 1339          |
|    iterations           | 135           |
|    time_elapsed         | 206           |
|    total_timesteps      | 276480        |
| train/                  |               |
|    approx_kl            | 7.4716227e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00103      |
|    explained_variance   | 0.969         |
|    learning_rate        | 0.0003        |
|    loss                 | 11.3          |
|    n_updates            | 1340          |
|    policy_gradient_loss | -2.55e-05     |
|    value_loss           | 12.4          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 198       |
| time/                   |           |
|    fps                  | 1339      |
|    iterations           | 136       |
|    time_elapsed         | 207       |
|    total_timesteps      | 278528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000956 |
|    explained_variance   | 0.974     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.24      |
|    n_updates            | 1350      |
|    policy_gradient_loss | -8.8e-09  |
|    value_loss           | 10.4      |
---------------------------------------
Eval num_timesteps=280000, episode_reward=201.63 +/- 18.60
Episode length: 223.20 +/- 2.32
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 223       |
|    mean_reward          | 202       |
| time/                   |           |
|    total_timesteps      | 280000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000989 |
|    explained_variance   | 0.977     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.82      |
|    n_updates            | 1360      |
|    policy_gradient_loss | -1.95e-09 |
|    value_loss           | 10.6      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 196      |
| time/              |          |
|    fps             | 1338     |
|    iterations      | 137      |
|    time_elapsed    | 209      |
|    total_timesteps | 280576   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 195       |
| time/                   |           |
|    fps                  | 1338      |
|    iterations           | 138       |
|    time_elapsed         | 211       |
|    total_timesteps      | 282624    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000958 |
|    explained_variance   | 0.972     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.82      |
|    n_updates            | 1370      |
|    policy_gradient_loss | -2.65e-08 |
|    value_loss           | 11.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 195       |
| time/                   |           |
|    fps                  | 1338      |
|    iterations           | 139       |
|    time_elapsed         | 212       |
|    total_timesteps      | 284672    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000959 |
|    explained_variance   | 0.97      |
|    learning_rate        | 0.0003    |
|    loss                 | 8.95      |
|    n_updates            | 1380      |
|    policy_gradient_loss | -5.84e-09 |
|    value_loss           | 13.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 195       |
| time/                   |           |
|    fps                  | 1338      |
|    iterations           | 140       |
|    time_elapsed         | 214       |
|    total_timesteps      | 286720    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000965 |
|    explained_variance   | 0.971     |
|    learning_rate        | 0.0003    |
|    loss                 | 5.85      |
|    n_updates            | 1390      |
|    policy_gradient_loss | -2.51e-08 |
|    value_loss           | 11.8      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 194       |
| time/                   |           |
|    fps                  | 1339      |
|    iterations           | 141       |
|    time_elapsed         | 215       |
|    total_timesteps      | 288768    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.001    |
|    explained_variance   | 0.975     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.92      |
|    n_updates            | 1400      |
|    policy_gradient_loss | -1.13e-07 |
|    value_loss           | 10.4      |
---------------------------------------
Eval num_timesteps=290000, episode_reward=190.05 +/- 23.10
Episode length: 220.60 +/- 2.42
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 221       |
|    mean_reward          | 190       |
| time/                   |           |
|    total_timesteps      | 290000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000981 |
|    explained_variance   | 0.973     |
|    learning_rate        | 0.0003    |
|    loss                 | 10.2      |
|    n_updates            | 1410      |
|    policy_gradient_loss | -1.1e-07  |
|    value_loss           | 10.9      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 193      |
| time/              |          |
|    fps             | 1336     |
|    iterations      | 142      |
|    time_elapsed    | 217      |
|    total_timesteps | 290816   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 195           |
| time/                   |               |
|    fps                  | 1337          |
|    iterations           | 143           |
|    time_elapsed         | 219           |
|    total_timesteps      | 292864        |
| train/                  |               |
|    approx_kl            | 2.9754592e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.000947     |
|    explained_variance   | 0.974         |
|    learning_rate        | 0.0003        |
|    loss                 | 5.54          |
|    n_updates            | 1420          |
|    policy_gradient_loss | -1.83e-05     |
|    value_loss           | 10.2          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 197       |
| time/                   |           |
|    fps                  | 1337      |
|    iterations           | 144       |
|    time_elapsed         | 220       |
|    total_timesteps      | 294912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000932 |
|    explained_variance   | 0.983     |
|    learning_rate        | 0.0003    |
|    loss                 | 7.54      |
|    n_updates            | 1430      |
|    policy_gradient_loss | -1.25e-08 |
|    value_loss           | 8.66      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 198       |
| time/                   |           |
|    fps                  | 1336      |
|    iterations           | 145       |
|    time_elapsed         | 222       |
|    total_timesteps      | 296960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000929 |
|    explained_variance   | 0.978     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.83      |
|    n_updates            | 1440      |
|    policy_gradient_loss | -7.72e-09 |
|    value_loss           | 10.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 197       |
| time/                   |           |
|    fps                  | 1337      |
|    iterations           | 146       |
|    time_elapsed         | 223       |
|    total_timesteps      | 299008    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000926 |
|    explained_variance   | 0.962     |
|    learning_rate        | 0.0003    |
|    loss                 | 4         |
|    n_updates            | 1450      |
|    policy_gradient_loss | -3.78e-07 |
|    value_loss           | 9.56      |
---------------------------------------
Eval num_timesteps=300000, episode_reward=206.94 +/- 18.46
Episode length: 220.40 +/- 3.50
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 220       |
|    mean_reward          | 207       |
| time/                   |           |
|    total_timesteps      | 300000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000941 |
|    explained_variance   | 0.961     |
|    learning_rate        | 0.0003    |
|    loss                 | 7.81      |
|    n_updates            | 1460      |
|    policy_gradient_loss | -2.27e-07 |
|    value_loss           | 10.6      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 198      |
| time/              |          |
|    fps             | 1335     |
|    iterations      | 147      |
|    time_elapsed    | 225      |
|    total_timesteps | 301056   |
---------------------------------

Training complete!
Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-08_23-58-40

