Run directory: /home/cris/hierarchical_rl_robotaxi/logs/2025-12-08_10-21-13

Map saved at: /home/cris/hierarchical_rl_robotaxi/logs/2025-12-08_10-21-13/map_visualization.png

Using cpu device
Wrapping the env in a DummyVecEnv.
Logging to /home/cris/hierarchical_rl_robotaxi/logs/2025-12-08_10-21-13/tensorboard/PPO_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 183      |
|    ep_rew_mean     | 96.1     |
| time/              |          |
|    fps             | 4004     |
|    iterations      | 1        |
|    time_elapsed    | 0        |
|    total_timesteps | 2048     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 187         |
|    ep_rew_mean          | 104         |
| time/                   |             |
|    fps                  | 259         |
|    iterations           | 2           |
|    time_elapsed         | 15          |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.012763349 |
|    clip_fraction        | 0.0287      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.683      |
|    explained_variance   | 0.00385     |
|    learning_rate        | 0.0003      |
|    loss                 | 33          |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00452    |
|    value_loss           | 97.8        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 186         |
|    ep_rew_mean          | 103         |
| time/                   |             |
|    fps                  | 186         |
|    iterations           | 3           |
|    time_elapsed         | 32          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.010249543 |
|    clip_fraction        | 0.0182      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.689      |
|    explained_variance   | 0.134       |
|    learning_rate        | 0.0003      |
|    loss                 | 24.6        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00159    |
|    value_loss           | 82.5        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 181         |
|    ep_rew_mean          | 100         |
| time/                   |             |
|    fps                  | 169         |
|    iterations           | 4           |
|    time_elapsed         | 48          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.008524988 |
|    clip_fraction        | 0.0183      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.684      |
|    explained_variance   | 0.104       |
|    learning_rate        | 0.0003      |
|    loss                 | 18.1        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00333    |
|    value_loss           | 121         |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=75.29 +/- 44.07
Episode length: 173.60 +/- 47.47
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 174         |
|    mean_reward          | 75.3        |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.010658659 |
|    clip_fraction        | 0.0166      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.669      |
|    explained_variance   | 0.0955      |
|    learning_rate        | 0.0003      |
|    loss                 | 29.6        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00224    |
|    value_loss           | 113         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 181      |
|    ep_rew_mean     | 99.5     |
| time/              |          |
|    fps             | 153      |
|    iterations      | 5        |
|    time_elapsed    | 66       |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 177         |
|    ep_rew_mean          | 92.7        |
| time/                   |             |
|    fps                  | 149         |
|    iterations           | 6           |
|    time_elapsed         | 82          |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.010390308 |
|    clip_fraction        | 0.0597      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.68       |
|    explained_variance   | 0.212       |
|    learning_rate        | 0.0003      |
|    loss                 | 40          |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00544    |
|    value_loss           | 130         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 177          |
|    ep_rew_mean          | 93.4         |
| time/                   |              |
|    fps                  | 144          |
|    iterations           | 7            |
|    time_elapsed         | 99           |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 0.0052719954 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.674       |
|    explained_variance   | 0.309        |
|    learning_rate        | 0.0003       |
|    loss                 | 44.7         |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00157     |
|    value_loss           | 170          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 178         |
|    ep_rew_mean          | 94.5        |
| time/                   |             |
|    fps                  | 141         |
|    iterations           | 8           |
|    time_elapsed         | 116         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.009986368 |
|    clip_fraction        | 0.0491      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.675      |
|    explained_variance   | 0.311       |
|    learning_rate        | 0.0003      |
|    loss                 | 68.5        |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00336    |
|    value_loss           | 134         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 179          |
|    ep_rew_mean          | 96.7         |
| time/                   |              |
|    fps                  | 132          |
|    iterations           | 9            |
|    time_elapsed         | 139          |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0056006266 |
|    clip_fraction        | 0.00435      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.674       |
|    explained_variance   | 0.36         |
|    learning_rate        | 0.0003       |
|    loss                 | 59.1         |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00206     |
|    value_loss           | 113          |
------------------------------------------
Eval num_timesteps=20000, episode_reward=209.43 +/- 1.65
Episode length: 222.20 +/- 2.48
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 222         |
|    mean_reward          | 209         |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.009732338 |
|    clip_fraction        | 0.024       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.669      |
|    explained_variance   | 0.316       |
|    learning_rate        | 0.0003      |
|    loss                 | 87.6        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00134    |
|    value_loss           | 135         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 178      |
|    ep_rew_mean     | 96.1     |
| time/              |          |
|    fps             | 130      |
|    iterations      | 10       |
|    time_elapsed    | 157      |
|    total_timesteps | 20480    |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 173       |
|    ep_rew_mean          | 90.3      |
| time/                   |           |
|    fps                  | 126       |
|    iterations           | 11        |
|    time_elapsed         | 177       |
|    total_timesteps      | 22528     |
| train/                  |           |
|    approx_kl            | 0.0109209 |
|    clip_fraction        | 0.0537    |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.638    |
|    explained_variance   | 0.434     |
|    learning_rate        | 0.0003    |
|    loss                 | 60.6      |
|    n_updates            | 100       |
|    policy_gradient_loss | -0.00556  |
|    value_loss           | 106       |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 174          |
|    ep_rew_mean          | 91.5         |
| time/                   |              |
|    fps                  | 125          |
|    iterations           | 12           |
|    time_elapsed         | 195          |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0033887883 |
|    clip_fraction        | 0.0107       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.648       |
|    explained_variance   | 0.392        |
|    learning_rate        | 0.0003       |
|    loss                 | 92.3         |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00125     |
|    value_loss           | 166          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 174          |
|    ep_rew_mean          | 91.9         |
| time/                   |              |
|    fps                  | 126          |
|    iterations           | 13           |
|    time_elapsed         | 210          |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0077887117 |
|    clip_fraction        | 0.0352       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.663       |
|    explained_variance   | 0.57         |
|    learning_rate        | 0.0003       |
|    loss                 | 53.4         |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00593     |
|    value_loss           | 117          |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 175        |
|    ep_rew_mean          | 94.7       |
| time/                   |            |
|    fps                  | 125        |
|    iterations           | 14         |
|    time_elapsed         | 227        |
|    total_timesteps      | 28672      |
| train/                  |            |
|    approx_kl            | 0.00990148 |
|    clip_fraction        | 0.00981    |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.667     |
|    explained_variance   | 0.429      |
|    learning_rate        | 0.0003     |
|    loss                 | 74.5       |
|    n_updates            | 130        |
|    policy_gradient_loss | -0.00084   |
|    value_loss           | 138        |
----------------------------------------
Eval num_timesteps=30000, episode_reward=181.07 +/- 4.48
Episode length: 221.00 +/- 3.35
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 221          |
|    mean_reward          | 181          |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0027579528 |
|    clip_fraction        | 0.002        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.662       |
|    explained_variance   | 0.415        |
|    learning_rate        | 0.0003       |
|    loss                 | 29.7         |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.0007      |
|    value_loss           | 105          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 178      |
|    ep_rew_mean     | 99       |
| time/              |          |
|    fps             | 126      |
|    iterations      | 15       |
|    time_elapsed    | 243      |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 176          |
|    ep_rew_mean          | 97.9         |
| time/                   |              |
|    fps                  | 125          |
|    iterations           | 16           |
|    time_elapsed         | 261          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0028273342 |
|    clip_fraction        | 0.0104       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.663       |
|    explained_variance   | 0.465        |
|    learning_rate        | 0.0003       |
|    loss                 | 41.6         |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.0016      |
|    value_loss           | 96.2         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 176         |
|    ep_rew_mean          | 98.4        |
| time/                   |             |
|    fps                  | 125         |
|    iterations           | 17          |
|    time_elapsed         | 277         |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.012350738 |
|    clip_fraction        | 0.0207      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.651      |
|    explained_variance   | 0.458       |
|    learning_rate        | 0.0003      |
|    loss                 | 47.7        |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.00287    |
|    value_loss           | 114         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 178          |
|    ep_rew_mean          | 101          |
| time/                   |              |
|    fps                  | 125          |
|    iterations           | 18           |
|    time_elapsed         | 294          |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 0.0031745285 |
|    clip_fraction        | 0.00879      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.66        |
|    explained_variance   | 0.515        |
|    learning_rate        | 0.0003       |
|    loss                 | 21.8         |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00182     |
|    value_loss           | 82.8         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 180         |
|    ep_rew_mean          | 103         |
| time/                   |             |
|    fps                  | 125         |
|    iterations           | 19          |
|    time_elapsed         | 309         |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.007905093 |
|    clip_fraction        | 0.043       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.663      |
|    explained_variance   | 0.612       |
|    learning_rate        | 0.0003      |
|    loss                 | 12.7        |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00106    |
|    value_loss           | 58.5        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=200.60 +/- 3.90
Episode length: 221.80 +/- 3.43
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 222         |
|    mean_reward          | 201         |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.009315582 |
|    clip_fraction        | 0.0377      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.652      |
|    explained_variance   | 0.531       |
|    learning_rate        | 0.0003      |
|    loss                 | 40.2        |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.00281    |
|    value_loss           | 93.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | 109      |
| time/              |          |
|    fps             | 125      |
|    iterations      | 20       |
|    time_elapsed    | 326      |
|    total_timesteps | 40960    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 188         |
|    ep_rew_mean          | 111         |
| time/                   |             |
|    fps                  | 125         |
|    iterations           | 21          |
|    time_elapsed         | 342         |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.009241253 |
|    clip_fraction        | 0.0542      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.637      |
|    explained_variance   | 0.732       |
|    learning_rate        | 0.0003      |
|    loss                 | 18.7        |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.0046     |
|    value_loss           | 55.5        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 188         |
|    ep_rew_mean          | 112         |
| time/                   |             |
|    fps                  | 125         |
|    iterations           | 22          |
|    time_elapsed         | 358         |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.007496631 |
|    clip_fraction        | 0.0415      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.644      |
|    explained_variance   | 0.618       |
|    learning_rate        | 0.0003      |
|    loss                 | 61.7        |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.00312    |
|    value_loss           | 109         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 189          |
|    ep_rew_mean          | 111          |
| time/                   |              |
|    fps                  | 124          |
|    iterations           | 23           |
|    time_elapsed         | 377          |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 0.0033249976 |
|    clip_fraction        | 0.0125       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.651       |
|    explained_variance   | 0.485        |
|    learning_rate        | 0.0003       |
|    loss                 | 82.8         |
|    n_updates            | 220          |
|    policy_gradient_loss | -0.00224     |
|    value_loss           | 118          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 187         |
|    ep_rew_mean          | 108         |
| time/                   |             |
|    fps                  | 123         |
|    iterations           | 24          |
|    time_elapsed         | 397         |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.004671885 |
|    clip_fraction        | 0.0117      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.639      |
|    explained_variance   | 0.605       |
|    learning_rate        | 0.0003      |
|    loss                 | 25.9        |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.00388    |
|    value_loss           | 120         |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=200.82 +/- 4.67
Episode length: 219.80 +/- 3.06
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 220          |
|    mean_reward          | 201          |
| time/                   |              |
|    total_timesteps      | 50000        |
| train/                  |              |
|    approx_kl            | 0.0024366858 |
|    clip_fraction        | 0.00737      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.621       |
|    explained_variance   | 0.691        |
|    learning_rate        | 0.0003       |
|    loss                 | 58.1         |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.00238     |
|    value_loss           | 115          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 190      |
|    ep_rew_mean     | 109      |
| time/              |          |
|    fps             | 123      |
|    iterations      | 25       |
|    time_elapsed    | 413      |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 192         |
|    ep_rew_mean          | 113         |
| time/                   |             |
|    fps                  | 123         |
|    iterations           | 26          |
|    time_elapsed         | 429         |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.006579913 |
|    clip_fraction        | 0.0371      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.602      |
|    explained_variance   | 0.762       |
|    learning_rate        | 0.0003      |
|    loss                 | 20.7        |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00363    |
|    value_loss           | 59.9        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 193         |
|    ep_rew_mean          | 114         |
| time/                   |             |
|    fps                  | 124         |
|    iterations           | 27          |
|    time_elapsed         | 445         |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.003621004 |
|    clip_fraction        | 0.0268      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.567      |
|    explained_variance   | 0.862       |
|    learning_rate        | 0.0003      |
|    loss                 | 16.8        |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.00142    |
|    value_loss           | 28.2        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 191         |
|    ep_rew_mean          | 113         |
| time/                   |             |
|    fps                  | 124         |
|    iterations           | 28          |
|    time_elapsed         | 461         |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.001395187 |
|    clip_fraction        | 0.00693     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.555      |
|    explained_variance   | 0.748       |
|    learning_rate        | 0.0003      |
|    loss                 | 24.8        |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.000901   |
|    value_loss           | 38.1        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 189          |
|    ep_rew_mean          | 112          |
| time/                   |              |
|    fps                  | 123          |
|    iterations           | 29           |
|    time_elapsed         | 479          |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 0.0044352347 |
|    clip_fraction        | 0.0155       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.542       |
|    explained_variance   | 0.669        |
|    learning_rate        | 0.0003       |
|    loss                 | 42.7         |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.00125     |
|    value_loss           | 71.1         |
------------------------------------------
Eval num_timesteps=60000, episode_reward=209.95 +/- 3.85
Episode length: 222.40 +/- 2.87
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 222          |
|    mean_reward          | 210          |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0017195535 |
|    clip_fraction        | 0.00776      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.524       |
|    explained_variance   | 0.671        |
|    learning_rate        | 0.0003       |
|    loss                 | 79.8         |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.0015      |
|    value_loss           | 99.7         |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 189      |
|    ep_rew_mean     | 115      |
| time/              |          |
|    fps             | 123      |
|    iterations      | 30       |
|    time_elapsed    | 497      |
|    total_timesteps | 61440    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 187          |
|    ep_rew_mean          | 113          |
| time/                   |              |
|    fps                  | 123          |
|    iterations           | 31           |
|    time_elapsed         | 514          |
|    total_timesteps      | 63488        |
| train/                  |              |
|    approx_kl            | 0.0035992465 |
|    clip_fraction        | 0.0219       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.499       |
|    explained_variance   | 0.706        |
|    learning_rate        | 0.0003       |
|    loss                 | 47.9         |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.00443     |
|    value_loss           | 79.7         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 187          |
|    ep_rew_mean          | 116          |
| time/                   |              |
|    fps                  | 122          |
|    iterations           | 32           |
|    time_elapsed         | 534          |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0030782265 |
|    clip_fraction        | 0.0138       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.494       |
|    explained_variance   | 0.558        |
|    learning_rate        | 0.0003       |
|    loss                 | 67.3         |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.00373     |
|    value_loss           | 131          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 188          |
|    ep_rew_mean          | 119          |
| time/                   |              |
|    fps                  | 122          |
|    iterations           | 33           |
|    time_elapsed         | 549          |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 0.0055580465 |
|    clip_fraction        | 0.0292       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.454       |
|    explained_variance   | 0.592        |
|    learning_rate        | 0.0003       |
|    loss                 | 87.3         |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00245     |
|    value_loss           | 140          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 187         |
|    ep_rew_mean          | 120         |
| time/                   |             |
|    fps                  | 122         |
|    iterations           | 34          |
|    time_elapsed         | 567         |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.002208165 |
|    clip_fraction        | 0.0041      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.416      |
|    explained_variance   | 0.655       |
|    learning_rate        | 0.0003      |
|    loss                 | 15.3        |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.000978   |
|    value_loss           | 83.4        |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=209.02 +/- 3.25
Episode length: 221.60 +/- 3.14
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 222          |
|    mean_reward          | 209          |
| time/                   |              |
|    total_timesteps      | 70000        |
| train/                  |              |
|    approx_kl            | 0.0017601782 |
|    clip_fraction        | 0.0176       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.406       |
|    explained_variance   | 0.644        |
|    learning_rate        | 0.0003       |
|    loss                 | 42.1         |
|    n_updates            | 340          |
|    policy_gradient_loss | -0.00139     |
|    value_loss           | 100          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 187      |
|    ep_rew_mean     | 121      |
| time/              |          |
|    fps             | 122      |
|    iterations      | 35       |
|    time_elapsed    | 585      |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 186         |
|    ep_rew_mean          | 120         |
| time/                   |             |
|    fps                  | 121         |
|    iterations           | 36          |
|    time_elapsed         | 605         |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.008605929 |
|    clip_fraction        | 0.0646      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.378      |
|    explained_variance   | 0.727       |
|    learning_rate        | 0.0003      |
|    loss                 | 8.81        |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00556    |
|    value_loss           | 39.4        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 186          |
|    ep_rew_mean          | 122          |
| time/                   |              |
|    fps                  | 121          |
|    iterations           | 37           |
|    time_elapsed         | 626          |
|    total_timesteps      | 75776        |
| train/                  |              |
|    approx_kl            | 0.0038999892 |
|    clip_fraction        | 0.0582       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.327       |
|    explained_variance   | 0.84         |
|    learning_rate        | 0.0003       |
|    loss                 | 17.7         |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.00534     |
|    value_loss           | 42           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 188          |
|    ep_rew_mean          | 126          |
| time/                   |              |
|    fps                  | 120          |
|    iterations           | 38           |
|    time_elapsed         | 644          |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 0.0011736813 |
|    clip_fraction        | 0.0064       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.305       |
|    explained_variance   | 0.444        |
|    learning_rate        | 0.0003       |
|    loss                 | 51.1         |
|    n_updates            | 370          |
|    policy_gradient_loss | -0.00357     |
|    value_loss           | 125          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 191          |
|    ep_rew_mean          | 131          |
| time/                   |              |
|    fps                  | 120          |
|    iterations           | 39           |
|    time_elapsed         | 662          |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 0.0017384718 |
|    clip_fraction        | 0.0239       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.271       |
|    explained_variance   | 0.703        |
|    learning_rate        | 0.0003       |
|    loss                 | 20.3         |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.00184     |
|    value_loss           | 75.2         |
------------------------------------------
Eval num_timesteps=80000, episode_reward=207.13 +/- 4.56
Episode length: 218.80 +/- 3.25
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 219          |
|    mean_reward          | 207          |
| time/                   |              |
|    total_timesteps      | 80000        |
| train/                  |              |
|    approx_kl            | 0.0037798353 |
|    clip_fraction        | 0.0325       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.256       |
|    explained_variance   | 0.732        |
|    learning_rate        | 0.0003       |
|    loss                 | 14.4         |
|    n_updates            | 390          |
|    policy_gradient_loss | -0.00297     |
|    value_loss           | 67           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 193      |
|    ep_rew_mean     | 134      |
| time/              |          |
|    fps             | 120      |
|    iterations      | 40       |
|    time_elapsed    | 681      |
|    total_timesteps | 81920    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 194          |
|    ep_rew_mean          | 138          |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 41           |
|    time_elapsed         | 700          |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 0.0022668159 |
|    clip_fraction        | 0.0289       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.24        |
|    explained_variance   | 0.722        |
|    learning_rate        | 0.0003       |
|    loss                 | 24.7         |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00412     |
|    value_loss           | 65.9         |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 198        |
|    ep_rew_mean          | 146        |
| time/                   |            |
|    fps                  | 119        |
|    iterations           | 42         |
|    time_elapsed         | 718        |
|    total_timesteps      | 86016      |
| train/                  |            |
|    approx_kl            | 0.01010327 |
|    clip_fraction        | 0.0278     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.24      |
|    explained_variance   | 0.787      |
|    learning_rate        | 0.0003     |
|    loss                 | 27.3       |
|    n_updates            | 410        |
|    policy_gradient_loss | -0.00268   |
|    value_loss           | 58.6       |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 200          |
|    ep_rew_mean          | 151          |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 43           |
|    time_elapsed         | 735          |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 0.0008658508 |
|    clip_fraction        | 0.0127       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.199       |
|    explained_variance   | 0.701        |
|    learning_rate        | 0.0003       |
|    loss                 | 40.8         |
|    n_updates            | 420          |
|    policy_gradient_loss | -0.00174     |
|    value_loss           | 72.9         |
------------------------------------------
Eval num_timesteps=90000, episode_reward=134.85 +/- 2.40
Episode length: 189.80 +/- 3.37
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 190         |
|    mean_reward          | 135         |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.006374234 |
|    clip_fraction        | 0.0309      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.159      |
|    explained_variance   | 0.856       |
|    learning_rate        | 0.0003      |
|    loss                 | 23.9        |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.00292    |
|    value_loss           | 44.5        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 202      |
|    ep_rew_mean     | 157      |
| time/              |          |
|    fps             | 119      |
|    iterations      | 44       |
|    time_elapsed    | 752      |
|    total_timesteps | 90112    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 203          |
|    ep_rew_mean          | 161          |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 45           |
|    time_elapsed         | 770          |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0012662254 |
|    clip_fraction        | 0.0221       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.159       |
|    explained_variance   | 0.829        |
|    learning_rate        | 0.0003       |
|    loss                 | 56.9         |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00304     |
|    value_loss           | 59.8         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 203         |
|    ep_rew_mean          | 165         |
| time/                   |             |
|    fps                  | 119         |
|    iterations           | 46          |
|    time_elapsed         | 787         |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.005357268 |
|    clip_fraction        | 0.0117      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.143      |
|    explained_variance   | 0.979       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.611       |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.0019     |
|    value_loss           | 3.72        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 207          |
|    ep_rew_mean          | 173          |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 47           |
|    time_elapsed         | 803          |
|    total_timesteps      | 96256        |
| train/                  |              |
|    approx_kl            | 0.0005883677 |
|    clip_fraction        | 0.00732      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.123       |
|    explained_variance   | 0.938        |
|    learning_rate        | 0.0003       |
|    loss                 | 13.4         |
|    n_updates            | 460          |
|    policy_gradient_loss | -0.00138     |
|    value_loss           | 19.1         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 209          |
|    ep_rew_mean          | 178          |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 48           |
|    time_elapsed         | 822          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 0.0016121801 |
|    clip_fraction        | 0.0184       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0886      |
|    explained_variance   | 0.936        |
|    learning_rate        | 0.0003       |
|    loss                 | 3.4          |
|    n_updates            | 470          |
|    policy_gradient_loss | -0.00274     |
|    value_loss           | 24.9         |
------------------------------------------
Eval num_timesteps=100000, episode_reward=135.64 +/- 2.69
Episode length: 191.60 +/- 3.83
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 192          |
|    mean_reward          | 136          |
| time/                   |              |
|    total_timesteps      | 100000       |
| train/                  |              |
|    approx_kl            | 0.0012313996 |
|    clip_fraction        | 0.00972      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0867      |
|    explained_variance   | 0.993        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.922        |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.000539    |
|    value_loss           | 1.93         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 212      |
|    ep_rew_mean     | 184      |
| time/              |          |
|    fps             | 119      |
|    iterations      | 49       |
|    time_elapsed    | 838      |
|    total_timesteps | 100352   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 213          |
|    ep_rew_mean          | 188          |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 50           |
|    time_elapsed         | 856          |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 0.0014615798 |
|    clip_fraction        | 0.0151       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0866      |
|    explained_variance   | 0.995        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.766        |
|    n_updates            | 490          |
|    policy_gradient_loss | -0.00124     |
|    value_loss           | 1.86         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 216          |
|    ep_rew_mean          | 195          |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 51           |
|    time_elapsed         | 873          |
|    total_timesteps      | 104448       |
| train/                  |              |
|    approx_kl            | 0.0007291627 |
|    clip_fraction        | 0.0101       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0695      |
|    explained_variance   | 0.997        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.606        |
|    n_updates            | 500          |
|    policy_gradient_loss | -0.00117     |
|    value_loss           | 1.56         |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 217        |
|    ep_rew_mean          | 196        |
| time/                   |            |
|    fps                  | 119        |
|    iterations           | 52         |
|    time_elapsed         | 890        |
|    total_timesteps      | 106496     |
| train/                  |            |
|    approx_kl            | 0.01574016 |
|    clip_fraction        | 0.0125     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.103     |
|    explained_variance   | 0.954      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.838      |
|    n_updates            | 510        |
|    policy_gradient_loss | -0.000992  |
|    value_loss           | 12.1       |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 218          |
|    ep_rew_mean          | 198          |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 53           |
|    time_elapsed         | 907          |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 0.0011860633 |
|    clip_fraction        | 0.0186       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.108       |
|    explained_variance   | 0.959        |
|    learning_rate        | 0.0003       |
|    loss                 | 5.84         |
|    n_updates            | 520          |
|    policy_gradient_loss | -0.00174     |
|    value_loss           | 19.1         |
------------------------------------------
Eval num_timesteps=110000, episode_reward=134.63 +/- 1.59
Episode length: 188.60 +/- 1.62
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 189          |
|    mean_reward          | 135          |
| time/                   |              |
|    total_timesteps      | 110000       |
| train/                  |              |
|    approx_kl            | 0.0029835405 |
|    clip_fraction        | 0.0297       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.118       |
|    explained_variance   | 0.993        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.431        |
|    n_updates            | 530          |
|    policy_gradient_loss | -0.0031      |
|    value_loss           | 1.68         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 220      |
|    ep_rew_mean     | 201      |
| time/              |          |
|    fps             | 119      |
|    iterations      | 54       |
|    time_elapsed    | 925      |
|    total_timesteps | 110592   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 200          |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 55           |
|    time_elapsed         | 941          |
|    total_timesteps      | 112640       |
| train/                  |              |
|    approx_kl            | 0.0006243475 |
|    clip_fraction        | 0.0122       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.115       |
|    explained_variance   | 0.975        |
|    learning_rate        | 0.0003       |
|    loss                 | 7.49         |
|    n_updates            | 540          |
|    policy_gradient_loss | -0.000996    |
|    value_loss           | 12.8         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 200          |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 56           |
|    time_elapsed         | 959          |
|    total_timesteps      | 114688       |
| train/                  |              |
|    approx_kl            | 0.0013488524 |
|    clip_fraction        | 0.0149       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.101       |
|    explained_variance   | 0.91         |
|    learning_rate        | 0.0003       |
|    loss                 | 27.1         |
|    n_updates            | 550          |
|    policy_gradient_loss | -0.00402     |
|    value_loss           | 49.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 201          |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 57           |
|    time_elapsed         | 975          |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 0.0014308192 |
|    clip_fraction        | 0.0155       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0998      |
|    explained_variance   | 0.98         |
|    learning_rate        | 0.0003       |
|    loss                 | 1.16         |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.00141     |
|    value_loss           | 3.38         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 201          |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 58           |
|    time_elapsed         | 993          |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 0.0010583161 |
|    clip_fraction        | 0.01         |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0929      |
|    explained_variance   | 0.993        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.34         |
|    n_updates            | 570          |
|    policy_gradient_loss | -0.00114     |
|    value_loss           | 1.95         |
------------------------------------------
Eval num_timesteps=120000, episode_reward=131.41 +/- 2.54
Episode length: 188.00 +/- 2.61
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 188          |
|    mean_reward          | 131          |
| time/                   |              |
|    total_timesteps      | 120000       |
| train/                  |              |
|    approx_kl            | 0.0012055998 |
|    clip_fraction        | 0.0112       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.107       |
|    explained_variance   | 0.97         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.98         |
|    n_updates            | 580          |
|    policy_gradient_loss | 0.000204     |
|    value_loss           | 11.2         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 219      |
|    ep_rew_mean     | 201      |
| time/              |          |
|    fps             | 119      |
|    iterations      | 59       |
|    time_elapsed    | 1010     |
|    total_timesteps | 120832   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 201          |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 60           |
|    time_elapsed         | 1028         |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 0.0010056461 |
|    clip_fraction        | 0.0114       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0573      |
|    explained_variance   | 0.994        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.33         |
|    n_updates            | 590          |
|    policy_gradient_loss | -0.000658    |
|    value_loss           | 1.61         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 219           |
|    ep_rew_mean          | 202           |
| time/                   |               |
|    fps                  | 119           |
|    iterations           | 61            |
|    time_elapsed         | 1044          |
|    total_timesteps      | 124928        |
| train/                  |               |
|    approx_kl            | 0.00062502694 |
|    clip_fraction        | 0.0119        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0611       |
|    explained_variance   | 0.997         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.278         |
|    n_updates            | 600           |
|    policy_gradient_loss | 0.000537      |
|    value_loss           | 1.02          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 220          |
|    ep_rew_mean          | 203          |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 62           |
|    time_elapsed         | 1062         |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 0.0037003667 |
|    clip_fraction        | 0.0143       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0767      |
|    explained_variance   | 0.998        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.446        |
|    n_updates            | 610          |
|    policy_gradient_loss | -0.000866    |
|    value_loss           | 0.761        |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 220        |
|    ep_rew_mean          | 203        |
| time/                   |            |
|    fps                  | 119        |
|    iterations           | 63         |
|    time_elapsed         | 1081       |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 0.00883792 |
|    clip_fraction        | 0.0127     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.102     |
|    explained_variance   | 0.975      |
|    learning_rate        | 0.0003     |
|    loss                 | 11.3       |
|    n_updates            | 620        |
|    policy_gradient_loss | -0.00318   |
|    value_loss           | 11.5       |
----------------------------------------
Eval num_timesteps=130000, episode_reward=135.31 +/- 3.21
Episode length: 190.60 +/- 2.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 191         |
|    mean_reward          | 135         |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.001917484 |
|    clip_fraction        | 0.0244      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0763     |
|    explained_variance   | 0.998       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.701       |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.00114    |
|    value_loss           | 0.651       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 220      |
|    ep_rew_mean     | 203      |
| time/              |          |
|    fps             | 119      |
|    iterations      | 64       |
|    time_elapsed    | 1098     |
|    total_timesteps | 131072   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 206          |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 65           |
|    time_elapsed         | 1116         |
|    total_timesteps      | 133120       |
| train/                  |              |
|    approx_kl            | 0.0050699473 |
|    clip_fraction        | 0.0413       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0646      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.174        |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.00563     |
|    value_loss           | 0.607        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 207         |
| time/                   |             |
|    fps                  | 119         |
|    iterations           | 66          |
|    time_elapsed         | 1133        |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.002535793 |
|    clip_fraction        | 0.00986     |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0738     |
|    explained_variance   | 0.998       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.191       |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.00178    |
|    value_loss           | 0.771       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 119          |
|    iterations           | 67           |
|    time_elapsed         | 1151         |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 0.0029564938 |
|    clip_fraction        | 0.0202       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0534      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.104        |
|    n_updates            | 660          |
|    policy_gradient_loss | -0.00148     |
|    value_loss           | 0.656        |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 221        |
|    ep_rew_mean          | 208        |
| time/                   |            |
|    fps                  | 119        |
|    iterations           | 68         |
|    time_elapsed         | 1168       |
|    total_timesteps      | 139264     |
| train/                  |            |
|    approx_kl            | 0.00601203 |
|    clip_fraction        | 0.00986    |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0766    |
|    explained_variance   | 0.999      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.24       |
|    n_updates            | 670        |
|    policy_gradient_loss | 0.00125    |
|    value_loss           | 0.567      |
----------------------------------------
Eval num_timesteps=140000, episode_reward=177.47 +/- 36.25
Episode length: 209.40 +/- 11.64
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 209           |
|    mean_reward          | 177           |
| time/                   |               |
|    total_timesteps      | 140000        |
| train/                  |               |
|    approx_kl            | 0.00045804516 |
|    clip_fraction        | 0.00913       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0537       |
|    explained_variance   | 0.999         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.319         |
|    n_updates            | 680           |
|    policy_gradient_loss | -0.001        |
|    value_loss           | 0.553         |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 118      |
|    iterations      | 69       |
|    time_elapsed    | 1187     |
|    total_timesteps | 141312   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 209           |
| time/                   |               |
|    fps                  | 119           |
|    iterations           | 70            |
|    time_elapsed         | 1204          |
|    total_timesteps      | 143360        |
| train/                  |               |
|    approx_kl            | 0.00035746844 |
|    clip_fraction        | 0.00659       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0631       |
|    explained_variance   | 0.998         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.518         |
|    n_updates            | 690           |
|    policy_gradient_loss | -0.00191      |
|    value_loss           | 0.8           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 118          |
|    iterations           | 71           |
|    time_elapsed         | 1222         |
|    total_timesteps      | 145408       |
| train/                  |              |
|    approx_kl            | 0.0017936502 |
|    clip_fraction        | 0.0126       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0501      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.158        |
|    n_updates            | 700          |
|    policy_gradient_loss | 0.000142     |
|    value_loss           | 0.589        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 208         |
| time/                   |             |
|    fps                  | 119         |
|    iterations           | 72          |
|    time_elapsed         | 1238        |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.012046753 |
|    clip_fraction        | 0.0378      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.112      |
|    explained_variance   | 0.971       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.603       |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.00644    |
|    value_loss           | 10.4        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 118          |
|    iterations           | 73           |
|    time_elapsed         | 1256         |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 0.0064564804 |
|    clip_fraction        | 0.027        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0642      |
|    explained_variance   | 0.994        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.417        |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.00416     |
|    value_loss           | 1.57         |
------------------------------------------
Eval num_timesteps=150000, episode_reward=209.62 +/- 3.56
Episode length: 220.60 +/- 3.44
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 221         |
|    mean_reward          | 210         |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.001299432 |
|    clip_fraction        | 0.0173      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0695     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.357       |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.00121    |
|    value_loss           | 0.584       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 208      |
| time/              |          |
|    fps             | 118      |
|    iterations      | 74       |
|    time_elapsed    | 1274     |
|    total_timesteps | 151552   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 118          |
|    iterations           | 75           |
|    time_elapsed         | 1294         |
|    total_timesteps      | 153600       |
| train/                  |              |
|    approx_kl            | 0.0010335247 |
|    clip_fraction        | 0.00962      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0768      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.24         |
|    n_updates            | 740          |
|    policy_gradient_loss | -0.000289    |
|    value_loss           | 0.41         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 118          |
|    iterations           | 76           |
|    time_elapsed         | 1312         |
|    total_timesteps      | 155648       |
| train/                  |              |
|    approx_kl            | 0.0007240899 |
|    clip_fraction        | 0.0114       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.06        |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.344        |
|    n_updates            | 750          |
|    policy_gradient_loss | -0.00139     |
|    value_loss           | 0.551        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 208         |
| time/                   |             |
|    fps                  | 118         |
|    iterations           | 77          |
|    time_elapsed         | 1333        |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.008771307 |
|    clip_fraction        | 0.024       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.1        |
|    explained_variance   | 0.975       |
|    learning_rate        | 0.0003      |
|    loss                 | 14.1        |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.00286    |
|    value_loss           | 12          |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 207           |
| time/                   |               |
|    fps                  | 118           |
|    iterations           | 78            |
|    time_elapsed         | 1353          |
|    total_timesteps      | 159744        |
| train/                  |               |
|    approx_kl            | 0.00052528444 |
|    clip_fraction        | 0.0146        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0808       |
|    explained_variance   | 0.999         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.116         |
|    n_updates            | 770           |
|    policy_gradient_loss | 6.56e-05      |
|    value_loss           | 0.46          |
-------------------------------------------
Eval num_timesteps=160000, episode_reward=196.81 +/- 32.17
Episode length: 215.40 +/- 12.75
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 215         |
|    mean_reward          | 197         |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.001450913 |
|    clip_fraction        | 0.0126      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0834     |
|    explained_variance   | 0.976       |
|    learning_rate        | 0.0003      |
|    loss                 | 7.48        |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.00133    |
|    value_loss           | 11          |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 207      |
| time/              |          |
|    fps             | 117      |
|    iterations      | 79       |
|    time_elapsed    | 1371     |
|    total_timesteps | 161792   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 220          |
|    ep_rew_mean          | 206          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 80           |
|    time_elapsed         | 1390         |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 0.0027712027 |
|    clip_fraction        | 0.0115       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0909      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.142        |
|    n_updates            | 790          |
|    policy_gradient_loss | 0.0012       |
|    value_loss           | 0.36         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 207         |
| time/                   |             |
|    fps                  | 117         |
|    iterations           | 81          |
|    time_elapsed         | 1407        |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.004070052 |
|    clip_fraction        | 0.0314      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0974     |
|    explained_variance   | 0.978       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.1         |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.00521    |
|    value_loss           | 9.88        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 207          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 82           |
|    time_elapsed         | 1424         |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 0.0016029017 |
|    clip_fraction        | 0.0298       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.088       |
|    explained_variance   | 0.997        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.155        |
|    n_updates            | 810          |
|    policy_gradient_loss | -0.00407     |
|    value_loss           | 0.445        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 207         |
| time/                   |             |
|    fps                  | 117         |
|    iterations           | 83          |
|    time_elapsed         | 1440        |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.006283002 |
|    clip_fraction        | 0.0164      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0818     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.296       |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.00367    |
|    value_loss           | 0.875       |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=214.07 +/- 2.39
Episode length: 222.00 +/- 2.97
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 222          |
|    mean_reward          | 214          |
| time/                   |              |
|    total_timesteps      | 170000       |
| train/                  |              |
|    approx_kl            | 0.0027803988 |
|    clip_fraction        | 0.0206       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.111       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.235        |
|    n_updates            | 830          |
|    policy_gradient_loss | -0.000798    |
|    value_loss           | 0.384        |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 207      |
| time/              |          |
|    fps             | 117      |
|    iterations      | 84       |
|    time_elapsed    | 1459     |
|    total_timesteps | 172032   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 206          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 85           |
|    time_elapsed         | 1476         |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 0.0009646699 |
|    clip_fraction        | 0.00806      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0799      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.646        |
|    n_updates            | 840          |
|    policy_gradient_loss | 1.24e-05     |
|    value_loss           | 0.32         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 206         |
| time/                   |             |
|    fps                  | 117         |
|    iterations           | 86          |
|    time_elapsed         | 1494        |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.007959278 |
|    clip_fraction        | 0.0282      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.114      |
|    explained_variance   | 0.963       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.97        |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.00509    |
|    value_loss           | 16          |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 207          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 87           |
|    time_elapsed         | 1510         |
|    total_timesteps      | 178176       |
| train/                  |              |
|    approx_kl            | 0.0052721915 |
|    clip_fraction        | 0.0161       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0755      |
|    explained_variance   | 0.996        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.45         |
|    n_updates            | 860          |
|    policy_gradient_loss | -0.00291     |
|    value_loss           | 0.834        |
------------------------------------------
Eval num_timesteps=180000, episode_reward=211.14 +/- 1.22
Episode length: 222.40 +/- 2.06
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 222           |
|    mean_reward          | 211           |
| time/                   |               |
|    total_timesteps      | 180000        |
| train/                  |               |
|    approx_kl            | 0.00034716184 |
|    clip_fraction        | 0.0105        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.066        |
|    explained_variance   | 0.999         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.19          |
|    n_updates            | 870           |
|    policy_gradient_loss | 0.000263      |
|    value_loss           | 0.598         |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 208      |
| time/              |          |
|    fps             | 117      |
|    iterations      | 88       |
|    time_elapsed    | 1529     |
|    total_timesteps | 180224   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 89           |
|    time_elapsed         | 1545         |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 0.0005856156 |
|    clip_fraction        | 0.00698      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0648      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.064        |
|    n_updates            | 880          |
|    policy_gradient_loss | -0.000256    |
|    value_loss           | 0.303        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 90           |
|    time_elapsed         | 1564         |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 0.0049123405 |
|    clip_fraction        | 0.0276       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0858      |
|    explained_variance   | 0.998        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0765       |
|    n_updates            | 890          |
|    policy_gradient_loss | -0.00452     |
|    value_loss           | 0.464        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 91           |
|    time_elapsed         | 1582         |
|    total_timesteps      | 186368       |
| train/                  |              |
|    approx_kl            | 0.0006274944 |
|    clip_fraction        | 0.00874      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0694      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0668       |
|    n_updates            | 900          |
|    policy_gradient_loss | -0.00035     |
|    value_loss           | 0.151        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 92           |
|    time_elapsed         | 1600         |
|    total_timesteps      | 188416       |
| train/                  |              |
|    approx_kl            | 0.0026093738 |
|    clip_fraction        | 0.0165       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0624      |
|    explained_variance   | 0.996        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.796        |
|    n_updates            | 910          |
|    policy_gradient_loss | -0.00124     |
|    value_loss           | 1.23         |
------------------------------------------
Eval num_timesteps=190000, episode_reward=209.04 +/- 1.79
Episode length: 220.20 +/- 2.93
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 220           |
|    mean_reward          | 209           |
| time/                   |               |
|    total_timesteps      | 190000        |
| train/                  |               |
|    approx_kl            | 0.00086180103 |
|    clip_fraction        | 0.0112        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0635       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.189         |
|    n_updates            | 920           |
|    policy_gradient_loss | -0.00205      |
|    value_loss           | 0.339         |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 208      |
| time/              |          |
|    fps             | 117      |
|    iterations      | 93       |
|    time_elapsed    | 1615     |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 208         |
| time/                   |             |
|    fps                  | 117         |
|    iterations           | 94          |
|    time_elapsed         | 1633        |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.003930975 |
|    clip_fraction        | 0.0313      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0721     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0754      |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.00655    |
|    value_loss           | 0.406       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 118          |
|    iterations           | 95           |
|    time_elapsed         | 1648         |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 0.0011629183 |
|    clip_fraction        | 0.0314       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.082       |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0907       |
|    n_updates            | 940          |
|    policy_gradient_loss | -0.000781    |
|    value_loss           | 0.309        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 208         |
| time/                   |             |
|    fps                  | 117         |
|    iterations           | 96          |
|    time_elapsed         | 1666        |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.004639522 |
|    clip_fraction        | 0.0188      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0548     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.113       |
|    n_updates            | 950         |
|    policy_gradient_loss | 0.00023     |
|    value_loss           | 0.161       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 118          |
|    iterations           | 97           |
|    time_elapsed         | 1682         |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 0.0033072212 |
|    clip_fraction        | 0.0234       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.102       |
|    explained_variance   | 0.974        |
|    learning_rate        | 0.0003       |
|    loss                 | 8.17         |
|    n_updates            | 960          |
|    policy_gradient_loss | -0.00515     |
|    value_loss           | 11.2         |
------------------------------------------
Eval num_timesteps=200000, episode_reward=207.56 +/- 2.28
Episode length: 220.20 +/- 2.56
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 220          |
|    mean_reward          | 208          |
| time/                   |              |
|    total_timesteps      | 200000       |
| train/                  |              |
|    approx_kl            | 0.0011464653 |
|    clip_fraction        | 0.0129       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0683      |
|    explained_variance   | 0.997        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.269        |
|    n_updates            | 970          |
|    policy_gradient_loss | 0.00278      |
|    value_loss           | 0.454        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 208      |
| time/              |          |
|    fps             | 117      |
|    iterations      | 98       |
|    time_elapsed    | 1702     |
|    total_timesteps | 200704   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 118          |
|    iterations           | 99           |
|    time_elapsed         | 1717         |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 0.0030718877 |
|    clip_fraction        | 0.0203       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0787      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0639       |
|    n_updates            | 980          |
|    policy_gradient_loss | -0.000483    |
|    value_loss           | 0.411        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 100          |
|    time_elapsed         | 1736         |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 0.0023156037 |
|    clip_fraction        | 0.0178       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0692      |
|    explained_variance   | 0.971        |
|    learning_rate        | 0.0003       |
|    loss                 | 2.73         |
|    n_updates            | 990          |
|    policy_gradient_loss | -0.0045      |
|    value_loss           | 11.6         |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 221        |
|    ep_rew_mean          | 208        |
| time/                   |            |
|    fps                  | 118        |
|    iterations           | 101        |
|    time_elapsed         | 1752       |
|    total_timesteps      | 206848     |
| train/                  |            |
|    approx_kl            | 0.04405323 |
|    clip_fraction        | 0.0361     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0877    |
|    explained_variance   | 0.997      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.405      |
|    n_updates            | 1000       |
|    policy_gradient_loss | -0.00574   |
|    value_loss           | 0.72       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 208         |
| time/                   |             |
|    fps                  | 118         |
|    iterations           | 102         |
|    time_elapsed         | 1770        |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.006076365 |
|    clip_fraction        | 0.0187      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0557     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.161       |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.000571   |
|    value_loss           | 0.437       |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=207.13 +/- 3.39
Episode length: 220.00 +/- 3.35
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 220          |
|    mean_reward          | 207          |
| time/                   |              |
|    total_timesteps      | 210000       |
| train/                  |              |
|    approx_kl            | 0.0007227374 |
|    clip_fraction        | 0.00747      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0566      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.149        |
|    n_updates            | 1020         |
|    policy_gradient_loss | -0.00108     |
|    value_loss           | 0.305        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 208      |
| time/              |          |
|    fps             | 118      |
|    iterations      | 103      |
|    time_elapsed    | 1785     |
|    total_timesteps | 210944   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 118          |
|    iterations           | 104          |
|    time_elapsed         | 1803         |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 0.0012853942 |
|    clip_fraction        | 0.00498      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0486      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.16         |
|    n_updates            | 1030         |
|    policy_gradient_loss | -0.000595    |
|    value_loss           | 0.271        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 208         |
| time/                   |             |
|    fps                  | 118         |
|    iterations           | 105         |
|    time_elapsed         | 1818        |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.005054961 |
|    clip_fraction        | 0.026       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0565     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.191       |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.00393    |
|    value_loss           | 0.28        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 118          |
|    iterations           | 106          |
|    time_elapsed         | 1836         |
|    total_timesteps      | 217088       |
| train/                  |              |
|    approx_kl            | 0.0007194989 |
|    clip_fraction        | 0.00942      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0769      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.216        |
|    n_updates            | 1050         |
|    policy_gradient_loss | -0.000721    |
|    value_loss           | 0.32         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 221           |
|    ep_rew_mean          | 209           |
| time/                   |               |
|    fps                  | 118           |
|    iterations           | 107           |
|    time_elapsed         | 1851          |
|    total_timesteps      | 219136        |
| train/                  |               |
|    approx_kl            | 0.00060528005 |
|    clip_fraction        | 0.00522       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0699       |
|    explained_variance   | 1             |
|    learning_rate        | 0.0003        |
|    loss                 | 0.155         |
|    n_updates            | 1060          |
|    policy_gradient_loss | -0.00146      |
|    value_loss           | 0.296         |
-------------------------------------------
Eval num_timesteps=220000, episode_reward=207.76 +/- 4.48
Episode length: 220.20 +/- 4.17
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 220          |
|    mean_reward          | 208          |
| time/                   |              |
|    total_timesteps      | 220000       |
| train/                  |              |
|    approx_kl            | 0.0014902526 |
|    clip_fraction        | 0.0196       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.069       |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.244        |
|    n_updates            | 1070         |
|    policy_gradient_loss | -0.00336     |
|    value_loss           | 0.338        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 118      |
|    iterations      | 108      |
|    time_elapsed    | 1871     |
|    total_timesteps | 221184   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 118          |
|    iterations           | 109          |
|    time_elapsed         | 1886         |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 0.0046849577 |
|    clip_fraction        | 0.0368       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0781      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.171        |
|    n_updates            | 1080         |
|    policy_gradient_loss | -0.00399     |
|    value_loss           | 0.293        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 118          |
|    iterations           | 110          |
|    time_elapsed         | 1907         |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 0.0011907262 |
|    clip_fraction        | 0.0145       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0603      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.213        |
|    n_updates            | 1090         |
|    policy_gradient_loss | -0.00208     |
|    value_loss           | 0.335        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 209         |
| time/                   |             |
|    fps                  | 118         |
|    iterations           | 111         |
|    time_elapsed         | 1924        |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.003044837 |
|    clip_fraction        | 0.0282      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0884     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.185       |
|    n_updates            | 1100        |
|    policy_gradient_loss | 0.000786    |
|    value_loss           | 0.374       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 209         |
| time/                   |             |
|    fps                  | 118         |
|    iterations           | 112         |
|    time_elapsed         | 1943        |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.004210295 |
|    clip_fraction        | 0.0257      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0657     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0146      |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.00206    |
|    value_loss           | 0.155       |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=210.29 +/- 4.54
Episode length: 221.40 +/- 3.61
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 221         |
|    mean_reward          | 210         |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.016329875 |
|    clip_fraction        | 0.0231      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0773     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0931      |
|    n_updates            | 1120        |
|    policy_gradient_loss | 0.00167     |
|    value_loss           | 0.263       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 118      |
|    iterations      | 113      |
|    time_elapsed    | 1959     |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 209         |
| time/                   |             |
|    fps                  | 118         |
|    iterations           | 114         |
|    time_elapsed         | 1977        |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.002066459 |
|    clip_fraction        | 0.0307      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0853     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.369       |
|    n_updates            | 1130        |
|    policy_gradient_loss | 0.00184     |
|    value_loss           | 0.67        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 118          |
|    iterations           | 115          |
|    time_elapsed         | 1994         |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 0.0011909457 |
|    clip_fraction        | 0.0166       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.076       |
|    explained_variance   | 0.998        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.3          |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.000884    |
|    value_loss           | 0.626        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 118          |
|    iterations           | 116          |
|    time_elapsed         | 2013         |
|    total_timesteps      | 237568       |
| train/                  |              |
|    approx_kl            | 0.0020446205 |
|    clip_fraction        | 0.0125       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0502      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.428        |
|    n_updates            | 1150         |
|    policy_gradient_loss | -0.00129     |
|    value_loss           | 0.313        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 118          |
|    iterations           | 117          |
|    time_elapsed         | 2028         |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 0.0012937882 |
|    clip_fraction        | 0.0085       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0715      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.361        |
|    n_updates            | 1160         |
|    policy_gradient_loss | -0.000159    |
|    value_loss           | 0.46         |
------------------------------------------
Eval num_timesteps=240000, episode_reward=211.95 +/- 3.29
Episode length: 219.80 +/- 1.94
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 220         |
|    mean_reward          | 212         |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.037682746 |
|    clip_fraction        | 0.0348      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0625     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0367      |
|    n_updates            | 1170        |
|    policy_gradient_loss | 0.00246     |
|    value_loss           | 0.256       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 208      |
| time/              |          |
|    fps             | 117      |
|    iterations      | 118      |
|    time_elapsed    | 2048     |
|    total_timesteps | 241664   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 220           |
|    ep_rew_mean          | 204           |
| time/                   |               |
|    fps                  | 117           |
|    iterations           | 119           |
|    time_elapsed         | 2065          |
|    total_timesteps      | 243712        |
| train/                  |               |
|    approx_kl            | 0.00093369465 |
|    clip_fraction        | 0.00859       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0787       |
|    explained_variance   | 0.944         |
|    learning_rate        | 0.0003        |
|    loss                 | 9.53          |
|    n_updates            | 1180          |
|    policy_gradient_loss | 0.000332      |
|    value_loss           | 30.4          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 219         |
|    ep_rew_mean          | 203         |
| time/                   |             |
|    fps                  | 117         |
|    iterations           | 120         |
|    time_elapsed         | 2084        |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.005119594 |
|    clip_fraction        | 0.0326      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.101      |
|    explained_variance   | 0.915       |
|    learning_rate        | 0.0003      |
|    loss                 | 11.2        |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.00594    |
|    value_loss           | 41          |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 202          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 121          |
|    time_elapsed         | 2102         |
|    total_timesteps      | 247808       |
| train/                  |              |
|    approx_kl            | 0.0010924136 |
|    clip_fraction        | 0.00571      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0801      |
|    explained_variance   | 0.951        |
|    learning_rate        | 0.0003       |
|    loss                 | 16.8         |
|    n_updates            | 1200         |
|    policy_gradient_loss | -0.0013      |
|    value_loss           | 30.3         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 202          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 122          |
|    time_elapsed         | 2120         |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 0.0014201887 |
|    clip_fraction        | 0.0167       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0837      |
|    explained_variance   | 0.967        |
|    learning_rate        | 0.0003       |
|    loss                 | 7.7          |
|    n_updates            | 1210         |
|    policy_gradient_loss | -0.0024      |
|    value_loss           | 20.2         |
------------------------------------------
Eval num_timesteps=250000, episode_reward=212.39 +/- 3.72
Episode length: 223.00 +/- 3.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 223         |
|    mean_reward          | 212         |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.002492134 |
|    clip_fraction        | 0.0276      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0942     |
|    explained_variance   | 0.99        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.147       |
|    n_updates            | 1220        |
|    policy_gradient_loss | 0.00128     |
|    value_loss           | 0.902       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 219      |
|    ep_rew_mean     | 202      |
| time/              |          |
|    fps             | 117      |
|    iterations      | 123      |
|    time_elapsed    | 2142     |
|    total_timesteps | 251904   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 219        |
|    ep_rew_mean          | 202        |
| time/                   |            |
|    fps                  | 117        |
|    iterations           | 124        |
|    time_elapsed         | 2157       |
|    total_timesteps      | 253952     |
| train/                  |            |
|    approx_kl            | 0.00199075 |
|    clip_fraction        | 0.0177     |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0823    |
|    explained_variance   | 0.996      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.2        |
|    n_updates            | 1230       |
|    policy_gradient_loss | -0.00102   |
|    value_loss           | 0.438      |
----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 219           |
|    ep_rew_mean          | 202           |
| time/                   |               |
|    fps                  | 117           |
|    iterations           | 125           |
|    time_elapsed         | 2177          |
|    total_timesteps      | 256000        |
| train/                  |               |
|    approx_kl            | 0.00075882464 |
|    clip_fraction        | 0.0287        |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.094        |
|    explained_variance   | 0.998         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.126         |
|    n_updates            | 1240          |
|    policy_gradient_loss | 0.00252       |
|    value_loss           | 0.243         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 202          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 126          |
|    time_elapsed         | 2194         |
|    total_timesteps      | 258048       |
| train/                  |              |
|    approx_kl            | 0.0010282337 |
|    clip_fraction        | 0.0148       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0876      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.308        |
|    n_updates            | 1250         |
|    policy_gradient_loss | 0.000265     |
|    value_loss           | 0.268        |
------------------------------------------
Eval num_timesteps=260000, episode_reward=210.03 +/- 3.44
Episode length: 221.20 +/- 3.97
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 221          |
|    mean_reward          | 210          |
| time/                   |              |
|    total_timesteps      | 260000       |
| train/                  |              |
|    approx_kl            | 0.0015246356 |
|    clip_fraction        | 0.0237       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.101       |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0541       |
|    n_updates            | 1260         |
|    policy_gradient_loss | 0.00129      |
|    value_loss           | 0.301        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 219      |
|    ep_rew_mean     | 201      |
| time/              |          |
|    fps             | 117      |
|    iterations      | 127      |
|    time_elapsed    | 2212     |
|    total_timesteps | 260096   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 219          |
|    ep_rew_mean          | 201          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 128          |
|    time_elapsed         | 2228         |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0046157297 |
|    clip_fraction        | 0.0117       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0871      |
|    explained_variance   | 0.998        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0401       |
|    n_updates            | 1270         |
|    policy_gradient_loss | -0.00131     |
|    value_loss           | 0.445        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 220          |
|    ep_rew_mean          | 204          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 129          |
|    time_elapsed         | 2247         |
|    total_timesteps      | 264192       |
| train/                  |              |
|    approx_kl            | 0.0012247668 |
|    clip_fraction        | 0.0236       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.069       |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0159       |
|    n_updates            | 1280         |
|    policy_gradient_loss | -0.000636    |
|    value_loss           | 0.135        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 130          |
|    time_elapsed         | 2263         |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 0.0005795683 |
|    clip_fraction        | 0.00454      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0703      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0172       |
|    n_updates            | 1290         |
|    policy_gradient_loss | -0.000612    |
|    value_loss           | 0.293        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 210          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 131          |
|    time_elapsed         | 2282         |
|    total_timesteps      | 268288       |
| train/                  |              |
|    approx_kl            | 0.0018614139 |
|    clip_fraction        | 0.0139       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0795      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0395       |
|    n_updates            | 1300         |
|    policy_gradient_loss | -0.00134     |
|    value_loss           | 0.173        |
------------------------------------------
Eval num_timesteps=270000, episode_reward=208.67 +/- 3.83
Episode length: 219.60 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 220         |
|    mean_reward          | 209         |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.004193746 |
|    clip_fraction        | 0.0177      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0862     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0336      |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.00297    |
|    value_loss           | 0.283       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 117      |
|    iterations      | 132      |
|    time_elapsed    | 2298     |
|    total_timesteps | 270336   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 209         |
| time/                   |             |
|    fps                  | 117         |
|    iterations           | 133         |
|    time_elapsed         | 2317        |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.002687615 |
|    clip_fraction        | 0.0146      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0551     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.255       |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.00237    |
|    value_loss           | 0.51        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 209         |
| time/                   |             |
|    fps                  | 117         |
|    iterations           | 134         |
|    time_elapsed         | 2333        |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.021837939 |
|    clip_fraction        | 0.0129      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0384     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.189       |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.00089    |
|    value_loss           | 0.417       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 135          |
|    time_elapsed         | 2353         |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 0.0009152336 |
|    clip_fraction        | 0.0149       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0717      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.134        |
|    n_updates            | 1340         |
|    policy_gradient_loss | -0.00108     |
|    value_loss           | 0.214        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 209          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 136          |
|    time_elapsed         | 2370         |
|    total_timesteps      | 278528       |
| train/                  |              |
|    approx_kl            | 0.0037224607 |
|    clip_fraction        | 0.0291       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0893      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.106        |
|    n_updates            | 1350         |
|    policy_gradient_loss | 0.000403     |
|    value_loss           | 0.386        |
------------------------------------------
Eval num_timesteps=280000, episode_reward=208.72 +/- 3.39
Episode length: 220.60 +/- 3.14
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 221         |
|    mean_reward          | 209         |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.001976537 |
|    clip_fraction        | 0.0323      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.077      |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0411      |
|    n_updates            | 1360        |
|    policy_gradient_loss | 0.000852    |
|    value_loss           | 0.201       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 209      |
| time/              |          |
|    fps             | 117      |
|    iterations      | 137      |
|    time_elapsed    | 2390     |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 209         |
| time/                   |             |
|    fps                  | 117         |
|    iterations           | 138         |
|    time_elapsed         | 2407        |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.003119993 |
|    clip_fraction        | 0.0169      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0689     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0591      |
|    n_updates            | 1370        |
|    policy_gradient_loss | 0.000323    |
|    value_loss           | 0.232       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 209         |
| time/                   |             |
|    fps                  | 117         |
|    iterations           | 139         |
|    time_elapsed         | 2426        |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.005156202 |
|    clip_fraction        | 0.0266      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0767     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.414       |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.00119    |
|    value_loss           | 0.461       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 209         |
| time/                   |             |
|    fps                  | 117         |
|    iterations           | 140         |
|    time_elapsed         | 2445        |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.001430519 |
|    clip_fraction        | 0.0106      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0625     |
|    explained_variance   | 1           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.223       |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.000488   |
|    value_loss           | 0.596       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 141          |
|    time_elapsed         | 2461         |
|    total_timesteps      | 288768       |
| train/                  |              |
|    approx_kl            | 0.0015312872 |
|    clip_fraction        | 0.00962      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0519      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.268        |
|    n_updates            | 1400         |
|    policy_gradient_loss | -0.00106     |
|    value_loss           | 0.596        |
------------------------------------------
Eval num_timesteps=290000, episode_reward=212.87 +/- 3.47
Episode length: 224.20 +/- 3.66
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 224          |
|    mean_reward          | 213          |
| time/                   |              |
|    total_timesteps      | 290000       |
| train/                  |              |
|    approx_kl            | 0.0036906889 |
|    clip_fraction        | 0.0227       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0772      |
|    explained_variance   | 0.967        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.712        |
|    n_updates            | 1410         |
|    policy_gradient_loss | -0.00331     |
|    value_loss           | 12.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 208      |
| time/              |          |
|    fps             | 117      |
|    iterations      | 142      |
|    time_elapsed    | 2479     |
|    total_timesteps | 290816   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 143          |
|    time_elapsed         | 2496         |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 0.0007429462 |
|    clip_fraction        | 0.0163       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0766      |
|    explained_variance   | 0.996        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.198        |
|    n_updates            | 1420         |
|    policy_gradient_loss | 0.00122      |
|    value_loss           | 1.01         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 221         |
|    ep_rew_mean          | 208         |
| time/                   |             |
|    fps                  | 117         |
|    iterations           | 144         |
|    time_elapsed         | 2515        |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.001185722 |
|    clip_fraction        | 0.0138      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.059      |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.208       |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.00137    |
|    value_loss           | 0.286       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 145          |
|    time_elapsed         | 2532         |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 0.0008732027 |
|    clip_fraction        | 0.0105       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0503      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0771       |
|    n_updates            | 1440         |
|    policy_gradient_loss | -0.000694    |
|    value_loss           | 0.129        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 221          |
|    ep_rew_mean          | 208          |
| time/                   |              |
|    fps                  | 117          |
|    iterations           | 146          |
|    time_elapsed         | 2552         |
|    total_timesteps      | 299008       |
| train/                  |              |
|    approx_kl            | 0.0042115767 |
|    clip_fraction        | 0.0106       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0493      |
|    explained_variance   | 1            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0144       |
|    n_updates            | 1450         |
|    policy_gradient_loss | -0.00118     |
|    value_loss           | 0.178        |
------------------------------------------
Eval num_timesteps=300000, episode_reward=210.89 +/- 2.56
Episode length: 222.60 +/- 3.07
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 223         |
|    mean_reward          | 211         |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.006673947 |
|    clip_fraction        | 0.0439      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0974     |
|    explained_variance   | 0.999       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0571      |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.00154    |
|    value_loss           | 0.37        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 208      |
| time/              |          |
|    fps             | 117      |
|    iterations      | 147      |
|    time_elapsed    | 2568     |
|    total_timesteps | 301056   |
---------------------------------

Training complete!
Run directory: /home/cris/hierarchical_rl_robotaxi/logs/2025-12-08_10-21-13

