Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-09_00-12-41

Map saved at: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-09_00-12-41/map_visualization.png

Using cpu device
Wrapping the env in a DummyVecEnv.
Logging to /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-09_00-12-41/tensorboard/PPO_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 328      |
|    ep_rew_mean     | -442     |
| time/              |          |
|    fps             | 2338     |
|    iterations      | 1        |
|    time_elapsed    | 0        |
|    total_timesteps | 2048     |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 304        |
|    ep_rew_mean          | -342       |
| time/                   |            |
|    fps                  | 1736       |
|    iterations           | 2          |
|    time_elapsed         | 2          |
|    total_timesteps      | 4096       |
| train/                  |            |
|    approx_kl            | 0.04242178 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.07      |
|    explained_variance   | -0.00209   |
|    learning_rate        | 0.0003     |
|    loss                 | 350        |
|    n_updates            | 10         |
|    policy_gradient_loss | -0.0291    |
|    value_loss           | 661        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 282        |
|    ep_rew_mean          | -250       |
| time/                   |            |
|    fps                  | 1619       |
|    iterations           | 3          |
|    time_elapsed         | 3          |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.11265497 |
|    clip_fraction        | 0.21       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.95      |
|    explained_variance   | 0.000162   |
|    learning_rate        | 0.0003     |
|    loss                 | 226        |
|    n_updates            | 20         |
|    policy_gradient_loss | -0.0198    |
|    value_loss           | 561        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 272         |
|    ep_rew_mean          | -199        |
| time/                   |             |
|    fps                  | 1560        |
|    iterations           | 4           |
|    time_elapsed         | 5           |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.005957462 |
|    clip_fraction        | 0.0276      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.876      |
|    explained_variance   | 0.0953      |
|    learning_rate        | 0.0003      |
|    loss                 | 128         |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00202    |
|    value_loss           | 534         |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=9.92 +/- 1.77
Episode length: 222.80 +/- 1.94
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 223         |
|    mean_reward          | 9.92        |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.017239518 |
|    clip_fraction        | 0.0681      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.834      |
|    explained_variance   | 0.419       |
|    learning_rate        | 0.0003      |
|    loss                 | 120         |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0056     |
|    value_loss           | 470         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 264      |
|    ep_rew_mean     | -168     |
| time/              |          |
|    fps             | 1456     |
|    iterations      | 5        |
|    time_elapsed    | 7        |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 262         |
|    ep_rew_mean          | -157        |
| time/                   |             |
|    fps                  | 1452        |
|    iterations           | 6           |
|    time_elapsed         | 8           |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.007948615 |
|    clip_fraction        | 0.0574      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.791      |
|    explained_variance   | 0.602       |
|    learning_rate        | 0.0003      |
|    loss                 | 159         |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00515    |
|    value_loss           | 369         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 260         |
|    ep_rew_mean          | -145        |
| time/                   |             |
|    fps                  | 1436        |
|    iterations           | 7           |
|    time_elapsed         | 9           |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.011997826 |
|    clip_fraction        | 0.0543      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.821      |
|    explained_variance   | 0.711       |
|    learning_rate        | 0.0003      |
|    loss                 | 143         |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00729    |
|    value_loss           | 430         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 257         |
|    ep_rew_mean          | -133        |
| time/                   |             |
|    fps                  | 1434        |
|    iterations           | 8           |
|    time_elapsed         | 11          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.007866652 |
|    clip_fraction        | 0.0531      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.828      |
|    explained_variance   | 0.78        |
|    learning_rate        | 0.0003      |
|    loss                 | 196         |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00326    |
|    value_loss           | 353         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 255          |
|    ep_rew_mean          | -126         |
| time/                   |              |
|    fps                  | 1426         |
|    iterations           | 9            |
|    time_elapsed         | 12           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0050492426 |
|    clip_fraction        | 0.056        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.812       |
|    explained_variance   | 0.8          |
|    learning_rate        | 0.0003       |
|    loss                 | 120          |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00455     |
|    value_loss           | 313          |
------------------------------------------
Eval num_timesteps=20000, episode_reward=69.75 +/- 1.48
Episode length: 220.00 +/- 1.55
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 220          |
|    mean_reward          | 69.8         |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0120581295 |
|    clip_fraction        | 0.0879       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.809       |
|    explained_variance   | 0.838        |
|    learning_rate        | 0.0003       |
|    loss                 | 171          |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00722     |
|    value_loss           | 309          |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 254      |
|    ep_rew_mean     | -122     |
| time/              |          |
|    fps             | 1392     |
|    iterations      | 10       |
|    time_elapsed    | 14       |
|    total_timesteps | 20480    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 252         |
|    ep_rew_mean          | -115        |
| time/                   |             |
|    fps                  | 1395        |
|    iterations           | 11          |
|    time_elapsed         | 16          |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.006845774 |
|    clip_fraction        | 0.0467      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.804      |
|    explained_variance   | 0.862       |
|    learning_rate        | 0.0003      |
|    loss                 | 153         |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00399    |
|    value_loss           | 286         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -109        |
| time/                   |             |
|    fps                  | 1397        |
|    iterations           | 12          |
|    time_elapsed         | 17          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.013471956 |
|    clip_fraction        | 0.0433      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.772      |
|    explained_variance   | 0.878       |
|    learning_rate        | 0.0003      |
|    loss                 | 82.6        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00594    |
|    value_loss           | 255         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 245         |
|    ep_rew_mean          | -83.3       |
| time/                   |             |
|    fps                  | 1400        |
|    iterations           | 13          |
|    time_elapsed         | 19          |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.006017273 |
|    clip_fraction        | 0.0143      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.741      |
|    explained_variance   | 0.893       |
|    learning_rate        | 0.0003      |
|    loss                 | 103         |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00326    |
|    value_loss           | 192         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 241         |
|    ep_rew_mean          | -65.2       |
| time/                   |             |
|    fps                  | 1402        |
|    iterations           | 14          |
|    time_elapsed         | 20          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.009184428 |
|    clip_fraction        | 0.0366      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.688      |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.0003      |
|    loss                 | 76.3        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00551    |
|    value_loss           | 213         |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=71.96 +/- 3.49
Episode length: 222.40 +/- 3.67
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 222          |
|    mean_reward          | 72           |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0013420114 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.666       |
|    explained_variance   | 0.897        |
|    learning_rate        | 0.0003       |
|    loss                 | 110          |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.000257    |
|    value_loss           | 202          |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 240      |
|    ep_rew_mean     | -60      |
| time/              |          |
|    fps             | 1385     |
|    iterations      | 15       |
|    time_elapsed    | 22       |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 239         |
|    ep_rew_mean          | -55.8       |
| time/                   |             |
|    fps                  | 1388        |
|    iterations           | 16          |
|    time_elapsed         | 23          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.011154965 |
|    clip_fraction        | 0.0854      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.634      |
|    explained_variance   | 0.913       |
|    learning_rate        | 0.0003      |
|    loss                 | 63.4        |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.0106     |
|    value_loss           | 200         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 238          |
|    ep_rew_mean          | -50.5        |
| time/                   |              |
|    fps                  | 1391         |
|    iterations           | 17           |
|    time_elapsed         | 25           |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0051330216 |
|    clip_fraction        | 0.00771      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.584       |
|    explained_variance   | 0.924        |
|    learning_rate        | 0.0003       |
|    loss                 | 52.9         |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00115     |
|    value_loss           | 144          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 235         |
|    ep_rew_mean          | -42.1       |
| time/                   |             |
|    fps                  | 1393        |
|    iterations           | 18          |
|    time_elapsed         | 26          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.005342772 |
|    clip_fraction        | 0.0344      |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.499      |
|    explained_variance   | 0.919       |
|    learning_rate        | 0.0003      |
|    loss                 | 62.2        |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0036     |
|    value_loss           | 153         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 234          |
|    ep_rew_mean          | -36.8        |
| time/                   |              |
|    fps                  | 1395         |
|    iterations           | 19           |
|    time_elapsed         | 27           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 0.0037593907 |
|    clip_fraction        | 0.0325       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.442       |
|    explained_variance   | 0.925        |
|    learning_rate        | 0.0003       |
|    loss                 | 57.1         |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.00282     |
|    value_loss           | 150          |
------------------------------------------
Eval num_timesteps=40000, episode_reward=73.64 +/- 2.73
Episode length: 224.00 +/- 2.76
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 224          |
|    mean_reward          | 73.6         |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0025005038 |
|    clip_fraction        | 0.0381       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.398       |
|    explained_variance   | 0.935        |
|    learning_rate        | 0.0003       |
|    loss                 | 72.7         |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.00348     |
|    value_loss           | 127          |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 233      |
|    ep_rew_mean     | -30      |
| time/              |          |
|    fps             | 1382     |
|    iterations      | 20       |
|    time_elapsed    | 29       |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 232          |
|    ep_rew_mean          | -20.4        |
| time/                   |              |
|    fps                  | 1385         |
|    iterations           | 21           |
|    time_elapsed         | 31           |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0013646286 |
|    clip_fraction        | 0.00469      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.371       |
|    explained_variance   | 0.938        |
|    learning_rate        | 0.0003       |
|    loss                 | 90.6         |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00119     |
|    value_loss           | 121          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 230          |
|    ep_rew_mean          | -12.1        |
| time/                   |              |
|    fps                  | 1386         |
|    iterations           | 22           |
|    time_elapsed         | 32           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0035387564 |
|    clip_fraction        | 0.039        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.318       |
|    explained_variance   | 0.938        |
|    learning_rate        | 0.0003       |
|    loss                 | 67.1         |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.00301     |
|    value_loss           | 120          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 229          |
|    ep_rew_mean          | -4.86        |
| time/                   |              |
|    fps                  | 1389         |
|    iterations           | 23           |
|    time_elapsed         | 33           |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 0.0021447833 |
|    clip_fraction        | 0.0216       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.272       |
|    explained_variance   | 0.944        |
|    learning_rate        | 0.0003       |
|    loss                 | 37.8         |
|    n_updates            | 220          |
|    policy_gradient_loss | -0.00238     |
|    value_loss           | 107          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 229          |
|    ep_rew_mean          | 2.14         |
| time/                   |              |
|    fps                  | 1392         |
|    iterations           | 24           |
|    time_elapsed         | 35           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0018011674 |
|    clip_fraction        | 0.0211       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.247       |
|    explained_variance   | 0.953        |
|    learning_rate        | 0.0003       |
|    loss                 | 40.1         |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.00239     |
|    value_loss           | 91.9         |
------------------------------------------
Eval num_timesteps=50000, episode_reward=68.75 +/- 2.46
Episode length: 219.20 +/- 2.32
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 219          |
|    mean_reward          | 68.7         |
| time/                   |              |
|    total_timesteps      | 50000        |
| train/                  |              |
|    approx_kl            | 0.0016186854 |
|    clip_fraction        | 0.0269       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.208       |
|    explained_variance   | 0.957        |
|    learning_rate        | 0.0003       |
|    loss                 | 41.3         |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.0035      |
|    value_loss           | 83.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 228      |
|    ep_rew_mean     | 8.85     |
| time/              |          |
|    fps             | 1380     |
|    iterations      | 25       |
|    time_elapsed    | 37       |
|    total_timesteps | 51200    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 227          |
|    ep_rew_mean          | 15.3         |
| time/                   |              |
|    fps                  | 1383         |
|    iterations           | 26           |
|    time_elapsed         | 38           |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0013797968 |
|    clip_fraction        | 0.00532      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.185       |
|    explained_variance   | 0.958        |
|    learning_rate        | 0.0003       |
|    loss                 | 56.5         |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.00252     |
|    value_loss           | 84           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 226           |
|    ep_rew_mean          | 21.9          |
| time/                   |               |
|    fps                  | 1386          |
|    iterations           | 27            |
|    time_elapsed         | 39            |
|    total_timesteps      | 55296         |
| train/                  |               |
|    approx_kl            | 0.00092065334 |
|    clip_fraction        | 0.018         |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.161        |
|    explained_variance   | 0.955         |
|    learning_rate        | 0.0003        |
|    loss                 | 66            |
|    n_updates            | 260           |
|    policy_gradient_loss | -0.00178      |
|    value_loss           | 84.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 226          |
|    ep_rew_mean          | 27           |
| time/                   |              |
|    fps                  | 1388         |
|    iterations           | 28           |
|    time_elapsed         | 41           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0015364233 |
|    clip_fraction        | 0.0144       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.162       |
|    explained_variance   | 0.958        |
|    learning_rate        | 0.0003       |
|    loss                 | 82.7         |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.00286     |
|    value_loss           | 82.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 226          |
|    ep_rew_mean          | 31.8         |
| time/                   |              |
|    fps                  | 1390         |
|    iterations           | 29           |
|    time_elapsed         | 42           |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 0.0009549681 |
|    clip_fraction        | 0.00327      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.159       |
|    explained_variance   | 0.96         |
|    learning_rate        | 0.0003       |
|    loss                 | 6            |
|    n_updates            | 280          |
|    policy_gradient_loss | 6.07e-05     |
|    value_loss           | 84           |
------------------------------------------
Eval num_timesteps=60000, episode_reward=69.84 +/- 3.62
Episode length: 220.40 +/- 3.77
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 220          |
|    mean_reward          | 69.8         |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0011864114 |
|    clip_fraction        | 0.0203       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.128       |
|    explained_variance   | 0.96         |
|    learning_rate        | 0.0003       |
|    loss                 | 12.1         |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.00105     |
|    value_loss           | 87.9         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 226      |
|    ep_rew_mean     | 36.3     |
| time/              |          |
|    fps             | 1383     |
|    iterations      | 30       |
|    time_elapsed    | 44       |
|    total_timesteps | 61440    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 225           |
|    ep_rew_mean          | 40            |
| time/                   |               |
|    fps                  | 1386          |
|    iterations           | 31            |
|    time_elapsed         | 45            |
|    total_timesteps      | 63488         |
| train/                  |               |
|    approx_kl            | 0.00046307073 |
|    clip_fraction        | 0.00693       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.114        |
|    explained_variance   | 0.961         |
|    learning_rate        | 0.0003        |
|    loss                 | 42.1          |
|    n_updates            | 300           |
|    policy_gradient_loss | -0.000276     |
|    value_loss           | 87.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 225          |
|    ep_rew_mean          | 43.7         |
| time/                   |              |
|    fps                  | 1388         |
|    iterations           | 32           |
|    time_elapsed         | 47           |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0013261511 |
|    clip_fraction        | 0.017        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0961      |
|    explained_variance   | 0.964        |
|    learning_rate        | 0.0003       |
|    loss                 | 78.4         |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.00184     |
|    value_loss           | 83.7         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 225          |
|    ep_rew_mean          | 46.3         |
| time/                   |              |
|    fps                  | 1390         |
|    iterations           | 33           |
|    time_elapsed         | 48           |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 0.0008859235 |
|    clip_fraction        | 0.0107       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0821      |
|    explained_variance   | 0.966        |
|    learning_rate        | 0.0003       |
|    loss                 | 4.68         |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00125     |
|    value_loss           | 77           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 225           |
|    ep_rew_mean          | 48.8          |
| time/                   |               |
|    fps                  | 1392          |
|    iterations           | 34            |
|    time_elapsed         | 49            |
|    total_timesteps      | 69632         |
| train/                  |               |
|    approx_kl            | 0.00040372225 |
|    clip_fraction        | 0.00527       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.075        |
|    explained_variance   | 0.97          |
|    learning_rate        | 0.0003        |
|    loss                 | 51.3          |
|    n_updates            | 330           |
|    policy_gradient_loss | -0.00102      |
|    value_loss           | 71.5          |
-------------------------------------------
Eval num_timesteps=70000, episode_reward=71.04 +/- 3.42
Episode length: 221.60 +/- 3.38
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 222          |
|    mean_reward          | 71           |
| time/                   |              |
|    total_timesteps      | 70000        |
| train/                  |              |
|    approx_kl            | 0.0010626167 |
|    clip_fraction        | 0.0118       |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0619      |
|    explained_variance   | 0.967        |
|    learning_rate        | 0.0003       |
|    loss                 | 2.89         |
|    n_updates            | 340          |
|    policy_gradient_loss | -0.00333     |
|    value_loss           | 74.3         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 225      |
|    ep_rew_mean     | 50.8     |
| time/              |          |
|    fps             | 1357     |
|    iterations      | 35       |
|    time_elapsed    | 52       |
|    total_timesteps | 71680    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 225           |
|    ep_rew_mean          | 53.2          |
| time/                   |               |
|    fps                  | 1360          |
|    iterations           | 36            |
|    time_elapsed         | 54            |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 0.00051486597 |
|    clip_fraction        | 0.00264       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0478       |
|    explained_variance   | 0.969         |
|    learning_rate        | 0.0003        |
|    loss                 | 91.3          |
|    n_updates            | 350           |
|    policy_gradient_loss | -0.000283     |
|    value_loss           | 68.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 225           |
|    ep_rew_mean          | 55.4          |
| time/                   |               |
|    fps                  | 1362          |
|    iterations           | 37            |
|    time_elapsed         | 55            |
|    total_timesteps      | 75776         |
| train/                  |               |
|    approx_kl            | 0.00032702982 |
|    clip_fraction        | 0.00234       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0397       |
|    explained_variance   | 0.966         |
|    learning_rate        | 0.0003        |
|    loss                 | 3.08          |
|    n_updates            | 360           |
|    policy_gradient_loss | -0.000821     |
|    value_loss           | 69.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 224           |
|    ep_rew_mean          | 57.3          |
| time/                   |               |
|    fps                  | 1364          |
|    iterations           | 38            |
|    time_elapsed         | 57            |
|    total_timesteps      | 77824         |
| train/                  |               |
|    approx_kl            | 0.00021684286 |
|    clip_fraction        | 0.000684      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.034        |
|    explained_variance   | 0.958         |
|    learning_rate        | 0.0003        |
|    loss                 | 124           |
|    n_updates            | 370           |
|    policy_gradient_loss | -0.000298     |
|    value_loss           | 82.3          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 224          |
|    ep_rew_mean          | 59.3         |
| time/                   |              |
|    fps                  | 1367         |
|    iterations           | 39           |
|    time_elapsed         | 58           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 0.0002816251 |
|    clip_fraction        | 0.00122      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0262      |
|    explained_variance   | 0.97         |
|    learning_rate        | 0.0003       |
|    loss                 | 48.8         |
|    n_updates            | 380          |
|    policy_gradient_loss | 1.66e-05     |
|    value_loss           | 63.3         |
------------------------------------------
Eval num_timesteps=80000, episode_reward=72.21 +/- 1.67
Episode length: 222.80 +/- 1.47
--------------------------------------------
| eval/                   |                |
|    mean_ep_length       | 223            |
|    mean_reward          | 72.2           |
| time/                   |                |
|    total_timesteps      | 80000          |
| train/                  |                |
|    approx_kl            | 0.000101976446 |
|    clip_fraction        | 0.000781       |
|    clip_range           | 0.2            |
|    entropy_loss         | -0.0289        |
|    explained_variance   | 0.965          |
|    learning_rate        | 0.0003         |
|    loss                 | 69.5           |
|    n_updates            | 390            |
|    policy_gradient_loss | -0.000792      |
|    value_loss           | 75.3           |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 224      |
|    ep_rew_mean     | 61.2     |
| time/              |          |
|    fps             | 1362     |
|    iterations      | 40       |
|    time_elapsed    | 60       |
|    total_timesteps | 81920    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 224          |
|    ep_rew_mean          | 62.8         |
| time/                   |              |
|    fps                  | 1364         |
|    iterations           | 41           |
|    time_elapsed         | 61           |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 0.0004504147 |
|    clip_fraction        | 0.00181      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0274      |
|    explained_variance   | 0.971        |
|    learning_rate        | 0.0003       |
|    loss                 | 23.6         |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.000339    |
|    value_loss           | 62           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 223          |
|    ep_rew_mean          | 64.5         |
| time/                   |              |
|    fps                  | 1366         |
|    iterations           | 42           |
|    time_elapsed         | 62           |
|    total_timesteps      | 86016        |
| train/                  |              |
|    approx_kl            | 7.860843e-05 |
|    clip_fraction        | 0.00107      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0204      |
|    explained_variance   | 0.969        |
|    learning_rate        | 0.0003       |
|    loss                 | 45.2         |
|    n_updates            | 410          |
|    policy_gradient_loss | -0.000619    |
|    value_loss           | 62.7         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 223          |
|    ep_rew_mean          | 66.1         |
| time/                   |              |
|    fps                  | 1368         |
|    iterations           | 43           |
|    time_elapsed         | 64           |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 0.0002558185 |
|    clip_fraction        | 0.000977     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0156      |
|    explained_variance   | 0.971        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.23         |
|    n_updates            | 420          |
|    policy_gradient_loss | -0.000811    |
|    value_loss           | 56.5         |
------------------------------------------
Eval num_timesteps=90000, episode_reward=70.86 +/- 2.38
Episode length: 221.40 +/- 2.58
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 221          |
|    mean_reward          | 70.9         |
| time/                   |              |
|    total_timesteps      | 90000        |
| train/                  |              |
|    approx_kl            | 0.0001568761 |
|    clip_fraction        | 0.000684     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0112      |
|    explained_variance   | 0.972        |
|    learning_rate        | 0.0003       |
|    loss                 | 64.2         |
|    n_updates            | 430          |
|    policy_gradient_loss | -0.00105     |
|    value_loss           | 54.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 223      |
|    ep_rew_mean     | 67       |
| time/              |          |
|    fps             | 1347     |
|    iterations      | 44       |
|    time_elapsed    | 66       |
|    total_timesteps | 90112    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 223           |
|    ep_rew_mean          | 68.3          |
| time/                   |               |
|    fps                  | 1349          |
|    iterations           | 45            |
|    time_elapsed         | 68            |
|    total_timesteps      | 92160         |
| train/                  |               |
|    approx_kl            | 2.1353771e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00961      |
|    explained_variance   | 0.973         |
|    learning_rate        | 0.0003        |
|    loss                 | 2.53          |
|    n_updates            | 440           |
|    policy_gradient_loss | -0.000141     |
|    value_loss           | 52.9          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 223          |
|    ep_rew_mean          | 69.1         |
| time/                   |              |
|    fps                  | 1351         |
|    iterations           | 46           |
|    time_elapsed         | 69           |
|    total_timesteps      | 94208        |
| train/                  |              |
|    approx_kl            | 6.324882e-05 |
|    clip_fraction        | 0.000293     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00885     |
|    explained_variance   | 0.973        |
|    learning_rate        | 0.0003       |
|    loss                 | 29.7         |
|    n_updates            | 450          |
|    policy_gradient_loss | -0.000314    |
|    value_loss           | 50.9         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 223           |
|    ep_rew_mean          | 69.7          |
| time/                   |               |
|    fps                  | 1353          |
|    iterations           | 47            |
|    time_elapsed         | 71            |
|    total_timesteps      | 96256         |
| train/                  |               |
|    approx_kl            | 2.0399893e-05 |
|    clip_fraction        | 0.000342      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00782      |
|    explained_variance   | 0.976         |
|    learning_rate        | 0.0003        |
|    loss                 | 1.07          |
|    n_updates            | 460           |
|    policy_gradient_loss | -0.000218     |
|    value_loss           | 46            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 70            |
| time/                   |               |
|    fps                  | 1355          |
|    iterations           | 48            |
|    time_elapsed         | 72            |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 3.6670826e-09 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00742      |
|    explained_variance   | 0.969         |
|    learning_rate        | 0.0003        |
|    loss                 | 38.3          |
|    n_updates            | 470           |
|    policy_gradient_loss | -2.81e-05     |
|    value_loss           | 55.4          |
-------------------------------------------
Eval num_timesteps=100000, episode_reward=71.45 +/- 2.45
Episode length: 221.80 +/- 2.56
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 222           |
|    mean_reward          | 71.5          |
| time/                   |               |
|    total_timesteps      | 100000        |
| train/                  |               |
|    approx_kl            | 4.9483497e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00705      |
|    explained_variance   | 0.978         |
|    learning_rate        | 0.0003        |
|    loss                 | 3.16          |
|    n_updates            | 480           |
|    policy_gradient_loss | -4.54e-05     |
|    value_loss           | 43.3          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 70       |
| time/              |          |
|    fps             | 1351     |
|    iterations      | 49       |
|    time_elapsed    | 74       |
|    total_timesteps | 100352   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 70.1          |
| time/                   |               |
|    fps                  | 1353          |
|    iterations           | 50            |
|    time_elapsed         | 75            |
|    total_timesteps      | 102400        |
| train/                  |               |
|    approx_kl            | 0.00017100805 |
|    clip_fraction        | 0.00229       |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00509      |
|    explained_variance   | 0.975         |
|    learning_rate        | 0.0003        |
|    loss                 | 1             |
|    n_updates            | 490           |
|    policy_gradient_loss | -0.000535     |
|    value_loss           | 46.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 70.4          |
| time/                   |               |
|    fps                  | 1355          |
|    iterations           | 51            |
|    time_elapsed         | 77            |
|    total_timesteps      | 104448        |
| train/                  |               |
|    approx_kl            | 1.7974235e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00457      |
|    explained_variance   | 0.979         |
|    learning_rate        | 0.0003        |
|    loss                 | 2.83          |
|    n_updates            | 500           |
|    policy_gradient_loss | -3.24e-05     |
|    value_loss           | 38.8          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 70.6          |
| time/                   |               |
|    fps                  | 1357          |
|    iterations           | 52            |
|    time_elapsed         | 78            |
|    total_timesteps      | 106496        |
| train/                  |               |
|    approx_kl            | 1.6678241e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00435      |
|    explained_variance   | 0.976         |
|    learning_rate        | 0.0003        |
|    loss                 | 44.3          |
|    n_updates            | 510           |
|    policy_gradient_loss | -1.77e-05     |
|    value_loss           | 44            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 70.9         |
| time/                   |              |
|    fps                  | 1358         |
|    iterations           | 53           |
|    time_elapsed         | 79           |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 5.847978e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00407     |
|    explained_variance   | 0.977        |
|    learning_rate        | 0.0003       |
|    loss                 | 64.6         |
|    n_updates            | 520          |
|    policy_gradient_loss | -3.32e-05    |
|    value_loss           | 43.4         |
------------------------------------------
Eval num_timesteps=110000, episode_reward=74.45 +/- 1.11
Episode length: 224.80 +/- 1.17
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 225          |
|    mean_reward          | 74.5         |
| time/                   |              |
|    total_timesteps      | 110000       |
| train/                  |              |
|    approx_kl            | 8.912175e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00393     |
|    explained_variance   | 0.98         |
|    learning_rate        | 0.0003       |
|    loss                 | 0.628        |
|    n_updates            | 530          |
|    policy_gradient_loss | -1.23e-05    |
|    value_loss           | 35.5         |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 70.7     |
| time/              |          |
|    fps             | 1354     |
|    iterations      | 54       |
|    time_elapsed    | 81       |
|    total_timesteps | 110592   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 70.9          |
| time/                   |               |
|    fps                  | 1356          |
|    iterations           | 55            |
|    time_elapsed         | 83            |
|    total_timesteps      | 112640        |
| train/                  |               |
|    approx_kl            | 1.3214827e-05 |
|    clip_fraction        | 0.000244      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00397      |
|    explained_variance   | 0.982         |
|    learning_rate        | 0.0003        |
|    loss                 | 1.08          |
|    n_updates            | 540           |
|    policy_gradient_loss | -0.000395     |
|    value_loss           | 32.3          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 70.8      |
| time/                   |           |
|    fps                  | 1358      |
|    iterations           | 56        |
|    time_elapsed         | 84        |
|    total_timesteps      | 114688    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0039   |
|    explained_variance   | 0.984     |
|    learning_rate        | 0.0003    |
|    loss                 | 24.3      |
|    n_updates            | 550       |
|    policy_gradient_loss | -5.08e-06 |
|    value_loss           | 28.7      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 70.8          |
| time/                   |               |
|    fps                  | 1359          |
|    iterations           | 57            |
|    time_elapsed         | 85            |
|    total_timesteps      | 116736        |
| train/                  |               |
|    approx_kl            | 1.6632839e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00385      |
|    explained_variance   | 0.977         |
|    learning_rate        | 0.0003        |
|    loss                 | 21.6          |
|    n_updates            | 560           |
|    policy_gradient_loss | -7.89e-06     |
|    value_loss           | 40.3          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 70.7      |
| time/                   |           |
|    fps                  | 1361      |
|    iterations           | 58        |
|    time_elapsed         | 87        |
|    total_timesteps      | 118784    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00388  |
|    explained_variance   | 0.984     |
|    learning_rate        | 0.0003    |
|    loss                 | 50        |
|    n_updates            | 570       |
|    policy_gradient_loss | -4.06e-06 |
|    value_loss           | 30.1      |
---------------------------------------
Eval num_timesteps=120000, episode_reward=68.07 +/- 1.65
Episode length: 218.40 +/- 1.62
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 218       |
|    mean_reward          | 68.1      |
| time/                   |           |
|    total_timesteps      | 120000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0038   |
|    explained_variance   | 0.982     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.85      |
|    n_updates            | 580       |
|    policy_gradient_loss | -1.74e-06 |
|    value_loss           | 31.1      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 70.7     |
| time/              |          |
|    fps             | 1351     |
|    iterations      | 59       |
|    time_elapsed    | 89       |
|    total_timesteps | 120832   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 70.9      |
| time/                   |           |
|    fps                  | 1353      |
|    iterations           | 60        |
|    time_elapsed         | 90        |
|    total_timesteps      | 122880    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00378  |
|    explained_variance   | 0.986     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.56      |
|    n_updates            | 590       |
|    policy_gradient_loss | -1.46e-06 |
|    value_loss           | 25.7      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 70.9          |
| time/                   |               |
|    fps                  | 1354          |
|    iterations           | 61            |
|    time_elapsed         | 92            |
|    total_timesteps      | 124928        |
| train/                  |               |
|    approx_kl            | 2.5034009e-05 |
|    clip_fraction        | 0.000195      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00338      |
|    explained_variance   | 0.984         |
|    learning_rate        | 0.0003        |
|    loss                 | 2.98          |
|    n_updates            | 600           |
|    policy_gradient_loss | -0.000117     |
|    value_loss           | 28.7          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 70.9         |
| time/                   |              |
|    fps                  | 1355         |
|    iterations           | 62           |
|    time_elapsed         | 93           |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 3.285348e-05 |
|    clip_fraction        | 0.000537     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00284     |
|    explained_variance   | 0.986        |
|    learning_rate        | 0.0003       |
|    loss                 | 57           |
|    n_updates            | 610          |
|    policy_gradient_loss | -0.00033     |
|    value_loss           | 25.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 70.8          |
| time/                   |               |
|    fps                  | 1357          |
|    iterations           | 63            |
|    time_elapsed         | 95            |
|    total_timesteps      | 129024        |
| train/                  |               |
|    approx_kl            | 6.0300226e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00257      |
|    explained_variance   | 0.985         |
|    learning_rate        | 0.0003        |
|    loss                 | 3.71          |
|    n_updates            | 620           |
|    policy_gradient_loss | -7.06e-06     |
|    value_loss           | 25.9          |
-------------------------------------------
Eval num_timesteps=130000, episode_reward=70.91 +/- 3.37
Episode length: 221.60 +/- 3.38
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 222      |
|    mean_reward          | 70.9     |
| time/                   |          |
|    total_timesteps      | 130000   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00248 |
|    explained_variance   | 0.989    |
|    learning_rate        | 0.0003   |
|    loss                 | 1.01     |
|    n_updates            | 630      |
|    policy_gradient_loss | -4.6e-07 |
|    value_loss           | 20.2     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 70.9     |
| time/              |          |
|    fps             | 1354     |
|    iterations      | 64       |
|    time_elapsed    | 96       |
|    total_timesteps | 131072   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.1      |
| time/                   |           |
|    fps                  | 1356      |
|    iterations           | 65        |
|    time_elapsed         | 98        |
|    total_timesteps      | 133120    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00247  |
|    explained_variance   | 0.984     |
|    learning_rate        | 0.0003    |
|    loss                 | 35.7      |
|    n_updates            | 640       |
|    policy_gradient_loss | -3.67e-07 |
|    value_loss           | 27.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 70.9      |
| time/                   |           |
|    fps                  | 1355      |
|    iterations           | 66        |
|    time_elapsed         | 99        |
|    total_timesteps      | 135168    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00255  |
|    explained_variance   | 0.989     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.52      |
|    n_updates            | 650       |
|    policy_gradient_loss | -4.71e-07 |
|    value_loss           | 22.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.7      |
| time/                   |           |
|    fps                  | 1357      |
|    iterations           | 67        |
|    time_elapsed         | 101       |
|    total_timesteps      | 137216    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00248  |
|    explained_variance   | 0.989     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.91      |
|    n_updates            | 660       |
|    policy_gradient_loss | -8.42e-07 |
|    value_loss           | 19.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.8      |
| time/                   |           |
|    fps                  | 1358      |
|    iterations           | 68        |
|    time_elapsed         | 102       |
|    total_timesteps      | 139264    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00246  |
|    explained_variance   | 0.991     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.03      |
|    n_updates            | 670       |
|    policy_gradient_loss | -1.28e-06 |
|    value_loss           | 16.7      |
---------------------------------------
Eval num_timesteps=140000, episode_reward=74.18 +/- 2.05
Episode length: 224.40 +/- 2.06
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 224       |
|    mean_reward          | 74.2      |
| time/                   |           |
|    total_timesteps      | 140000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00243  |
|    explained_variance   | 0.98      |
|    learning_rate        | 0.0003    |
|    loss                 | 2.07      |
|    n_updates            | 680       |
|    policy_gradient_loss | -7.46e-07 |
|    value_loss           | 28.5      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 70.9     |
| time/              |          |
|    fps             | 1356     |
|    iterations      | 69       |
|    time_elapsed    | 104      |
|    total_timesteps | 141312   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 70.9      |
| time/                   |           |
|    fps                  | 1357      |
|    iterations           | 70        |
|    time_elapsed         | 105       |
|    total_timesteps      | 143360    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00249  |
|    explained_variance   | 0.987     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.07      |
|    n_updates            | 690       |
|    policy_gradient_loss | -3.94e-07 |
|    value_loss           | 22.2      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.7      |
| time/                   |           |
|    fps                  | 1359      |
|    iterations           | 71        |
|    time_elapsed         | 106       |
|    total_timesteps      | 145408    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00239  |
|    explained_variance   | 0.989     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.28      |
|    n_updates            | 700       |
|    policy_gradient_loss | -2.61e-07 |
|    value_loss           | 19        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 71        |
| time/                   |           |
|    fps                  | 1360      |
|    iterations           | 72        |
|    time_elapsed         | 108       |
|    total_timesteps      | 147456    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00239  |
|    explained_variance   | 0.989     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.842     |
|    n_updates            | 710       |
|    policy_gradient_loss | -6.03e-07 |
|    value_loss           | 18.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.8      |
| time/                   |           |
|    fps                  | 1361      |
|    iterations           | 73        |
|    time_elapsed         | 109       |
|    total_timesteps      | 149504    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00235  |
|    explained_variance   | 0.99      |
|    learning_rate        | 0.0003    |
|    loss                 | 6.91      |
|    n_updates            | 720       |
|    policy_gradient_loss | -3.05e-07 |
|    value_loss           | 19        |
---------------------------------------
Eval num_timesteps=150000, episode_reward=72.18 +/- 3.02
Episode length: 222.80 +/- 3.19
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 223       |
|    mean_reward          | 72.2      |
| time/                   |           |
|    total_timesteps      | 150000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00239  |
|    explained_variance   | 0.991     |
|    learning_rate        | 0.0003    |
|    loss                 | 5.54      |
|    n_updates            | 730       |
|    policy_gradient_loss | -1.03e-06 |
|    value_loss           | 15.8      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 70.7     |
| time/              |          |
|    fps             | 1358     |
|    iterations      | 74       |
|    time_elapsed    | 111      |
|    total_timesteps | 151552   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.5      |
| time/                   |           |
|    fps                  | 1359      |
|    iterations           | 75        |
|    time_elapsed         | 112       |
|    total_timesteps      | 153600    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0023   |
|    explained_variance   | 0.991     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.68      |
|    n_updates            | 740       |
|    policy_gradient_loss | -4.54e-07 |
|    value_loss           | 15.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.6      |
| time/                   |           |
|    fps                  | 1360      |
|    iterations           | 76        |
|    time_elapsed         | 114       |
|    total_timesteps      | 155648    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00232  |
|    explained_variance   | 0.993     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.42      |
|    n_updates            | 750       |
|    policy_gradient_loss | -1.47e-07 |
|    value_loss           | 11.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.8      |
| time/                   |           |
|    fps                  | 1361      |
|    iterations           | 77        |
|    time_elapsed         | 115       |
|    total_timesteps      | 157696    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0023   |
|    explained_variance   | 0.989     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.53      |
|    n_updates            | 760       |
|    policy_gradient_loss | -2.45e-07 |
|    value_loss           | 18.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 71        |
| time/                   |           |
|    fps                  | 1362      |
|    iterations           | 78        |
|    time_elapsed         | 117       |
|    total_timesteps      | 159744    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00235  |
|    explained_variance   | 0.989     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.25      |
|    n_updates            | 770       |
|    policy_gradient_loss | -2.12e-07 |
|    value_loss           | 19.4      |
---------------------------------------
Eval num_timesteps=160000, episode_reward=71.36 +/- 3.06
Episode length: 222.00 +/- 3.16
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 222       |
|    mean_reward          | 71.4      |
| time/                   |           |
|    total_timesteps      | 160000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00231  |
|    explained_variance   | 0.992     |
|    learning_rate        | 0.0003    |
|    loss                 | 16.8      |
|    n_updates            | 780       |
|    policy_gradient_loss | -2.87e-07 |
|    value_loss           | 13.2      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 70.9     |
| time/              |          |
|    fps             | 1360     |
|    iterations      | 79       |
|    time_elapsed    | 118      |
|    total_timesteps | 161792   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.9      |
| time/                   |           |
|    fps                  | 1361      |
|    iterations           | 80        |
|    time_elapsed         | 120       |
|    total_timesteps      | 163840    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0023   |
|    explained_variance   | 0.994     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.22      |
|    n_updates            | 790       |
|    policy_gradient_loss | -5.07e-07 |
|    value_loss           | 10.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.8      |
| time/                   |           |
|    fps                  | 1362      |
|    iterations           | 81        |
|    time_elapsed         | 121       |
|    total_timesteps      | 165888    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0023   |
|    explained_variance   | 0.986     |
|    learning_rate        | 0.0003    |
|    loss                 | 17.5      |
|    n_updates            | 800       |
|    policy_gradient_loss | -7.92e-08 |
|    value_loss           | 21.4      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 71            |
| time/                   |               |
|    fps                  | 1362          |
|    iterations           | 82            |
|    time_elapsed         | 123           |
|    total_timesteps      | 167936        |
| train/                  |               |
|    approx_kl            | 1.6470265e-05 |
|    clip_fraction        | 0.000244      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00213      |
|    explained_variance   | 0.995         |
|    learning_rate        | 0.0003        |
|    loss                 | 1.65          |
|    n_updates            | 810           |
|    policy_gradient_loss | -7.47e-05     |
|    value_loss           | 9.88          |
-------------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 221      |
|    ep_rew_mean          | 70.8     |
| time/                   |          |
|    fps                  | 1363     |
|    iterations           | 83       |
|    time_elapsed         | 124      |
|    total_timesteps      | 169984   |
| train/                  |          |
|    approx_kl            | 0.0      |
|    clip_fraction        | 0        |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.00191 |
|    explained_variance   | 0.991    |
|    learning_rate        | 0.0003   |
|    loss                 | 9.28     |
|    n_updates            | 820      |
|    policy_gradient_loss | -1.4e-07 |
|    value_loss           | 16.5     |
--------------------------------------
Eval num_timesteps=170000, episode_reward=71.54 +/- 2.61
Episode length: 222.00 +/- 2.76
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 222           |
|    mean_reward          | 71.5          |
| time/                   |               |
|    total_timesteps      | 170000        |
| train/                  |               |
|    approx_kl            | 5.5029523e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0018       |
|    explained_variance   | 0.989         |
|    learning_rate        | 0.0003        |
|    loss                 | 2.48          |
|    n_updates            | 830           |
|    policy_gradient_loss | -4.4e-05      |
|    value_loss           | 18.5          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 71.1     |
| time/              |          |
|    fps             | 1360     |
|    iterations      | 84       |
|    time_elapsed    | 126      |
|    total_timesteps | 172032   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.3      |
| time/                   |           |
|    fps                  | 1361      |
|    iterations           | 85        |
|    time_elapsed         | 127       |
|    total_timesteps      | 174080    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00171  |
|    explained_variance   | 0.993     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.79      |
|    n_updates            | 840       |
|    policy_gradient_loss | -4.23e-08 |
|    value_loss           | 12.5      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.4      |
| time/                   |           |
|    fps                  | 1362      |
|    iterations           | 86        |
|    time_elapsed         | 129       |
|    total_timesteps      | 176128    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00174  |
|    explained_variance   | 0.99      |
|    learning_rate        | 0.0003    |
|    loss                 | 8.64      |
|    n_updates            | 850       |
|    policy_gradient_loss | -1.19e-07 |
|    value_loss           | 18.6      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.3      |
| time/                   |           |
|    fps                  | 1363      |
|    iterations           | 87        |
|    time_elapsed         | 130       |
|    total_timesteps      | 178176    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00174  |
|    explained_variance   | 0.995     |
|    learning_rate        | 0.0003    |
|    loss                 | 8.32      |
|    n_updates            | 860       |
|    policy_gradient_loss | -2.47e-07 |
|    value_loss           | 10.4      |
---------------------------------------
Eval num_timesteps=180000, episode_reward=72.62 +/- 1.89
Episode length: 223.00 +/- 2.10
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 223       |
|    mean_reward          | 72.6      |
| time/                   |           |
|    total_timesteps      | 180000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00168  |
|    explained_variance   | 0.992     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.33      |
|    n_updates            | 870       |
|    policy_gradient_loss | -2.41e-07 |
|    value_loss           | 13.6      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 71.3     |
| time/              |          |
|    fps             | 1361     |
|    iterations      | 88       |
|    time_elapsed    | 132      |
|    total_timesteps | 180224   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 71.2         |
| time/                   |              |
|    fps                  | 1362         |
|    iterations           | 89           |
|    time_elapsed         | 133          |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 7.834547e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00155     |
|    explained_variance   | 0.994        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.312        |
|    n_updates            | 880          |
|    policy_gradient_loss | -9.01e-05    |
|    value_loss           | 9.97         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.3      |
| time/                   |           |
|    fps                  | 1363      |
|    iterations           | 90        |
|    time_elapsed         | 135       |
|    total_timesteps      | 184320    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00147  |
|    explained_variance   | 0.989     |
|    learning_rate        | 0.0003    |
|    loss                 | 50.4      |
|    n_updates            | 890       |
|    policy_gradient_loss | -1.77e-07 |
|    value_loss           | 18.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.4      |
| time/                   |           |
|    fps                  | 1363      |
|    iterations           | 91        |
|    time_elapsed         | 136       |
|    total_timesteps      | 186368    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00151  |
|    explained_variance   | 0.994     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.635     |
|    n_updates            | 900       |
|    policy_gradient_loss | -9.84e-08 |
|    value_loss           | 11.4      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.5      |
| time/                   |           |
|    fps                  | 1363      |
|    iterations           | 92        |
|    time_elapsed         | 138       |
|    total_timesteps      | 188416    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00146  |
|    explained_variance   | 0.994     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.417     |
|    n_updates            | 910       |
|    policy_gradient_loss | -1.31e-07 |
|    value_loss           | 12.3      |
---------------------------------------
Eval num_timesteps=190000, episode_reward=68.41 +/- 2.80
Episode length: 218.80 +/- 2.79
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 219       |
|    mean_reward          | 68.4      |
| time/                   |           |
|    total_timesteps      | 190000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00148  |
|    explained_variance   | 0.997     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.64      |
|    n_updates            | 920       |
|    policy_gradient_loss | -2.36e-07 |
|    value_loss           | 5.76      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 71.4     |
| time/              |          |
|    fps             | 1361     |
|    iterations      | 93       |
|    time_elapsed    | 139      |
|    total_timesteps | 190464   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.4      |
| time/                   |           |
|    fps                  | 1362      |
|    iterations           | 94        |
|    time_elapsed         | 141       |
|    total_timesteps      | 192512    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00149  |
|    explained_variance   | 0.993     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.07      |
|    n_updates            | 930       |
|    policy_gradient_loss | -6.06e-08 |
|    value_loss           | 10.2      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 71.4         |
| time/                   |              |
|    fps                  | 1363         |
|    iterations           | 95           |
|    time_elapsed         | 142          |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 3.654859e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.00145     |
|    explained_variance   | 0.996        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.86         |
|    n_updates            | 940          |
|    policy_gradient_loss | -5.84e-05    |
|    value_loss           | 7.84         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.2      |
| time/                   |           |
|    fps                  | 1364      |
|    iterations           | 96        |
|    time_elapsed         | 144       |
|    total_timesteps      | 196608    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00132  |
|    explained_variance   | 0.992     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.59      |
|    n_updates            | 950       |
|    policy_gradient_loss | -2.79e-08 |
|    value_loss           | 13        |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.1      |
| time/                   |           |
|    fps                  | 1364      |
|    iterations           | 97        |
|    time_elapsed         | 145       |
|    total_timesteps      | 198656    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0013   |
|    explained_variance   | 0.998     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.897     |
|    n_updates            | 960       |
|    policy_gradient_loss | -2.63e-07 |
|    value_loss           | 4.07      |
---------------------------------------
Eval num_timesteps=200000, episode_reward=69.65 +/- 3.74
Episode length: 220.00 +/- 3.69
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 220           |
|    mean_reward          | 69.6          |
| time/                   |               |
|    total_timesteps      | 200000        |
| train/                  |               |
|    approx_kl            | 3.9105915e-05 |
|    clip_fraction        | 0.000342      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00121      |
|    explained_variance   | 0.992         |
|    learning_rate        | 0.0003        |
|    loss                 | 6.45          |
|    n_updates            | 970           |
|    policy_gradient_loss | -0.000243     |
|    value_loss           | 13            |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 70.9     |
| time/              |          |
|    fps             | 1362     |
|    iterations      | 98       |
|    time_elapsed    | 147      |
|    total_timesteps | 200704   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 70.9          |
| time/                   |               |
|    fps                  | 1362          |
|    iterations           | 99            |
|    time_elapsed         | 148           |
|    total_timesteps      | 202752        |
| train/                  |               |
|    approx_kl            | 2.5305577e-05 |
|    clip_fraction        | 0.000293      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00104      |
|    explained_variance   | 0.998         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.535         |
|    n_updates            | 980           |
|    policy_gradient_loss | -0.000262     |
|    value_loss           | 3.97          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 70.9      |
| time/                   |           |
|    fps                  | 1363      |
|    iterations           | 100       |
|    time_elapsed         | 150       |
|    total_timesteps      | 204800    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000916 |
|    explained_variance   | 0.993     |
|    learning_rate        | 0.0003    |
|    loss                 | 5.3       |
|    n_updates            | 990       |
|    policy_gradient_loss | -2.07e-07 |
|    value_loss           | 11.1      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 71           |
| time/                   |              |
|    fps                  | 1364         |
|    iterations           | 101          |
|    time_elapsed         | 151          |
|    total_timesteps      | 206848       |
| train/                  |              |
|    approx_kl            | 7.805822e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.000879    |
|    explained_variance   | 0.996        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.23         |
|    n_updates            | 1000         |
|    policy_gradient_loss | -7.35e-05    |
|    value_loss           | 6.32         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 70.7      |
| time/                   |           |
|    fps                  | 1365      |
|    iterations           | 102       |
|    time_elapsed         | 153       |
|    total_timesteps      | 208896    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000829 |
|    explained_variance   | 0.99      |
|    learning_rate        | 0.0003    |
|    loss                 | 5.19      |
|    n_updates            | 1010      |
|    policy_gradient_loss | -8.66e-09 |
|    value_loss           | 16.7      |
---------------------------------------
Eval num_timesteps=210000, episode_reward=70.93 +/- 2.79
Episode length: 221.40 +/- 2.58
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 221           |
|    mean_reward          | 70.9          |
| time/                   |               |
|    total_timesteps      | 210000        |
| train/                  |               |
|    approx_kl            | 2.6958296e-05 |
|    clip_fraction        | 0.000439      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.000788     |
|    explained_variance   | 0.997         |
|    learning_rate        | 0.0003        |
|    loss                 | 6.72          |
|    n_updates            | 1020          |
|    policy_gradient_loss | -0.000238     |
|    value_loss           | 4.03          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 71       |
| time/              |          |
|    fps             | 1363     |
|    iterations      | 103      |
|    time_elapsed    | 154      |
|    total_timesteps | 210944   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71        |
| time/                   |           |
|    fps                  | 1363      |
|    iterations           | 104       |
|    time_elapsed         | 156       |
|    total_timesteps      | 212992    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000792 |
|    explained_variance   | 0.998     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.42      |
|    n_updates            | 1030      |
|    policy_gradient_loss | -6.7e-09  |
|    value_loss           | 6.03      |
---------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 70.9          |
| time/                   |               |
|    fps                  | 1364          |
|    iterations           | 105           |
|    time_elapsed         | 157           |
|    total_timesteps      | 215040        |
| train/                  |               |
|    approx_kl            | 1.9367551e-05 |
|    clip_fraction        | 0.000342      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.00069      |
|    explained_variance   | 0.997         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.28          |
|    n_updates            | 1040          |
|    policy_gradient_loss | -0.000365     |
|    value_loss           | 5.58          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 70.9      |
| time/                   |           |
|    fps                  | 1365      |
|    iterations           | 106       |
|    time_elapsed         | 159       |
|    total_timesteps      | 217088    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000675 |
|    explained_variance   | 0.997     |
|    learning_rate        | 0.0003    |
|    loss                 | 11.5      |
|    n_updates            | 1050      |
|    policy_gradient_loss | -5.6e-08  |
|    value_loss           | 6.44      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 70.8      |
| time/                   |           |
|    fps                  | 1366      |
|    iterations           | 107       |
|    time_elapsed         | 160       |
|    total_timesteps      | 219136    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000677 |
|    explained_variance   | 0.994     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.67      |
|    n_updates            | 1060      |
|    policy_gradient_loss | -9.01e-08 |
|    value_loss           | 10.2      |
---------------------------------------
Eval num_timesteps=220000, episode_reward=69.78 +/- 2.94
Episode length: 220.20 +/- 2.79
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 220           |
|    mean_reward          | 69.8          |
| time/                   |               |
|    total_timesteps      | 220000        |
| train/                  |               |
|    approx_kl            | 1.4062767e-05 |
|    clip_fraction        | 0.000342      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.000599     |
|    explained_variance   | 0.997         |
|    learning_rate        | 0.0003        |
|    loss                 | 1.37          |
|    n_updates            | 1070          |
|    policy_gradient_loss | -0.000112     |
|    value_loss           | 3.84          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 71       |
| time/              |          |
|    fps             | 1356     |
|    iterations      | 108      |
|    time_elapsed    | 163      |
|    total_timesteps | 221184   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.2      |
| time/                   |           |
|    fps                  | 1357      |
|    iterations           | 109       |
|    time_elapsed         | 164       |
|    total_timesteps      | 223232    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000557 |
|    explained_variance   | 0.997     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.529     |
|    n_updates            | 1080      |
|    policy_gradient_loss | -1.62e-07 |
|    value_loss           | 4.12      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.3      |
| time/                   |           |
|    fps                  | 1358      |
|    iterations           | 110       |
|    time_elapsed         | 165       |
|    total_timesteps      | 225280    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000556 |
|    explained_variance   | 0.996     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.669     |
|    n_updates            | 1090      |
|    policy_gradient_loss | -1.26e-07 |
|    value_loss           | 6.2       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.3      |
| time/                   |           |
|    fps                  | 1359      |
|    iterations           | 111       |
|    time_elapsed         | 167       |
|    total_timesteps      | 227328    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000548 |
|    explained_variance   | 0.993     |
|    learning_rate        | 0.0003    |
|    loss                 | 53.5      |
|    n_updates            | 1100      |
|    policy_gradient_loss | -2.17e-07 |
|    value_loss           | 11.3      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71        |
| time/                   |           |
|    fps                  | 1360      |
|    iterations           | 112       |
|    time_elapsed         | 168       |
|    total_timesteps      | 229376    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000563 |
|    explained_variance   | 0.996     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.07      |
|    n_updates            | 1110      |
|    policy_gradient_loss | -2.79e-08 |
|    value_loss           | 7.06      |
---------------------------------------
Eval num_timesteps=230000, episode_reward=68.77 +/- 2.39
Episode length: 219.20 +/- 2.32
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 219       |
|    mean_reward          | 68.8      |
| time/                   |           |
|    total_timesteps      | 230000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000552 |
|    explained_variance   | 0.999     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.2       |
|    n_updates            | 1120      |
|    policy_gradient_loss | -3.07e-08 |
|    value_loss           | 2.26      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 70.9     |
| time/              |          |
|    fps             | 1358     |
|    iterations      | 113      |
|    time_elapsed    | 170      |
|    total_timesteps | 231424   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.8      |
| time/                   |           |
|    fps                  | 1359      |
|    iterations           | 114       |
|    time_elapsed         | 171       |
|    total_timesteps      | 233472    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000549 |
|    explained_variance   | 0.998     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.55      |
|    n_updates            | 1130      |
|    policy_gradient_loss | -1.55e-07 |
|    value_loss           | 3.76      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.5      |
| time/                   |           |
|    fps                  | 1359      |
|    iterations           | 115       |
|    time_elapsed         | 173       |
|    total_timesteps      | 235520    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000553 |
|    explained_variance   | 0.998     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.838     |
|    n_updates            | 1140      |
|    policy_gradient_loss | -1.45e-07 |
|    value_loss           | 2.48      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.6      |
| time/                   |           |
|    fps                  | 1360      |
|    iterations           | 116       |
|    time_elapsed         | 174       |
|    total_timesteps      | 237568    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000566 |
|    explained_variance   | 0.998     |
|    learning_rate        | 0.0003    |
|    loss                 | 16.7      |
|    n_updates            | 1150      |
|    policy_gradient_loss | -5.56e-08 |
|    value_loss           | 4.57      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.7      |
| time/                   |           |
|    fps                  | 1360      |
|    iterations           | 117       |
|    time_elapsed         | 176       |
|    total_timesteps      | 239616    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000554 |
|    explained_variance   | 0.997     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.08      |
|    n_updates            | 1160      |
|    policy_gradient_loss | -1.45e-08 |
|    value_loss           | 5.49      |
---------------------------------------
Eval num_timesteps=240000, episode_reward=70.70 +/- 3.69
Episode length: 221.20 +/- 3.49
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 221       |
|    mean_reward          | 70.7      |
| time/                   |           |
|    total_timesteps      | 240000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000553 |
|    explained_variance   | 0.999     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.482     |
|    n_updates            | 1170      |
|    policy_gradient_loss | -3.31e-08 |
|    value_loss           | 1.27      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 70.9     |
| time/              |          |
|    fps             | 1353     |
|    iterations      | 118      |
|    time_elapsed    | 178      |
|    total_timesteps | 241664   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71        |
| time/                   |           |
|    fps                  | 1349      |
|    iterations           | 119       |
|    time_elapsed         | 180       |
|    total_timesteps      | 243712    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000567 |
|    explained_variance   | 0.999     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.6       |
|    n_updates            | 1180      |
|    policy_gradient_loss | -2.13e-08 |
|    value_loss           | 2.48      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.9      |
| time/                   |           |
|    fps                  | 1350      |
|    iterations           | 120       |
|    time_elapsed         | 182       |
|    total_timesteps      | 245760    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000569 |
|    explained_variance   | 0.997     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.85      |
|    n_updates            | 1190      |
|    policy_gradient_loss | -1.82e-07 |
|    value_loss           | 4.74      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 71        |
| time/                   |           |
|    fps                  | 1350      |
|    iterations           | 121       |
|    time_elapsed         | 183       |
|    total_timesteps      | 247808    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000555 |
|    explained_variance   | 0.998     |
|    learning_rate        | 0.0003    |
|    loss                 | 33.8      |
|    n_updates            | 1200      |
|    policy_gradient_loss | -9.74e-08 |
|    value_loss           | 5.53      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.9      |
| time/                   |           |
|    fps                  | 1351      |
|    iterations           | 122       |
|    time_elapsed         | 184       |
|    total_timesteps      | 249856    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000558 |
|    explained_variance   | 0.997     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.686     |
|    n_updates            | 1210      |
|    policy_gradient_loss | -2.5e-08  |
|    value_loss           | 4.82      |
---------------------------------------
Eval num_timesteps=250000, episode_reward=70.76 +/- 3.64
Episode length: 221.40 +/- 3.72
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 221           |
|    mean_reward          | 70.8          |
| time/                   |               |
|    total_timesteps      | 250000        |
| train/                  |               |
|    approx_kl            | 1.1842232e-05 |
|    clip_fraction        | 9.77e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.0005       |
|    explained_variance   | 0.997         |
|    learning_rate        | 0.0003        |
|    loss                 | 6.98          |
|    n_updates            | 1220          |
|    policy_gradient_loss | -0.00014      |
|    value_loss           | 6.18          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 71.2     |
| time/              |          |
|    fps             | 1349     |
|    iterations      | 123      |
|    time_elapsed    | 186      |
|    total_timesteps | 251904   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.3      |
| time/                   |           |
|    fps                  | 1350      |
|    iterations           | 124       |
|    time_elapsed         | 188       |
|    total_timesteps      | 253952    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000482 |
|    explained_variance   | 0.994     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.937     |
|    n_updates            | 1230      |
|    policy_gradient_loss | -4.27e-08 |
|    value_loss           | 10.7      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.4      |
| time/                   |           |
|    fps                  | 1350      |
|    iterations           | 125       |
|    time_elapsed         | 189       |
|    total_timesteps      | 256000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000474 |
|    explained_variance   | 0.998     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.21      |
|    n_updates            | 1240      |
|    policy_gradient_loss | -1.32e-08 |
|    value_loss           | 4.39      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.5      |
| time/                   |           |
|    fps                  | 1351      |
|    iterations           | 126       |
|    time_elapsed         | 190       |
|    total_timesteps      | 258048    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000477 |
|    explained_variance   | 0.998     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.34      |
|    n_updates            | 1250      |
|    policy_gradient_loss | -3.75e-08 |
|    value_loss           | 5.6       |
---------------------------------------
Eval num_timesteps=260000, episode_reward=70.31 +/- 3.16
Episode length: 221.00 +/- 3.29
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 221       |
|    mean_reward          | 70.3      |
| time/                   |           |
|    total_timesteps      | 260000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000477 |
|    explained_variance   | 0.999     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.633     |
|    n_updates            | 1260      |
|    policy_gradient_loss | -2.68e-08 |
|    value_loss           | 1.74      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 71.5     |
| time/              |          |
|    fps             | 1347     |
|    iterations      | 127      |
|    time_elapsed    | 193      |
|    total_timesteps | 260096   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 222           |
|    ep_rew_mean          | 71.5          |
| time/                   |               |
|    fps                  | 1348          |
|    iterations           | 128           |
|    time_elapsed         | 194           |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 1.0643853e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.000432     |
|    explained_variance   | 0.996         |
|    learning_rate        | 0.0003        |
|    loss                 | 0.948         |
|    n_updates            | 1270          |
|    policy_gradient_loss | -8.42e-05     |
|    value_loss           | 7.52          |
-------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.5      |
| time/                   |           |
|    fps                  | 1348      |
|    iterations           | 129       |
|    time_elapsed         | 195       |
|    total_timesteps      | 264192    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000416 |
|    explained_variance   | 0.997     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.37      |
|    n_updates            | 1280      |
|    policy_gradient_loss | -1.94e-08 |
|    value_loss           | 5.27      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.4      |
| time/                   |           |
|    fps                  | 1348      |
|    iterations           | 130       |
|    time_elapsed         | 197       |
|    total_timesteps      | 266240    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000405 |
|    explained_variance   | 0.998     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.74      |
|    n_updates            | 1290      |
|    policy_gradient_loss | -5.55e-08 |
|    value_loss           | 3.21      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.5      |
| time/                   |           |
|    fps                  | 1349      |
|    iterations           | 131       |
|    time_elapsed         | 198       |
|    total_timesteps      | 268288    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000406 |
|    explained_variance   | 0.996     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.93      |
|    n_updates            | 1300      |
|    policy_gradient_loss | -6.76e-09 |
|    value_loss           | 7.2       |
---------------------------------------
Eval num_timesteps=270000, episode_reward=72.20 +/- 2.22
Episode length: 222.60 +/- 2.42
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 223       |
|    mean_reward          | 72.2      |
| time/                   |           |
|    total_timesteps      | 270000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000405 |
|    explained_variance   | 0.997     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.34      |
|    n_updates            | 1310      |
|    policy_gradient_loss | -4.45e-09 |
|    value_loss           | 5.59      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 71.3     |
| time/              |          |
|    fps             | 1347     |
|    iterations      | 132      |
|    time_elapsed    | 200      |
|    total_timesteps | 270336   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.4      |
| time/                   |           |
|    fps                  | 1348      |
|    iterations           | 133       |
|    time_elapsed         | 202       |
|    total_timesteps      | 272384    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000416 |
|    explained_variance   | 0.999     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.526     |
|    n_updates            | 1320      |
|    policy_gradient_loss | -1.99e-08 |
|    value_loss           | 3.02      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.5      |
| time/                   |           |
|    fps                  | 1348      |
|    iterations           | 134       |
|    time_elapsed         | 203       |
|    total_timesteps      | 274432    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000407 |
|    explained_variance   | 0.996     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.7       |
|    n_updates            | 1330      |
|    policy_gradient_loss | -1.19e-08 |
|    value_loss           | 7.38      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.4      |
| time/                   |           |
|    fps                  | 1349      |
|    iterations           | 135       |
|    time_elapsed         | 204       |
|    total_timesteps      | 276480    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000405 |
|    explained_variance   | 0.995     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.95      |
|    n_updates            | 1340      |
|    policy_gradient_loss | -4.87e-09 |
|    value_loss           | 8.43      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.3      |
| time/                   |           |
|    fps                  | 1350      |
|    iterations           | 136       |
|    time_elapsed         | 206       |
|    total_timesteps      | 278528    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000409 |
|    explained_variance   | 0.999     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.63      |
|    n_updates            | 1350      |
|    policy_gradient_loss | -5.55e-08 |
|    value_loss           | 1.17      |
---------------------------------------
Eval num_timesteps=280000, episode_reward=71.77 +/- 3.31
Episode length: 222.00 +/- 3.29
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 222       |
|    mean_reward          | 71.8      |
| time/                   |           |
|    total_timesteps      | 280000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000417 |
|    explained_variance   | 0.999     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.745     |
|    n_updates            | 1360      |
|    policy_gradient_loss | 1.75e-08  |
|    value_loss           | 1.71      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 71.3     |
| time/              |          |
|    fps             | 1349     |
|    iterations      | 137      |
|    time_elapsed    | 207      |
|    total_timesteps | 280576   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.3      |
| time/                   |           |
|    fps                  | 1349      |
|    iterations           | 138       |
|    time_elapsed         | 209       |
|    total_timesteps      | 282624    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000415 |
|    explained_variance   | 0.995     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.19      |
|    n_updates            | 1370      |
|    policy_gradient_loss | -1.46e-08 |
|    value_loss           | 7.75      |
---------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 222          |
|    ep_rew_mean          | 71.3         |
| time/                   |              |
|    fps                  | 1350         |
|    iterations           | 139          |
|    time_elapsed         | 210          |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 1.798026e-05 |
|    clip_fraction        | 0.000342     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0004      |
|    explained_variance   | 0.999        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.23         |
|    n_updates            | 1380         |
|    policy_gradient_loss | -0.000277    |
|    value_loss           | 4.19         |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.4      |
| time/                   |           |
|    fps                  | 1351      |
|    iterations           | 140       |
|    time_elapsed         | 212       |
|    total_timesteps      | 286720    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000394 |
|    explained_variance   | 0.999     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.52      |
|    n_updates            | 1390      |
|    policy_gradient_loss | -7e-09    |
|    value_loss           | 2.81      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 222       |
|    ep_rew_mean          | 71.1      |
| time/                   |           |
|    fps                  | 1351      |
|    iterations           | 141       |
|    time_elapsed         | 213       |
|    total_timesteps      | 288768    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000393 |
|    explained_variance   | 0.996     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.84      |
|    n_updates            | 1400      |
|    policy_gradient_loss | -1.96e-08 |
|    value_loss           | 6.86      |
---------------------------------------
Eval num_timesteps=290000, episode_reward=69.55 +/- 1.75
Episode length: 220.00 +/- 1.67
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 220           |
|    mean_reward          | 69.6          |
| time/                   |               |
|    total_timesteps      | 290000        |
| train/                  |               |
|    approx_kl            | 2.7037458e-08 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.000399     |
|    explained_variance   | 0.999         |
|    learning_rate        | 0.0003        |
|    loss                 | 1.86          |
|    n_updates            | 1410          |
|    policy_gradient_loss | -5.18e-07     |
|    value_loss           | 3.98          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 71       |
| time/              |          |
|    fps             | 1350     |
|    iterations      | 142      |
|    time_elapsed    | 215      |
|    total_timesteps | 290816   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.9      |
| time/                   |           |
|    fps                  | 1351      |
|    iterations           | 143       |
|    time_elapsed         | 216       |
|    total_timesteps      | 292864    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000392 |
|    explained_variance   | 0.999     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.84      |
|    n_updates            | 1420      |
|    policy_gradient_loss | 4.81e-09  |
|    value_loss           | 3.56      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.8      |
| time/                   |           |
|    fps                  | 1351      |
|    iterations           | 144       |
|    time_elapsed         | 218       |
|    total_timesteps      | 294912    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000389 |
|    explained_variance   | 0.999     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.76      |
|    n_updates            | 1430      |
|    policy_gradient_loss | -8.88e-10 |
|    value_loss           | 3.83      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.7      |
| time/                   |           |
|    fps                  | 1352      |
|    iterations           | 145       |
|    time_elapsed         | 219       |
|    total_timesteps      | 296960    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000403 |
|    explained_variance   | 0.999     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.01      |
|    n_updates            | 1440      |
|    policy_gradient_loss | -9.55e-10 |
|    value_loss           | 3.64      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 221       |
|    ep_rew_mean          | 70.6      |
| time/                   |           |
|    fps                  | 1352      |
|    iterations           | 146       |
|    time_elapsed         | 221       |
|    total_timesteps      | 299008    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000393 |
|    explained_variance   | 0.999     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.21      |
|    n_updates            | 1450      |
|    policy_gradient_loss | -9.4e-09  |
|    value_loss           | 2.67      |
---------------------------------------
Eval num_timesteps=300000, episode_reward=70.85 +/- 2.93
Episode length: 221.40 +/- 2.94
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 221       |
|    mean_reward          | 70.9      |
| time/                   |           |
|    total_timesteps      | 300000    |
| train/                  |           |
|    approx_kl            | 0.0       |
|    clip_fraction        | 0         |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.000394 |
|    explained_variance   | 0.998     |
|    learning_rate        | 0.0003    |
|    loss                 | 5.46      |
|    n_updates            | 1460      |
|    policy_gradient_loss | -3.18e-08 |
|    value_loss           | 3.45      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 70.9     |
| time/              |          |
|    fps             | 1351     |
|    iterations      | 147      |
|    time_elapsed    | 222      |
|    total_timesteps | 301056   |
---------------------------------

Training complete!
Run directory: /users/PAS2119/cristianbautistai/hierarchical_rl_robotaxi/logs/2025-12-09_00-12-41

